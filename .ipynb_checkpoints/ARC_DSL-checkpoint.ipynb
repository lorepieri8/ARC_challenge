{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 version:  4.1.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy\n",
    "import gc\n",
    "import cv2\n",
    "import requests\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as colors_mat\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "from skimage import measure\n",
    "from skimage.segmentation import flood, flood_fill\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from itertools import product\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.signal import convolve2d\n",
    "from collections import Counter\n",
    "from cv2 import matchTemplate as cv2m\n",
    "from math import sqrt; from itertools import count, islice\n",
    "print(\"cv2 version: \",cv2.__version__)\n",
    "\n",
    "DEBUG = True # Active logging, printing, etc. False when committing to the LB. \n",
    "url_slack = \"https://hooks.slack.com/services/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\"  # This is secret, do not share.\n",
    "headers = {'Content-type': 'application/json'}\n",
    "MAX_DIM_MATRIX = 30\n",
    "MAX_magic_args_number = 1000\n",
    "I_AM_IN_KAGGLE = os.path.isdir(\"/kaggle/input/abstraction-and-reasoning-challenge/\")\n",
    "black_square = np.full((2,2),0)\n",
    "DUMMY_COLOR = 17\n",
    "MAX_N_OBJECTS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Initial Data ...\n",
      "--- 0.019137144088745117 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Initial Data ...\")\n",
    "\n",
    "if I_AM_IN_KAGGLE:\n",
    "    data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "else:\n",
    "    data_path = Path('')\n",
    "training_path = data_path / 'training'\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "testing_path = data_path / 'test'\n",
    "\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "evaluation_tasks = sorted(os.listdir(evaluation_path))\n",
    "testing_tasks = sorted(os.listdir(testing_path))\n",
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Functions ...\n",
      "--- 0.001046895980834961 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Functions ...\")\n",
    "\n",
    "def flattener(pred):\n",
    "    \n",
    "    str_pred = str([row for row in pred.tolist()])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    \n",
    "    return str_pred\n",
    "\n",
    "def build_trainlist(task):\n",
    "    \n",
    "    task_data = []\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "        list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "    \n",
    "    return task_data\n",
    "\n",
    "def build_testlist(task, LB_submission=False, pair_id=0):\n",
    "    \n",
    "    task_data = []\n",
    "    \n",
    "    if LB_submission:\n",
    "        t_in = np.array(task[\"test\"][pair_id][\"input\"]).astype('uint8')       \n",
    "        list.append(task_data, (t_in.copy()))\n",
    "    else:\n",
    "        for i, t in enumerate(task[\"test\"]):\n",
    "            t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "            list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "          \n",
    "    return task_data\n",
    "\n",
    "def load_data(p, phase=None):\n",
    "    \n",
    "    if phase in {'training', 'test', 'evaluation'}:\n",
    "        p = data_path / phase / p\n",
    "    \n",
    "    task = json.loads(Path(p).read_text())\n",
    "    dict_vals_to_np = lambda x: { k : np.array(v) for k, v in x.items() }\n",
    "    assert set(task) == {'test', 'train'}\n",
    "    res = dict(test=[], train=[])\n",
    "    \n",
    "    for t in task['train']:\n",
    "        assert set(t) == {'input', 'output'}\n",
    "        res['train'].append(dict_vals_to_np(t))\n",
    "    for t in task['test']:\n",
    "        res['test'].append(dict_vals_to_np(t))\n",
    "        \n",
    "    return res\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Files ...\n",
      "--- 0.8840620517730713 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Files ...\")\n",
    "\n",
    "train_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(training_tasks[i], phase='training')\n",
    "    list.append(train_task_data, task)\n",
    "\n",
    "eval_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(evaluation_tasks[i], phase='evaluation')\n",
    "    list.append(eval_task_data, task)\n",
    "\n",
    "test_task_data = []\n",
    "for i in range(0, 100):\n",
    "    task = load_data(testing_tasks[i], phase='test')\n",
    "    list.append(test_task_data, task)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checking Functions\n",
      "--- 0.0015759468078613281 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Checking Functions\")\n",
    "\n",
    "cmap = colors_mat.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors_mat.Normalize(vmin=0, vmax=9)\n",
    "num2color = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\n",
    "color2num = {c: n for n, c in enumerate(num2color)}\n",
    "\n",
    "def plot_one(task, ax, i,train_or_test,input_or_output):\n",
    "    \n",
    "    input_matrix = task[train_or_test][i][input_or_output]\n",
    "    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
    "    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
    "    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(train_or_test + ' '+ input_or_output)\n",
    "    \n",
    "def plot_task(task):\n",
    "\n",
    "    num_train = len(task['train'])\n",
    "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
    "    for i in range(num_train):     \n",
    "        plot_one(task, axs[0,i],i,'train','input')\n",
    "        plot_one(task, axs[1,i],i,'train','output')        \n",
    "    plt.tight_layout()\n",
    "    plt.show()        \n",
    "        \n",
    "    num_test = len(task['test'])\n",
    "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
    "    if num_test==1: \n",
    "        plot_one(task, axs[0],0,'test','input')\n",
    "        plot_one(task, axs[1],0,'test','output')     \n",
    "    else:\n",
    "        for i in range(num_test):      \n",
    "            plot_one(task, axs[0,i],i,'test','input')\n",
    "            plot_one(task, axs[1,i],i,'test','output')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def check_p(task, pred_func):\n",
    "    \n",
    "    fig_num = 0\n",
    "    n = len(task[\"train\"]) + len(task[\"test\"])\n",
    "    fig, axs = plt.subplots(3, n, figsize=(4*n,12), dpi=50)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # All Data for Task\n",
    "    train_data = build_trainlist(task)\n",
    "    test_data = build_testlist(task)\n",
    "    task_data = Task(train_data, test_data)\n",
    "    \n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')   \n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Train-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Train-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Train-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "        \n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')\n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Test-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Test-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Test-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Main)\n",
      "--- 0.0025217533111572266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Main)\")\n",
    "\n",
    "# color the given coordinates points, passed as list of 2d list. Example: [[0,1],[2,3],[2,4]]\n",
    "def color_points(t,points_coord,color):\n",
    "    \n",
    "    t_copy = np.copy(t)\n",
    "    for point in points_coord:\n",
    "        t_copy[point[0],point[1]] = color\n",
    "    return t_copy\n",
    "\n",
    "# https://stackoverflow.com/questions/10823877/what-is-the-fastest-way-to-flatten-arbitrarily-nested-lists-in-python\n",
    "# flatten a list of nested lists\n",
    "def flatten_rec(container):\n",
    "    for i in container:\n",
    "        if isinstance(i, (list,tuple)):\n",
    "            for j in flatten_rec(i):\n",
    "                yield j\n",
    "        else:\n",
    "            yield i\n",
    "            \n",
    "#https://stackoverflow.com/questions/32531377/how-can-i-check-if-one-two-dimensional-numpy-array-contains-a-specific-pattern-o\n",
    "# return the coords of all the instances of template in grid (upper left corner)\n",
    "def match_template(grid, template):\n",
    "    \n",
    "    # check that the shapes are consinstent\n",
    "    if grid.shape == (1,):\n",
    "        return []\n",
    "    if template.shape == (1,):\n",
    "        pass \n",
    "    else:\n",
    "        if (grid.shape[0] < template.shape[0]) or (grid.shape[1] < template.shape[1]):\n",
    "            return []\n",
    "        \n",
    "    M = cv2m(grid.astype('uint8'),template.astype('uint8'),cv2.TM_SQDIFF)\n",
    "    x,y = np.where(M<0.01) # =0 can fail with floats\n",
    "    coords = list(zip(x, y))\n",
    "    return coords\n",
    "\n",
    "# https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical\n",
    "def checkEqual1(iterator):\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all(first == rest for rest in iterator)\n",
    "\n",
    "# expect a list of lists, check that all of them have more than N elements\n",
    "def checkAllMoreN(iterator, N):\n",
    "    if iterator == []:\n",
    "        return False\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "        if not (len(first) > N):\n",
    "            return False\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all( (len(rest) > N) for rest in iterator)\n",
    "\n",
    "def is_prime(n):\n",
    "    return n > 1 and all(n%i for i in islice(count(2), int(sqrt(n)-1)))\n",
    "\n",
    "# return max and min lenght objects in llist\n",
    "def checkMaxMinLen(llist):\n",
    "    max_len = 0\n",
    "    min_len = 100\n",
    "    for el in llist:\n",
    "        if len(el) > max_len:\n",
    "            max_len = len(el)\n",
    "        if len(el) < min_len:   \n",
    "            min_len = len(el)\n",
    "    return {\"min_len\":min_len, \"max_len\":max_len}\n",
    "        \n",
    "\n",
    "def send_slack_report(message):\n",
    "    data = {'auth_token': 'auth1', 'widget': 'id1', 'text': message}\n",
    "    r = requests.post(url_slack, data=json.dumps(data), headers=headers)\n",
    "\n",
    "def get_neighbors(grid, i, j):\n",
    "    \n",
    "    nbh = lambda x, i, j: { \n",
    "        (ip, jp) : x[i+ip, j+jp] \n",
    "            for ip, jp in product([1, -1, 0], repeat=2) \n",
    "                if 0 <= i+ip < x.shape[0] and 0 <= j+jp < x.shape[1]\n",
    "    }\n",
    "        \n",
    "    nbh_data = nbh(grid, i, j)\n",
    "    nbh_values = [(1, 1), (1, -1), (1, 0), (-1, 1), (-1, -1), \n",
    "                  (-1, 0), (0, 1), (0, -1), (0, 0)]\n",
    "\n",
    "    for val in nbh_values:\n",
    "        if val not in nbh_data:\n",
    "            nbh_data[val] = 0\n",
    "    \n",
    "    return nbh_data\n",
    "\n",
    "def get_background_color(grid):\n",
    "    \n",
    "    try:    \n",
    "        background_color = 0\n",
    "        cnt = np.bincount(grid.flatten())[1:]\n",
    "        bg_color = [i + 1 for i, x in enumerate(cnt) if x == max(cnt)][0]\n",
    "        if np.nonzero(cnt)[0].shape[0] >= 2:\n",
    "            if max(cnt) >= (grid.shape[0] * grid.shape[1] * 0.25):\n",
    "                background_color = bg_color\n",
    "        return background_color    \n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "# return a list with all the colors available in grid\n",
    "def get_unique_colors(grid):\n",
    "        return np.unique(grid).tolist()\n",
    "    \n",
    "# Return a dictionary color:percentage, for instance: {0: 0.666,1: 0.333, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}\n",
    "def color_percentage(grid, sorted_dict=True):\n",
    "    \n",
    "    n_elements = grid.shape[0] * grid.shape[1]\n",
    "    if ( n_elements <= 0):\n",
    "        raise ValueError(\"n_elements <= 0\")\n",
    "    unique, counts = np.unique(grid, return_counts=True)\n",
    "    if not (all(j < 10 for j in unique)):\n",
    "        raise ValueError(\"Uknown color! unique:\", unique)\n",
    "        \n",
    "    percentages =  dict(zip(unique, counts))\n",
    "    for color in range(0,10):\n",
    "        if color not in percentages.keys():\n",
    "            percentages[color] = 0.0\n",
    "    percentages.update((x, y*1.0/n_elements) for x, y in percentages.items())\n",
    "    \n",
    "    if sorted_dict:\n",
    "        percentages = collections.OrderedDict(sorted(percentages.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return percentages\n",
    "\n",
    "# Return True if symmetric\n",
    "def horizontal_symmetric(grid):\n",
    "    return np.array_equal(grid, np.flipud(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def vertical_symmetric(grid):\n",
    "    return np.array_equal(grid, np.fliplr(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def left_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid.T)\n",
    "\n",
    "# Return True if symmetric\n",
    "def right_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid[::-1,::-1].T) # or np.rot90(grid,2).T\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Detection)\n",
      "--- 0.00186920166015625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Detection)\")\n",
    "       \n",
    "## OBJECTS ######################\n",
    "\n",
    "# detect all the objects (a cluster of pixels colored differently from the background, without making distinction of colors)\n",
    "# Return a list of arrays, containing the coordinates of the objects in the parent grid.\n",
    "def detect_objects(grid, include_diag=True):\n",
    "    \n",
    "    structure = [[1,1,1],[1,1,1],[1,1,1]]\n",
    "    if not include_diag:\n",
    "        structure = [[0,1,0],[1,1,1],[0,1,0]]\n",
    "        \n",
    "    t_copy = np.copy(grid)\n",
    "    background_color = get_background_color(grid)\n",
    "    u_colors = np.unique(grid)\n",
    "    colors = np.delete(u_colors, np.where(u_colors == background_color))\n",
    "    t_copy[t_copy != background_color] = DUMMY_COLOR\n",
    "    \n",
    "    indices = []\n",
    "    labels, num_labels = label(t_copy == DUMMY_COLOR, structure=structure)\n",
    "    \n",
    "    for i in range(0, num_labels):\n",
    "        idx = np.column_stack(np.where(labels == i + 1))\n",
    "        list.append(indices, idx)\n",
    "    \n",
    "    if len(indices) > MAX_N_OBJECTS:\n",
    "        return []\n",
    "    return indices\n",
    "\n",
    "# Take an array with the object coordinates in the parent grid, and return useful stats.\n",
    "def matrix_rect(obj, add_border=0):\n",
    "    \n",
    "    x_max, x_min, y_max, y_min = 0, 99, 0, 99\n",
    "    \n",
    "    for point in obj:\n",
    "        if point[0] < x_min:\n",
    "            x_min = point[0]\n",
    "        if point[1] < y_min:\n",
    "            y_min = point[1]\n",
    "        if point[0] > x_max:\n",
    "            x_max = point[0]\n",
    "        if point[1] > y_max:\n",
    "            y_max = point[1]\n",
    "            \n",
    "    x_min = x_min - add_border\n",
    "    y_min = y_min - add_border\n",
    "    x_max = x_max + add_border\n",
    "    y_max = y_max + add_border\n",
    "\n",
    "    for i in range(x_min,x_max + 1):\n",
    "        for j in range(y_min,y_max + 1):\n",
    "            new_point = [i,j]\n",
    "            if not (new_point in obj):\n",
    "                obj.append(new_point)\n",
    "                \n",
    "    x_dim = x_max + 1 - x_min\n",
    "    y_dim = y_max + 1 - y_min\n",
    "    \n",
    "    return {\"obj\":obj, \n",
    "            \"x_dim\": x_dim, \n",
    "            \"y_dim\": y_dim, \n",
    "            \"x_max\": x_max, \n",
    "            \"y_max\": y_max, \n",
    "            \"x_min\": x_min, \n",
    "            \"y_min\": y_min}\n",
    "    \n",
    "    \n",
    "# fill a contiguous space with fill_color, percolating from starting_point\n",
    "def fill_holes(t,fill_color,starting_point=(0,0)):\n",
    "    t_copy = np.copy(t)\n",
    "    filled = flood_fill(t_copy, starting_point,fill_color,connectivity=0) #  TODO, should fill holes also diagonally\n",
    "    return filled\n",
    "    \n",
    "# is this value(color) on the border of the grid?\n",
    "def is_value_on_border(t,value):\n",
    "    for i in range(0,t.shape[0]):\n",
    "        if (t[i,0]==value): \n",
    "                return True\n",
    "        if (t[i,t.shape[1]-1]==value): \n",
    "                return True\n",
    "    for j in range(0,t.shape[1]):\n",
    "        if (t[0,j]==value): \n",
    "                return True\n",
    "        if (t[t.shape[0]-1,j]==value): \n",
    "                return True         \n",
    "    return False\n",
    "\n",
    "# return the coordinates of all the holes in t. An hole is defined as a region which does not percolate to the border.\n",
    "def flood_scan(t, count_only_background_holes = True):\n",
    "    holes_coordinates = []\n",
    "    t_copy = np.copy(t)\n",
    "    for i in range(0,t.shape[0]):\n",
    "        for j in range(0,t.shape[1]):\n",
    "            filled = fill_holes(t_copy,DUMMY_COLOR,starting_point=(i,j))\n",
    "            if not is_value_on_border(filled,DUMMY_COLOR):\n",
    "                holes_coordinates.append([i,j])\n",
    "    \n",
    "    # remove \"border regions\" inside the grid from the holes coordinates\n",
    "    if count_only_background_holes:\n",
    "        new_holes_coordinates = []\n",
    "        background_color = get_background_color(t)\n",
    "        for point in holes_coordinates:\n",
    "            if (t[point[0],point[1]] == background_color):\n",
    "                new_holes_coordinates.append(point)\n",
    "        return new_holes_coordinates\n",
    "        \n",
    "    return holes_coordinates\n",
    "\n",
    "## REGIONS ######################\n",
    "\n",
    "# detect lines which span the whole grid. Return the associated index.\n",
    "def detect_lines(a): \n",
    "    \n",
    "    lines = {\"h_lines\":[],\"v_lines\":[],\"rd_lines\":[],\"ld_lines\":[]}\n",
    "    try:\n",
    "        for i in range(a.shape[1]):\n",
    "            if np.all(a[:,i]==([a[0,i]]*a.shape[0])):\n",
    "                lines[\"v_lines\"].append(i)\n",
    "\n",
    "        for j in range(a.shape[0]):\n",
    "            if np.all(a[j,:]==([a[j,0]]*a.shape[1])):\n",
    "                lines[\"h_lines\"].append(j) \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    b = np.copy(a)\n",
    "    \n",
    "    for key, value in lines.items():      \n",
    "        if key==\"h_lines\":\n",
    "            b = np.delete(b, value, axis=0)\n",
    "        if key==\"v_lines\":\n",
    "            b = np.delete(b, value, axis=1)\n",
    "        \n",
    "    # eliminate lines which are not real separators\n",
    "    h_lines = []\n",
    "    v_lines = []\n",
    "    \n",
    "    for key, value in lines.items():\n",
    "        for line_index in value:\n",
    "            line_color = 0\n",
    "            if key==\"h_lines\":\n",
    "                line_color = a[line_index,0]\n",
    "                if line_color not in b:\n",
    "                    h_lines.append(line_index)\n",
    "            if key==\"v_lines\":\n",
    "                line_color = a[0,line_index]\n",
    "                if line_color not in b:\n",
    "                    v_lines.append(line_index)\n",
    "        \n",
    "    lines[\"h_lines\"] = h_lines\n",
    "    lines[\"v_lines\"] = v_lines\n",
    "    \n",
    "    return lines\n",
    "\n",
    "# get the number of regions separated by lines (thee lines span the whole grid)\n",
    "# need to pass lines = detect_lines(a)\n",
    "def count_lines_regions(lines): \n",
    "    n_regions = (1+len(lines[\"h_lines\"])) * (1+len(lines[\"v_lines\"]))\n",
    "    return n_regions\n",
    "\n",
    "# return the coordinates of all the regions separated by lines\n",
    "# need to pass lines = detect_lines(a)\n",
    "def detect_regions(a, lines,random_lines=False):\n",
    "    \n",
    "    b = np.full(a.shape,0)\n",
    "    regions = []\n",
    "    \n",
    "    if random_lines: # arbitrary (but all connected) lines, see task 144\n",
    "        #coords = get_random_lines_coords(a)\n",
    "        #b = fill_holes(b,DUMMY_COLOR,starting_point=(coords[0][0],coords[0][1]))\n",
    "        pass\n",
    "    else: # scenario with only h and v straight lines\n",
    "        for row in lines[\"h_lines\"]:\n",
    "            b[row,:] = DUMMY_COLOR\n",
    "        for col in lines[\"v_lines\"]:\n",
    "            b[:,col] = DUMMY_COLOR\n",
    "     \n",
    "    # fill the regions with dummy colors, then find their coordinates\n",
    "    k = 1\n",
    "    used_dummy_colors = []\n",
    "    for x in range(0,b.shape[0]):\n",
    "        for y in range(0,b.shape[1]):\n",
    "            if (b[x,y]!= DUMMY_COLOR) and (not b[x,y] in used_dummy_colors):\n",
    "                b = fill_holes(b,DUMMY_COLOR + k,starting_point=(x,y))\n",
    "                used_dummy_colors.append(DUMMY_COLOR + k)\n",
    "                k += 1\n",
    "       \n",
    "    for colo in used_dummy_colors:        \n",
    "        regions.append(np.argwhere(b == colo).tolist())\n",
    "    \n",
    "    return regions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Entity)\n",
      "--- 0.006622791290283203 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Entity)\")\n",
    "\n",
    "# Fundamental Entity (Tensors, Objects, etc). \n",
    "# Contains all Basic Methods acting on Task Samples.\n",
    "class Entity():\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        self.grid = grid\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        self.attributes = {}\n",
    "        \n",
    "        # Color Related\n",
    "        self.attributes[\"unique_colors\"] = get_unique_colors(self.grid)\n",
    "        self.attributes[\"n_unique_colors\"] = len(self.attributes[\"unique_colors\"])\n",
    "        self.attributes[\"n_unique_non_backg_colors\"] = self.attributes[\"n_unique_colors\"] - 1\n",
    "        self.attributes[\"grid_colors_perc\"] = color_percentage(self.grid)\n",
    "        self.attributes[\"max_color_perc\"] = max(self.attributes[\"grid_colors_perc\"].values()) \n",
    "    \n",
    "        existing_colors = {k: v for k, v in self.attributes[\"grid_colors_perc\"].items() if v > 0}\n",
    "        existing_colors = list(existing_colors.keys())\n",
    "\n",
    "        self.attributes[\"most_common_color\"] = existing_colors[0]\n",
    "        try:\n",
    "            self.attributes[\"second_most_common_color\"] = existing_colors[1]\n",
    "        except:\n",
    "            pass\n",
    "        self.attributes[\"least_common_color\"] = existing_colors[-1]\n",
    "        \n",
    "        # Shape Related\n",
    "        self.attributes[\"grid_shape\"] = self.grid.shape\n",
    "        self.attributes[\"v_shape\"] = self.attributes[\"grid_shape\"][0]\n",
    "        self.attributes[\"h_shape\"] = self.attributes[\"grid_shape\"][1]\n",
    "        if (self.attributes[\"v_shape\"]%2)==0:\n",
    "            self.attributes[\"v_shape_half\"] = self.attributes[\"v_shape\"] // 2\n",
    "        else:\n",
    "            self.attributes[\"v_shape_half\"] = None\n",
    "        if (self.attributes[\"h_shape\"]%2)==0:\n",
    "            self.attributes[\"h_shape_half\"] = self.attributes[\"h_shape\"] // 2\n",
    "        else:\n",
    "            self.attributes[\"h_shape_half\"] = None\n",
    "        if (self.attributes[\"v_shape\"]%2)==0:\n",
    "            self.attributes[\"v_shape_third\"] = self.attributes[\"v_shape\"] // 3\n",
    "        else:\n",
    "            self.attributes[\"v_shape_third\"] = None\n",
    "        if (self.attributes[\"h_shape\"]%2)==0:\n",
    "            self.attributes[\"h_shape_third\"] = self.attributes[\"h_shape\"] // 3 \n",
    "        else:\n",
    "            self.attributes[\"h_shape_third\"] = None\n",
    "        \n",
    "        # Symmetry Related\n",
    "        self.attributes[\"h_symm\"] = horizontal_symmetric(self.grid)\n",
    "        self.attributes[\"v_symm\"] = vertical_symmetric(self.grid)\n",
    "        self.attributes[\"ld_symm\"] = left_diagonal_symmetric(self.grid)\n",
    "        self.attributes[\"rd_symm\"] = right_diagonal_symmetric(self.grid)\n",
    "        \n",
    "        # Object Related\n",
    "        self.attributes[\"top_left_corner\"] = (0,0)\n",
    "        if not self.attributes[\"h_shape_half\"] is None:\n",
    "            self.attributes[\"top_mid_point\"] = (0,self.attributes[\"h_shape_half\"])\n",
    "        else:\n",
    "            self.attributes[\"top_mid_point\"] = None\n",
    "        if not self.attributes[\"v_shape_half\"] is None:\n",
    "            self.attributes[\"left_mid_point\"] = (self.attributes[\"v_shape_half\"],0)\n",
    "        else:\n",
    "            self.attributes[\"left_mid_point\"] = None\n",
    "            \n",
    "        self.attributes[\"lines\"] = detect_lines(self.grid)\n",
    "        \n",
    "    \n",
    "class Obj(Entity):\n",
    "    \n",
    "    def __init__(self, parent_grid, obj_coords_in_parent_grid):            \n",
    "        obj_data = matrix_rect(obj_coords_in_parent_grid)  \n",
    "        self.obj_data = obj_data\n",
    "        new_obj = np.full((obj_data[\"x_dim\"], obj_data[\"y_dim\"]), 0) # TODO here 0 should be background color\n",
    "        # the object is always embedded in a rectangolar grid for simplicity\n",
    "        for i in range(obj_data[\"x_dim\"]):\n",
    "            for j in range(obj_data[\"y_dim\"]):\n",
    "                new_obj[i,j] = (parent_grid[obj_data[\"x_min\"] + i, obj_data[\"y_min\"] + j])\n",
    "                \n",
    "        super().__init__(new_obj) # define the entity with the object grid\n",
    "        self.parent_grid = parent_grid\n",
    "        self.coords = obj_coords_in_parent_grid  # these coordinates are exact, so in general it is not a rectangle\n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "        \n",
    "        self.attributes[\"has_hole\"] = False\n",
    "        self.attributes[\"holes_coords_obj\"] = None # coords with respect to the object\n",
    "        self.attributes[\"holes_coords_parent\"] = None # coords with respect to the parent\n",
    "        if len(self.coords) != self.grid.size: \n",
    "            holes_coords = flood_scan(self.grid)\n",
    "            self.attributes[\"has_hole\"] = len(holes_coords) > 0\n",
    "            if self.attributes[\"has_hole\"]:\n",
    "                self.attributes[\"holes_coords_obj\"] = holes_coords\n",
    "                self.attributes[\"holes_coords_parent\"] = [[x + self.obj_data[\"x_min\"],y + self.obj_data[\"y_min\"]] for x,y in holes_coords]\n",
    "                \n",
    "class Region(Entity):\n",
    "    \n",
    "    def __init__(self, parent_grid, reg_coords_in_parent_grid):            \n",
    "        reg_data = matrix_rect(reg_coords_in_parent_grid)   \n",
    "        new_region = np.full((reg_data[\"x_dim\"], reg_data[\"y_dim\"]), 0) \n",
    "        for i in range(reg_data[\"x_dim\"]):\n",
    "            for j in range(reg_data[\"y_dim\"]):\n",
    "                new_region[i,j] = (parent_grid[reg_data[\"x_min\"] + i, reg_data[\"y_min\"] + j])\n",
    "    \n",
    "        super().__init__(new_region) \n",
    "        self.parent_grid = parent_grid\n",
    "        self.coords = reg_coords_in_parent_grid  \n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "        \n",
    "# Contains Entire Data for Input/Output\n",
    "class Tensor(Entity):\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        super().__init__(grid)\n",
    "        self.objects = []\n",
    "        self.regions = [] \n",
    "        self.layers = [] # TODO\n",
    "        \n",
    "        \n",
    "    # detect objects, layer and regions\n",
    "    def detect_entities(self):\n",
    "        objects_coords = detect_objects(self.grid)\n",
    "        for obj_coords in objects_coords:\n",
    "            self.objects.append(Obj(self.grid,obj_coords))\n",
    "        \n",
    "        regions_coords = detect_regions(self.grid, self.attributes[\"lines\"])\n",
    "        for region_coords in regions_coords:\n",
    "            self.regions.append(Region(self.grid,region_coords))\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        # compute the attributes of the whole grid\n",
    "        super().compute_attributes()  \n",
    "        # find the entities (objects, layer and regions)\n",
    "        self.detect_entities()\n",
    "        \n",
    "        # compute the attributes of the objects in the grid\n",
    "        for obj in self.objects:\n",
    "            obj.compute_attributes()\n",
    "        # compute the attributes of the whole grid referred to entities\n",
    "        self.attributes[\"n_objects\"] = len(self.objects)\n",
    "        \n",
    "        for region in self.regions:\n",
    "            region.compute_attributes()\n",
    "        self.attributes[\"n_regions\"] = len(self.regions)\n",
    "            \n",
    "\n",
    "# Fundamental Class for ALL Tasks\n",
    "# Contains all Basic Methods acting on Tasks.\n",
    "class Task():\n",
    "    \n",
    "    def __init__(self, train_data, test_data, LB_submission=False):\n",
    "        \n",
    "        # Lists of Train/Test Tensors\n",
    "        self.train_tensors = [] # Explicitly:  [[t_in_1,t_out_1],[t_in_2,t_out_2],...\n",
    "        self.train_diff = []  # For every in-out pair, difference between in and out attributes\n",
    "        self.common_diff = {} # For all the in-out pairs, common differences (Example: All of the in-out pairs change color)\n",
    "        self.sequences = {} # Sequences or patterns among all the in-out pairs \n",
    "        self.test_tensors = []\n",
    "        self.LB_submission = LB_submission\n",
    "        \n",
    "        # Compute Train Tensors\n",
    "        for t_in, t_out in train_data:\n",
    "            tensor_in = Tensor(t_in)\n",
    "            tensor_out = Tensor(t_out)\n",
    "            list.append(self.train_tensors, [tensor_in, tensor_out])\n",
    "            \n",
    "        # Compute Test Tensors\n",
    "        if self.LB_submission:\n",
    "            for t_in in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                list.append(self.test_tensors, [tensor_in])\n",
    "        else:\n",
    "            for t_in, t_out in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                tensor_out = Tensor(t_out)\n",
    "                list.append(self.test_tensors, [tensor_in, tensor_out])\n",
    "        \n",
    "           \n",
    "    # Compute Task Train Attributes \n",
    "    def compute_train_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            for t in in_out_pair:\n",
    "                t.compute_attributes()\n",
    "    \n",
    "    # Compute Task Test Attributes \n",
    "    def compute_test_attributes(self):\n",
    "        if self.LB_submission:\n",
    "            for t in self.test_tensors:\n",
    "                t[0].compute_attributes()\n",
    "        else:\n",
    "            for in_out_pair in self.test_tensors:\n",
    "                for t in in_out_pair:\n",
    "                    t.compute_attributes()\n",
    "    \n",
    "    # Compute Attribute Differences for every in-out pair\n",
    "    def compute_diff_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            diff = {}\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            \n",
    "            # Color Related\n",
    "            diff[\"color_changed\"] = set(t_in.attributes[\"unique_colors\"]) != set(t_out.attributes[\"unique_colors\"])\n",
    "            diff[\"new_colors\"] = list(set(t_out.attributes[\"unique_colors\"]) - set(t_in.attributes[\"unique_colors\"]))\n",
    "            \n",
    "            keylist = t_in.attributes[\"grid_colors_perc\"].keys()\n",
    "            color_perc_in = np.array([t_in.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            color_perc_out = np.array([t_out.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            diff[\"color_perc_changed\"] = not np.allclose(color_perc_in, color_perc_out)\n",
    "            \n",
    "            diff[\"most_common_color_changed\"] = t_in.attributes[\"most_common_color\"] != t_out.attributes[\"most_common_color\"]\n",
    "            try:\n",
    "                diff[\"second_most_common_color_changed\"] = t_in.attributes[\"second_most_common_color\"] != t_out.attributes[\"second_most_common_color\"]\n",
    "            except:\n",
    "                pass\n",
    "            diff[\"least_common_color_changed\"] = t_in.attributes[\"least_common_color\"] != t_out.attributes[\"least_common_color\"]\n",
    "            \n",
    "            # Shape Related\n",
    "            diff[\"shape_changed\"] = t_in.attributes[\"grid_shape\"] != t_out.attributes[\"grid_shape\"]\n",
    "            diff[\"h_shape_changed\"] = t_in.attributes[\"grid_shape\"][1] != t_out.attributes[\"grid_shape\"][1]\n",
    "            diff[\"v_shape_changed\"] = t_in.attributes[\"grid_shape\"][0] != t_out.attributes[\"grid_shape\"][0]\n",
    "           \n",
    "            \n",
    "            # Symmetry Related\n",
    "            diff[\"h_symm_changed\"] = t_in.attributes[\"h_symm\"] != t_out.attributes[\"h_symm\"]\n",
    "            diff[\"v_symm_changed\"] = t_in.attributes[\"v_symm\"] != t_out.attributes[\"v_symm\"]\n",
    "            diff[\"ld_symm_changed\"] = t_in.attributes[\"ld_symm\"] != t_out.attributes[\"ld_symm\"]\n",
    "            diff[\"rd_symm_changed\"] = t_in.attributes[\"rd_symm\"] != t_out.attributes[\"rd_symm\"]\n",
    "            \n",
    "            # Objects Related\n",
    "            # diff[\"n_objects_changed\"] = t_in.attributes[\"n_objects\"] != t_out.attributes[\"n_objects\"]\n",
    "            \n",
    "            # Other\n",
    "            diff[\"is_in_in_out\"] = match_template(t_out.grid, t_in.grid)\n",
    "            diff[\"is_out_in_in\"] = match_template(t_in.grid, t_out.grid)\n",
    "            \n",
    "            \n",
    "            list.append(self.train_diff,diff)\n",
    "        \n",
    "    # Find Common Differences in Input/Output Pairs. Return a dict \"diff\":int, such as {'color_changed': -1, 'color_perc_changed': 1, 'shape_changed': 1}.\n",
    "    def find_common_diff(self):\n",
    "        \n",
    "        diffs = self.train_diff[0].keys()\n",
    "        \n",
    "        for k in diffs:\n",
    "            try:\n",
    "                truth_values = []\n",
    "                for i, diff in enumerate(self.train_diff): \n",
    "                    truth_values.append(diff[k])\n",
    "\n",
    "                if all(truth_values): \n",
    "                    self.common_diff[k] = 1 # this difference k is common in all the in-out pairs and it is True.\n",
    "                elif (not all(truth_values)) and (not any(truth_values)):\n",
    "                    self.common_diff[k] = -1 # this difference k is common in all the in-out pairs and it is False.\n",
    "                else:\n",
    "                    self.common_diff[k] = 0 # the difference is not common to all the in-out pairs.\n",
    "            except KeyError as error:\n",
    "                self.common_diff[k] = 0\n",
    "                \n",
    "        \n",
    "    # Find Sequences or patterns in Common Differences or in the outputs. \n",
    "    # For instance a color/shape common to all the outputs.\n",
    "    def find_sequence(self):\n",
    "        \n",
    "        # find which colors do not appear in train input, but appear in all the outputs\n",
    "        common_new_colors = [0,1,2,3,4,5,6,7,8,9]\n",
    "        for in_out_pair in self.train_diff:\n",
    "            common_new_colors = list(set(common_new_colors).intersection(in_out_pair[\"new_colors\"]))\n",
    "        self.sequences[\"common_new_colors\"] = common_new_colors\n",
    "        for i, cnc in enumerate(self.sequences[\"common_new_colors\"]):\n",
    "            self.sequences[\"common_new_colors\" + \"_\" + str(i)] = cnc\n",
    "            \n",
    "        # memorize the shape, if all the output shapes are the same\n",
    "        out_shapes_0 = []\n",
    "        out_shapes_1 = []\n",
    "        in_shapes_0 = []\n",
    "        in_shapes_1 = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            out_shapes_0.append(t_out.grid.shape[0])\n",
    "            out_shapes_1.append(t_out.grid.shape[1])\n",
    "            in_shapes_0.append(t_in.grid.shape[0])\n",
    "            in_shapes_1.append(t_in.grid.shape[1])\n",
    "        self.sequences[\"out_shape_0\"] = -1\n",
    "        self.sequences[\"out_shape_1\"] = -1\n",
    "        if checkEqual1(out_shapes_0):\n",
    "            self.sequences[\"out_shape_0\"] = out_shapes_0[0]\n",
    "        if checkEqual1(out_shapes_1):\n",
    "            self.sequences[\"out_shape_1\"] = out_shapes_1[0]\n",
    "        self.sequences[\"max_in_shape\"] = max(in_shapes_0 + in_shapes_1)\n",
    "        self.sequences[\"min_in_shape\"] = min(in_shapes_0 + in_shapes_1)\n",
    "        self.sequences[\"max_out_shape\"] = max(out_shapes_0 + out_shapes_1)\n",
    "        self.sequences[\"min_out_shape\"] = min(out_shapes_0 + out_shapes_1)\n",
    "        self.sequences[\"prime_in_shape_0\"] = any(is_prime(ele) for ele in in_shapes_0)\n",
    "        self.sequences[\"prime_in_shape_1\"] = any(is_prime(ele) for ele in in_shapes_1)\n",
    "            \n",
    "            \n",
    "         \n",
    "        # check if all the outputs have the same number of colors\n",
    "        n_colors = []\n",
    "        for in_out_pair in task_data.train_tensors:\n",
    "            t_out = in_out_pair[1]\n",
    "            n_colors.append(t_out.attributes[\"n_unique_colors\"])\n",
    "        self.sequences[\"n_colors\"] = 0\n",
    "        if checkEqual1(n_colors):\n",
    "            self.sequences[\"n_colors\"] = n_colors[0]\n",
    "            \n",
    "        # check in and out objects\n",
    "        in_objs = []\n",
    "        out_objs = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_objs.append(t_in.objects)\n",
    "            out_objs.append(t_out.objects)\n",
    "        self.sequences[\"max_n_objects_in\"] = checkMaxMinLen(in_objs)[\"max_len\"]\n",
    "        self.sequences[\"min_n_objects_in\"] = checkMaxMinLen(in_objs)[\"min_len\"]\n",
    "        self.sequences[\"max_n_objects_out\"] = checkMaxMinLen(out_objs)[\"max_len\"]\n",
    "        self.sequences[\"min_n_objects_out\"] = checkMaxMinLen(out_objs)[\"min_len\"]\n",
    "              \n",
    "            \n",
    "        # check in and out regions\n",
    "        in_regions = []\n",
    "        out_regions = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_regions.append(t_in.regions)\n",
    "            out_regions.append(t_out.regions)\n",
    "        self.sequences[\"max_n_regions_in\"] = checkMaxMinLen(in_regions)[\"max_len\"]\n",
    "        self.sequences[\"min_n_regions_in\"] = checkMaxMinLen(in_regions)[\"min_len\"]\n",
    "        self.sequences[\"max_n_regions_out\"] = checkMaxMinLen(out_regions)[\"max_len\"]\n",
    "        self.sequences[\"min_n_regions_out\"] = checkMaxMinLen(out_regions)[\"min_len\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # check in and out color_perc\n",
    "        in_cp = []\n",
    "        out_cp = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_cp.append(t_in.attributes[\"max_color_perc\"])\n",
    "            out_cp.append(t_out.attributes[\"max_color_perc\"])\n",
    "        self.sequences[\"max_max_color_perc_in\"] = max(in_cp)\n",
    "        self.sequences[\"min_max_color_perc_in\"] = min(in_cp)\n",
    "        self.sequences[\"max_max_color_perc_out\"] = max(out_cp)\n",
    "        self.sequences[\"min_max_color_perc_out\"] = min(out_cp)\n",
    "            \n",
    "        \n",
    "                               \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Rotates) ...\n",
      "--- 0.0004830360412597656 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Rotates) ...\")\n",
    "\n",
    "# Rotate Image 90 Degrees\n",
    "def rotate_1(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 1, axes=(0,1))\n",
    "\n",
    "# Rotate Image 180 Degrees\n",
    "def rotate_2(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 2, axes=(0,1))\n",
    "\n",
    "# Rotate Image 270 Degrees\n",
    "def rotate_3(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 3, axes=(0,1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Flips) ...\n",
      "--- 0.0008046627044677734 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Flips) ...\")\n",
    "\n",
    "# Flip Image Along X-Axis\n",
    "def flip_1(a, a_t, task_data, *args):\n",
    "    return np.flip(a, 0)\n",
    "\n",
    "# Flip Image Along Y-Axis\n",
    "def flip_2(a, a_t, task_data, *args):\n",
    "    return np.flip(a, 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Mirrors) ...\n",
      "--- 0.0018639564514160156 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Mirrors) ...\")\n",
    "\n",
    "# Mirror Image Along Top Side of Frame\n",
    "def mirror_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=0), a), axis=0)\n",
    "\n",
    "# Mirror Image Along Right Side of Frame\n",
    "def mirror_2(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=1)), axis=1)\n",
    "\n",
    "# Mirror Image Along Bottom Side of Frame\n",
    "def mirror_3(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=0)), axis=0)\n",
    "\n",
    "# Mirror Image Along Left Side of Frame\n",
    "def mirror_4(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=1), a), axis=1)  \n",
    "\n",
    "# Get Transpose of Image\n",
    "def mirror_5(a, a_t, task_data, *args):\n",
    "    return a.T\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.001138925552368164 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Duplicate Original grid args[0] times vertically and args[1] horizontally\n",
    "def repeat_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.tile(a,(args[0],args[1]))\n",
    "\n",
    "# Repeat the grid, only in correspondents of positions where there are non background colors\n",
    "def repeat_2(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * a.shape[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * a.shape[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    c = np.tile(a, a.shape)\n",
    "    c_mask = a.repeat(a.shape[0], axis=0).repeat(a.shape[1], axis=1)\n",
    "    return c & c_mask\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.002839803695678711 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Elastically rescales up grid args[0] times vertically and args[1] horizontally\n",
    "def rescale_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.kron(a, np.ones((args[0],args[1]), dtype=np.uint8)) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Crop) ...\n",
      "--- 0.0007569789886474609 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Crop) ...\")\n",
    "\n",
    "# Crop using the coordinates of a color as a reference.\n",
    "def crop_1(a, a_t, task_data, *args):\n",
    "    color = args[0]\n",
    "    coords = np.argwhere(a==color)\n",
    "    x_min, y_min = coords.min(axis=0)\n",
    "    x_max, y_max = coords.max(axis=0)\n",
    "    return a[x_min:x_max+1, y_min:y_max+1]\n",
    "    \n",
    "    \n",
    "# Crop using the top left corner and two dimensions\n",
    "def crop_2(a, a_t, task_data, *args):\n",
    "    shape_v = args[0]\n",
    "    shape_h = args[1]\n",
    "    top_left_coords = args[2]\n",
    "    if ((top_left_coords[0]  + shape_v) > a.shape[0]) or ((top_left_coords[1]  + shape_h) > a.shape[1]):\n",
    "        #print(\"Out of bounds B\", shape_v ,shape_h ,top_left_coords, a.shape[0], a.shape[1])\n",
    "        raise ValueError(\"Out of bounds\")  \n",
    "    return a[top_left_coords[0]:top_left_coords[0]+shape_v, top_left_coords[1]:top_left_coords[1]+shape_h]\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Symmetric) ...\n",
      "--- 0.0007572174072265625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Symmetric) ...\")\n",
    "\n",
    "# Make Image Symmetric Along X-Axis\n",
    "def symmetric_1(a, a_t, task_data, *args):\n",
    "    b1 = flip_1(a, a_t, task_data, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "# Make Image Symmetric Along Y-Axis\n",
    "def symmetric_2(a, a_t, task_data, *args):\n",
    "    b1 = flip_2(a, a_t, task_data, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Color) ...\n",
      "--- 0.0017070770263671875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Color) ...\")\n",
    "\n",
    "# Substitute Color1 with Color2 (NOT viceversa) \n",
    "def color_1(a, a_t, task_data, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    a[b_first] = color2\n",
    "    return a \n",
    "\n",
    "# Swap Color1 with Color2 and Color2 with Color1\n",
    "def color_2(a, a_t, task_data, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    b_second = a == color2\n",
    "    a[b_first] = color2\n",
    "    a[b_second] = color1\n",
    "    return a\n",
    "\n",
    "# Substitute all colors different from Color1 with Color2 (NOT viceversa) \n",
    "def color_3(a, a_t, task_data, *args):\n",
    "    if (len(get_unique_colors(a)) < 3):\n",
    "        raise ValueError(\"Not enough colors in this grid\")\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a != color1\n",
    "    a[b_first] = color2\n",
    "    return a\n",
    "\n",
    "# Color objects with a given attribute\n",
    "def color_ob(a, a_t, task_data, key ,*args):\n",
    "    new_color = args[0]\n",
    "    objs_to_color = []\n",
    "    for obj in a_t.objects:\n",
    "        if obj.attributes[key]:\n",
    "            objs_to_color.append(obj)\n",
    "            \n",
    "    if (len(objs_to_color) == 0):\n",
    "        raise ValueError(\"No objects to color\")\n",
    "      \n",
    "    for obj in objs_to_color:\n",
    "        a = color_points(a,obj.coords,new_color)\n",
    "    return a\n",
    "\n",
    "# Color objects with holes in them\n",
    "def color_ob_1(a, a_t, task_data, *args):\n",
    "    return color_ob(a, a_t, task_data,\"has_hole\",*args)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Superpose) ...\n",
      "--- 0.008308887481689453 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Superpose) ...\")\n",
    "\n",
    "\n",
    "\n",
    "# superpose all the regions with an operation given by op. Here the regions are just inferred from splicing the grid.\n",
    "def superp(a, a_t, task_data,*args,op=\"AND\",axis=0):\n",
    "    \n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    n_regions = args[2]\n",
    "    if (n_regions > 5):\n",
    "        raise ValueError(\"Too many regions\")\n",
    "    axis = axis #args[3] # 0 or 1\n",
    "    regions = np.split(a,n_regions,axis=axis)\n",
    "    for previous, current in zip(regions, regions[1:]):\n",
    "        if op==\"AND\":\n",
    "            b = np.where((previous !=background_color) & (current !=background_color), new_color, background_color)\n",
    "        if op==\"OR\":\n",
    "            b = np.where((previous !=background_color) | (current !=background_color), new_color, background_color)\n",
    "        if op==\"XOR\":\n",
    "            b = np.where((previous !=background_color) ^ (current !=background_color), new_color, background_color)\n",
    "        if op==\"ADD\":\n",
    "            b =  np.where((previous + current) < 10, previous + current, background_color)\n",
    "    return b\n",
    "\n",
    "def superp_1(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"AND\",axis=0)\n",
    "def superp_2(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"OR\",axis=0)\n",
    "def superp_3(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"XOR\",axis=0)\n",
    "def superp_4(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"ADD\",axis=0)\n",
    "def superp_5(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"AND\",axis=1)\n",
    "def superp_6(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"OR\",axis=1)\n",
    "def superp_7(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"XOR\",axis=1)\n",
    "def superp_8(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"ADD\",axis=1)\n",
    "\n",
    "# superpose all the regions with an operation given by op\n",
    "def superp_reg(a, a_t, task_data,*args, key=None, op=\"AND\"):\n",
    "    \n",
    "    b = black_square\n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    for previous, current in zip(a_t.regions, a_t.regions[1:]):\n",
    "        if not (key is None):\n",
    "            pass\n",
    "        else:\n",
    "            if op==\"AND\":\n",
    "                b = np.where((previous.grid !=background_color) & (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"OR\":\n",
    "                b = np.where((previous.grid !=background_color) | (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"XOR\":\n",
    "                b = np.where((previous.grid !=background_color) ^ (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"ADD\":\n",
    "                b =  np.where((previous.grid + current.grid) < 10, previous.grid + current.grid, background_color)\n",
    "    return b\n",
    "\n",
    "\n",
    "def superp_reg_1(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"AND\")\n",
    "def superp_reg_2(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"OR\")\n",
    "def superp_reg_3(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"XOR\")\n",
    "def superp_reg_4(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"ADD\")\n",
    "        \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Draw) ...\n",
      "--- 0.0008590221405029297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Draw) ...\")\n",
    "\n",
    "# superpose all the regions with an operation given by op\n",
    "def draw_reg(a, a_t, task_data,*args, key=\"most_common_color\"):\n",
    "    \n",
    "    lines = a_t.attributes[\"lines\"]\n",
    "    n_h_lines = len(lines[\"h_lines\"])\n",
    "    n_v_lines = len(lines[\"v_lines\"])\n",
    "    \n",
    "    b = np.full((n_h_lines +1, n_v_lines +1),0)\n",
    "    i = 0\n",
    "    for x in range(0,n_h_lines +1):\n",
    "        for y in range(0,n_v_lines +1): \n",
    "            b[x,y] = a_t.regions[i].attributes[key]\n",
    "            i +=1\n",
    "    \n",
    "    return b\n",
    "\n",
    "def draw_reg_1(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"most_common_color\")\n",
    "def draw_reg_2(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"second_most_common_color\")\n",
    "def draw_reg_3(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"least_common_color\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Special) ...\n",
      "--- 0.0005249977111816406 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Special) ...\")\n",
    "\n",
    "# create a uniformely colored new grid from scratch\n",
    "def special_1(a, a_t, task_data, *args):\n",
    "    color = args[0]\n",
    "    shape_v = args[1]\n",
    "    shape_h = args[2]\n",
    "    if (color > 9):\n",
    "        raise ValueError(\"Bad color!\")\n",
    "    return np.full((shape_v,shape_h), color, dtype=np.uint8)\n",
    "\n",
    "\n",
    "# fill holes in the objects\n",
    "def special_2(a, a_t, task_data, *args):\n",
    "    \n",
    "    fill_color = args[0]\n",
    "    objs = a_t.objects\n",
    "    if len(objs) == 0:\n",
    "        raise ValueError(\"No Objects!\")\n",
    "    for ob in objs:\n",
    "        if ob.attributes[\"has_hole\"]:\n",
    "            for hole_coord in ob.attributes[\"holes_coords_parent\"]:\n",
    "                if (a[hole_coord[0],hole_coord[1]] != fill_color):\n",
    "                    a = fill_holes(a,fill_color,starting_point=tuple(hole_coord))\n",
    "            \n",
    "    return a       \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine DSL Functions ...\n",
      "DSL_fs_names  ['rotate_1', 'rotate_2', 'rotate_3', 'flip_1', 'flip_2', 'mirror_1', 'mirror_2', 'mirror_3', 'mirror_4', 'mirror_5', 'repeat_1', 'repeat_2', 'rescale_1', 'crop_1', 'crop_2', 'symmetric_1', 'symmetric_2', 'color_1', 'color_2', 'color_3', 'color_ob_1', 'superp_1', 'superp_2', 'superp_3', 'superp_4', 'superp_5', 'superp_6', 'superp_7', 'superp_8', 'superp_reg_1', 'superp_reg_2', 'superp_reg_3', 'superp_reg_4', 'draw_reg_1', 'draw_reg_2', 'draw_reg_3', 'special_1', 'special_2']\n",
      "Total number of functions:  38\n",
      "--- 0.0028018951416015625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Combine DSL Functions ...\")\n",
    "\n",
    "rotate = [rotate_1, rotate_2, rotate_3\n",
    "         ]\n",
    "flip = [flip_1, flip_2\n",
    "       ]\n",
    "mirror = [mirror_1,mirror_2,mirror_3,mirror_4,mirror_5]\n",
    "repeat = [repeat_1, repeat_2]\n",
    "rescale = [rescale_1]\n",
    "crop = [\n",
    "    crop_1, \n",
    "    crop_2\n",
    "]\n",
    "symmetric = [symmetric_1, symmetric_2]\n",
    "color = [color_1, color_2, color_3, color_ob_1\n",
    "        ]\n",
    "\n",
    "superpose = [superp_1, superp_2, superp_3, superp_4,superp_5, superp_6, superp_7, superp_8, superp_reg_1,superp_reg_2,superp_reg_3,superp_reg_4]\n",
    "draw = [draw_reg_1,draw_reg_2,draw_reg_3]\n",
    "special = [special_1, special_2]\n",
    "\n",
    "DSL_functions =  rotate + flip + mirror + repeat + rescale + crop + symmetric + color + superpose + draw + special \n",
    "DSL_fs_names = [f.__name__ for f in DSL_functions]\n",
    "print(\"DSL_fs_names \", DSL_fs_names)\n",
    "print(\"Total number of functions: \", len(DSL_functions))\n",
    "\n",
    "# Return True if the new_function should not compose with the current_functions\n",
    "def forbidden_composition(new_function, current_functions):\n",
    "    \n",
    "    f_names = [f.__name__ for f in current_functions]\n",
    "    new_f_names = [f.__name__ for f in new_function]\n",
    "    # avoid crop_1, crop_2 or crop_1, crop_1 combos.\n",
    "    forbidden_combos = [\"crop\", \"rescale\", \"repeat\"]\n",
    "    \n",
    "    for keyword in forbidden_combos:\n",
    "        if (keyword in '\\t'.join(new_f_names)) and (keyword in '\\t'.join(f_names)):\n",
    "            return True\n",
    "        \n",
    "    functions_that_must_go_first = [\"repeat_2\",\"special_2\", \"crop_2\",\"color_ob_1\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\n",
    "                                   \"draw_reg_1\",\"draw_reg_2\",\"draw_reg_3\",\n",
    "                                   \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"]\n",
    "    for keyword in functions_that_must_go_first:\n",
    "        if (keyword in '\\t'.join(new_f_names)):\n",
    "            return True\n",
    "      \n",
    "    functions_that_must_go_alone = [\"special_1\",\"color_3\"]\n",
    "    for keyword in functions_that_must_go_alone:\n",
    "        if ((keyword in '\\t'.join(new_f_names)) or (keyword in '\\t'.join(f_names)) ):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Actions ...\n",
      "--- 0.0019459724426269531 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Actions ...\")\n",
    "\n",
    "# Return the action is defined by the dict above. Put \"UNDEF\" is the function may or may not change the attribute.\n",
    "# Notice that some \"UNDEF\" actions can actually be defined if we add more info.\n",
    "def get_functions_actions(entity):\n",
    "    \n",
    "    shape = entity.attributes[\"grid_shape\"]\n",
    "    is_a_square =  shape[0] == shape[1]\n",
    "    is_h_symm = entity.attributes[\"h_symm\"]\n",
    "    is_v_symm = entity.attributes[\"v_symm\"]\n",
    "    \n",
    "    go_from_h_symm_to_v_or_viceversa = ((is_h_symm) and (not is_v_symm)) or ((is_v_symm) and (not is_h_symm))\n",
    "    \n",
    "    functions_actions = {\n",
    "    \"rotate_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\": not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}, \n",
    "    \"rotate_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"rotate_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}, \n",
    "    \"flip_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"flip_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_4\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_5\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"repeat_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"repeat_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"rescale_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"crop_1\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"crop_2\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"symmetric_1\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":not is_h_symm,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"symmetric_2\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":not is_v_symm,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"color_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_ob_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_4\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_5\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_6\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_7\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_8\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_4\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"special_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":\"UNDEF\",\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"special_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}\n",
    "                   }\n",
    "    return functions_actions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Filtering ...\n",
      "--- 0.0016770362854003906 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Filtering ...\")\n",
    "\n",
    "# Filter the functions which will enter the generate loops. Run over all the test_in and take only the functions that are compatible with all the test_in.\n",
    "def function_filter(task_data, fs_names):\n",
    "\n",
    "    test_t_ins = task_data.test_tensors\n",
    "    functions_to_select = fs_names\n",
    "    functions_removed = []\n",
    "    \n",
    "    for t_in in test_t_ins:\n",
    "        \n",
    "        functions_actions = get_functions_actions(t_in[0])\n",
    "        diff = task_data.common_diff\n",
    "        \n",
    "        d1 = [\"color_changed\",\"color_perc_changed\",\"most_common_color_changed\",\"second_most_common_color_changed\",\"least_common_color_changed\",\"shape_changed\",\"h_shape_changed\",\"v_shape_changed\"]\n",
    "        d2 = [\"new_colors\", \"h_symm_changed\",\"v_symm_changed\",\"ld_symm_changed\",\"rd_symm_changed\",\"is_in_in_out\", \"is_out_in_in\"] \n",
    "        print(\"diff\",diff)\n",
    "        d_final =  [x for x in list(diff.keys()) if x not in d2]\n",
    "\n",
    "        # remove the functions (from the list of all function) which make undesired changes. \n",
    "        for f,v in functions_actions.items():\n",
    "            \n",
    "            for diff_name in d_final:\n",
    "                if diff[diff_name]==-1: # Example: if the task is preserving the color. \n",
    "                    if v[diff_name]==True: # Example: check if the function modifies colors. Explicit ==True check is important here.\n",
    "                        if f in functions_to_select: \n",
    "                            functions_removed.append(f) # Example: If so, remove function which modify colors.\n",
    "           \n",
    "    # if the outputs are not mono-color\n",
    "    if task_data.sequences[\"n_colors\"] ==1:\n",
    "        functions_removed.extend([\"special_2\", \"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "    else:\n",
    "        functions_removed.append(\"special_1\")\n",
    "      \n",
    "    # if out is always in in, the solution is likely crop or similar\n",
    "    if diff[\"is_out_in_in\"]==1:\n",
    "        functions_removed.extend(set(fs_names) - set([\"crop_1\",\"crop_2\",\"special_1\"]))\n",
    "        \n",
    "    # if in is very small\n",
    "    if (task_data.sequences[\"max_in_shape\"]<6):\n",
    "        functions_removed.extend([\"special_2\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "        \n",
    "    # if out is very small\n",
    "    if (task_data.sequences[\"out_shape_0\"]!=-1) and (task_data.sequences[\"out_shape_0\"]<3) and (task_data.sequences[\"out_shape_1\"]!=-1) and (task_data.sequences[\"out_shape_1\"]<3) :\n",
    "        functions_removed.extend([\"rescale_1\",\"repeat_1\",\"mirror_1\",\"mirror_2\",\"mirror_3\",\"mirror_4\"])\n",
    "     \n",
    "    # if out is only 1 dim\n",
    "    if (task_data.sequences[\"min_out_shape\"]==1):\n",
    "        functions_removed.extend([\"special_2\", \"repeat_1\",\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "    \n",
    "    # if out is very large\n",
    "    if (task_data.sequences[\"out_shape_0\"]>13) and (task_data.sequences[\"out_shape_1\"]>13):\n",
    "        functions_removed.extend([\"crop_1\",\"crop_2\",\"special_1\"])\n",
    "        \n",
    "    # if out is bigger than in\n",
    "    if (task_data.sequences[\"min_out_shape\"] > task_data.sequences[\"max_in_shape\"]):\n",
    "        functions_removed.extend([\"special_1\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "        \n",
    "    # if there aren't at least 2 objects in all the inputs\n",
    "    if task_data.sequences[\"min_n_objects_in\"] < 2:\n",
    "        functions_removed.extend([\"color_ob_1\"])\n",
    "        \n",
    "    # if there are many objects in input\n",
    "    if task_data.sequences[\"min_n_objects_in\"] > 3:\n",
    "        functions_removed.extend([\"special_1\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "        \n",
    "    # if there aren't at least 2 regions in all the inputs\n",
    "    if task_data.sequences[\"min_n_regions_in\"] < 2:\n",
    "        functions_removed.extend([\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\"draw_reg_1\",\"draw_reg_2\",\"draw_reg_3\"])\n",
    "    else:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "     \n",
    "    # if the input dimension is not divisible\n",
    "    if task_data.sequences[\"prime_in_shape_0\"]:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\"])\n",
    "    if task_data.sequences[\"prime_in_shape_1\"]:\n",
    "        functions_removed.extend([\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "        \n",
    "    # if the input is mainly background\n",
    "    if task_data.sequences[\"min_max_color_perc_in\"] > 0.7:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\"])\n",
    "   \n",
    "    print(\"functions removed\", set(functions_removed))\n",
    "    functions_to_select = [item for item in fs_names if item not in functions_removed]\n",
    "    functions_to_select = [func for func in DSL_functions if func.__name__ in functions_to_select] # convert from string to function\n",
    "    return functions_to_select\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic Numbers ...\n",
      "--- 0.002804994583129883 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Magic Numbers ...\")\n",
    "\n",
    "# How many additional arguments every functions is taking, for each kind of argument. The order is important here.\n",
    "fs_argument_structure = {\n",
    "\"rotate_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0}, \n",
    "    \"rotate_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"rotate_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"flip_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"flip_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_4\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_5\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"repeat_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"repeat_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"rescale_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_2\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":1,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"symmetric_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"symmetric_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_1\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_2\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_3\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_ob_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_1\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_2\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_3\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_4\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_5\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_6\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_7\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_8\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_1\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_2\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_3\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_4\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"special_1\":{\"color_related\":1, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"special_2\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0}\n",
    "                    }\n",
    "\n",
    "# how many magic arguments this function takes\n",
    "def number_of_magic_arguments(function):\n",
    "    args = fs_argument_structure[function.__name__]\n",
    "    return sum(args.values())\n",
    "\n",
    "# helper to get_magic_numbers from a single tensor. Only color related magic numbers.\n",
    "def get_magic_numbers_color_single(t, magic_numbers_colors):\n",
    "    #colors_perc = t.attributes[\"grid_colors_perc\"] \n",
    "    magic_numbers_colors.append(t.attributes[\"most_common_color\"])\n",
    "    try:\n",
    "        magic_numbers_colors.append(t.attributes[\"second_most_common_color\"])\n",
    "    except:\n",
    "        pass\n",
    "    magic_numbers_colors.append(t.attributes[\"least_common_color\"])\n",
    "    \n",
    "    return magic_numbers_colors \n",
    "\n",
    "# helper\n",
    "def compute_shape_variations(diff,direction, magic_numbers_shape, t_out_shape, t_in_shape): \n",
    "    # append ratios and differences. This is useful for functions like repeat, crop and resize.\n",
    "    if diff:\n",
    "        ratio_1 = t_out_shape[direction]//t_in_shape[direction]\n",
    "        ratio_2 = t_in_shape[direction]//t_out_shape[direction]\n",
    "        diff_1 = t_out_shape[direction]-t_in_shape[direction]\n",
    "        diff_2 = t_in_shape[direction]-t_out_shape[direction]\n",
    "        \n",
    "        if (ratio_1 > 1) and ((t_out_shape[direction]%t_in_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_1)\n",
    "        if (ratio_2 > 1) and ((t_in_shape[direction]%t_out_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_2)\n",
    "        if diff_1 > 0:\n",
    "            magic_numbers_shape.append(diff_1)\n",
    "        if diff_2 > 0:\n",
    "            magic_numbers_shape.append(diff_2)\n",
    "\n",
    "# helper to get_magic_numbers from a pair of tensors. Only shape related magic numbers.\n",
    "def get_magic_numbers_shape_pair(in_out_pair, magic_numbers_shape,task_data,pair_n):\n",
    "    \n",
    "    t_in = in_out_pair[0]\n",
    "    t_out = in_out_pair[1]\n",
    "    MAX_SHAPE_MAGIC_NUMBER = 10\n",
    "    \n",
    "    t_in_shape = t_in.attributes[\"grid_shape\"] \n",
    "    t_out_shape = t_out.attributes[\"grid_shape\"] \n",
    "    \n",
    "    # do not append t_in shapes, as they should not be predictive\n",
    "    magic_numbers_shape.extend([1,2,3,4]) # these are pretty basic shape numbers always worth trying \n",
    "    magic_numbers_shape.append(t_out_shape[0])\n",
    "    magic_numbers_shape.append(t_out_shape[1])\n",
    "    \n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"h_shape_changed\"],0, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"v_shape_changed\"],1, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    \n",
    "    magic_numbers_shape = [mn for mn in magic_numbers_shape if mn <= MAX_SHAPE_MAGIC_NUMBER]\n",
    "    \n",
    "    return magic_numbers_shape \n",
    "\n",
    "# helper to get_magic_numbers from a pair of tensors. Only object related magic numbers.\n",
    "def get_magic_numbers_object_pair(in_out_pair, magic_numbers_object,task_data,pair_n):\n",
    "    positions_of_out_in_in = task_data.train_diff[pair_n][\"is_out_in_in\"]\n",
    "    if (len(positions_of_out_in_in) < 5): # avoid edge cases in with output is just a pixel, repeated a lot of times in input.\n",
    "        magic_numbers_object.extend(positions_of_out_in_in) \n",
    "    return magic_numbers_object \n",
    "\n",
    "# prepare the magic numbers for all the categories. Example: {'color_related': [0, 2, 3, 4, 6, 8], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "def get_magic_numbers(task_data):\n",
    "    \n",
    "    magic_numbers = {\"color_related\":[], \"shape_related\":[],\"regions_related\":[],\"object_related\":[],\"layer_related\":[],\"axis_related\":[]}\n",
    "    \n",
    "    # get magic numbers from train in-out pairs\n",
    "    for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "        magic_numbers[\"shape_related\"] = get_magic_numbers_shape_pair(in_out_pair, magic_numbers[\"shape_related\"],task_data,pair_n)\n",
    "        magic_numbers[\"object_related\"] = get_magic_numbers_object_pair(in_out_pair, magic_numbers[\"object_related\"],task_data,pair_n)\n",
    "        \n",
    "        for color_n, new_color in enumerate(task_data.sequences[\"common_new_colors\"]): \n",
    "            magic_numbers[\"color_related\"].append(new_color)\n",
    "        for t in in_out_pair:         \n",
    "            magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t, magic_numbers[\"color_related\"])\n",
    "       \n",
    "    # get magic numbers from test in samples\n",
    "    for t in task_data.test_tensors:       \n",
    "        magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t[0], magic_numbers[\"color_related\"])    \n",
    "    \n",
    "    \n",
    "    magic_numbers[\"color_related\"] = list(set(magic_numbers[\"color_related\"]))\n",
    "    magic_numbers[\"shape_related\"] = list(set(magic_numbers[\"shape_related\"]))\n",
    "    magic_numbers[\"object_related\"] = list(set(magic_numbers[\"object_related\"]))\n",
    "    #magic_numbers[\"axis_related\"] = [0,1]\n",
    "    return magic_numbers\n",
    "\n",
    "\n",
    "# return all the possible combinations of lists of arguments. For instance, if the function take 2 color_related arguments\n",
    "# and 1 shape_related argument, the function will return a list like: [ [1,2,3], [1,2,4], ... ] with [c1,c2,s1] as ordering.\n",
    "def prepare_magic_arguments(func, magic_numbers):\n",
    "    \n",
    "    func_argument_structure = fs_argument_structure[func.__name__]\n",
    "    magic_args = {'color_related': [], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "    \n",
    "    for x_related,numbers in magic_numbers.items():\n",
    "        if func_argument_structure[x_related] > 0:\n",
    "            # compute all the possible combinations of arguments of the same kind\n",
    "            magic_args[x_related] = list(itertools.product(numbers, repeat=func_argument_structure[x_related]))\n",
    "    \n",
    "    # assemble the arguments of different categories together\n",
    "    magic_args_lists = []\n",
    "    for k,v in magic_args.items():\n",
    "        if len(v) > 0:\n",
    "            magic_args_lists.append(v)\n",
    "    magic_args_mixed = list(itertools.product(*magic_args_lists))\n",
    "    for i in range(len(magic_args_mixed)):\n",
    "        magic_args_mixed[i] = [y for x in magic_args_mixed[i] for y in (x if isinstance(x, tuple) else (x,))]\n",
    "        \n",
    "    if len(magic_args_mixed) > MAX_magic_args_number : # avoid very lengthy computations\n",
    "        return {'color_related': [], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': [], 'axis_related': []}\n",
    "    return magic_args_mixed \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program():\n",
    "    \n",
    "    def __init__(self, functions=[], sim_score=0, acting_on=\"Tensor\", mn=[]):\n",
    "        self.functions = functions # list of functions. The program is the composition of those.\n",
    "        self.sim_score = sim_score # How well the program scores on the expected output.\n",
    "        self.acting_on = acting_on # Is this acting on a Tensor, an Object, a Layer?\n",
    "        self.task_accuracy = 0  # +1 for every time program maps t_in in t_out\n",
    "        self.magic_numbers = mn # list of lists of magic numbers. Every sublist is associated to a function.\n",
    "        self.magic_logic_understood = False\n",
    "        self.logic_num = [] # array which contain strings explaining the logic of the magic numbers\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.functions==other.functions) and (self.magic_numbers==other.magic_numbers) and (self.magic_logic_understood==other.magic_logic_understood) and (self.logic_num==other.logic_num)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(('functions', ','.join(str(v) for v in self.functions),\n",
    "                     'magic_numbers', ','.join(str(v) for v in self.magic_numbers),\n",
    "                     'magic_logic_understood', str(self.magic_logic_understood),\n",
    "                     'logic_num',','.join(str(v) for v in self.logic_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how much the predicted_out coming from entity_in is in line with the expected \n",
    "# attribute differences of the train in-out pairs in task_data.\n",
    "def attributes_similarity(task_data,entity_in,predicted_out_grid, verbose=False):\n",
    "    \n",
    "    sim_score = 0 # sim_score = 1 if the grids are equal\n",
    "    t_in_grid = entity_in.grid\n",
    "    \n",
    "    # slight misuse of the Task object. I'm using it to easily compute \"common_diff\" and \"sequence\" for [entity_in,predicted_out]\n",
    "    train_data = build_trainlist({\"train\":[{\"input\":t_in_grid,\"output\":predicted_out_grid},],})\n",
    "    #print(\"t_in_grid\",t_in_grid)\n",
    "    #print(\"predicted_out_grid\",predicted_out_grid)\n",
    "    t = Task(train_data, train_data)\n",
    "    t.compute_train_attributes()\n",
    "    t.compute_diff_attributes()\n",
    "    t.find_common_diff()\n",
    "    t.find_sequence()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n task_data.common_diff\", task_data.common_diff)\n",
    "        print(\"\\n t.common_diff\", t.common_diff)\n",
    "    \n",
    "    keys_to_exclude = ['color_perc_changed', 'most_common_color_changed', 'second_most_common_color_changed', \n",
    "                       'least_common_color_changed','h_symm_changed', 'v_symm_changed', 'ld_symm_changed',\n",
    "                       'rd_symm_changed', \"is_in_in_out\", \"is_out_in_in\"\n",
    "                       #'color_changed',\n",
    "                       #'new_colors',\n",
    "                       #'shape_changed',\n",
    "                       #\"h_shape_changed\", \"v_shape_changed\"\n",
    "                      ] \n",
    "    \n",
    "    normalisation = 0 # normalise to 1\n",
    "    \n",
    "    for key_diff, value in task_data.common_diff.items():\n",
    "        if (key_diff not in keys_to_exclude) and (task_data.common_diff[key_diff] !=0 ):\n",
    "            normalisation += 1\n",
    "            if (task_data.common_diff[key_diff] == t.common_diff[key_diff]): \n",
    "                sim_score += 1\n",
    "    \n",
    "    return sim_score/normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the programs which do not predict the expected attributes when acting on the test t_in\n",
    "def filter_programs(programs, task_data):\n",
    "    \n",
    "    filtered_trained_similarities = []\n",
    "    # Iterate Through Test Tasks\n",
    "    for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "        t_in = in_out_pair[0]\n",
    "\n",
    "        for prog_ram in programs: \n",
    "            #print(\"prog_ram\",[(x.functions,x.magic_numbers, x.magic_logic_understood) for x in [prog_ram]]) \n",
    "            # make the prediction\n",
    "            pred_generate = t_in.grid\n",
    "            get_magic_numbers_from_logic(prog_ram, t_in, task_data) \n",
    "            \n",
    "            # eliminate all the programs which have undefined magic numbers (the logic is working on the train set, but not on test)\n",
    "            ok_magic_numbers = not None in flatten_rec(prog_ram.magic_numbers)\n",
    "            \n",
    "            for num, func in enumerate(prog_ram.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, func, *prog_ram.magic_numbers[num])\n",
    "\n",
    "            if (pred_generate.size == 0) or (np.array_equal(pred_generate,black_square)):\n",
    "                continue\n",
    "            #print(\"prog_ram\",prog_ram.functions)\n",
    "            #print(\"mns\", prog_ram.magic_numbers)\n",
    "            #print(\"pred_generate\", pred_generate)\n",
    "            #print(\"t_in\", t_in.grid)\n",
    "            at_s = 1.0\n",
    "            if I_AM_IN_KAGGLE and (not DEBUG):\n",
    "                # TODO speedup\n",
    "                pass\n",
    "                #at_s = attributes_similarity(task_data,t_in,pred_generate)#, verbose=True)\n",
    "            #print(\"at_s\",at_s)\n",
    "                 \n",
    "            if np.isclose(at_s, 1.0) and ok_magic_numbers:   # the program satisfies all the expected attributes     \n",
    "                filtered_trained_similarities.append(prog_ram)\n",
    "                \n",
    "    return filtered_trained_similarities \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Programs...\n",
      "--- 0.0021021366119384766 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Programs...\")\n",
    "        \n",
    "def pred_wrapper(grid, t, task_data, func, *magic_args):\n",
    "    grid_copy = grid.copy()\n",
    "    if DEBUG:\n",
    "        try:\n",
    "            return func(grid_copy, t, task_data, *magic_args)\n",
    "        except Exception as error:\n",
    "            return black_square\n",
    "    else:\n",
    "        try:\n",
    "            return func(grid_copy, t, task_data, *magic_args)\n",
    "        except:\n",
    "            return black_square\n",
    "        \n",
    "def get_sim_score(pred, reference):\n",
    "    if np.array_equal(pred, reference):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "# generate a candidate program\n",
    "def generate_programs(task_data):\n",
    "    \n",
    "    n_train_pairs = len(task_data.train_tensors)\n",
    "    max_solution_length = 2\n",
    "    \n",
    "    # compute attributes\n",
    "    task_data.compute_train_attributes()\n",
    "    task_data.compute_test_attributes()\n",
    "    task_data.compute_diff_attributes()\n",
    "    task_data.find_common_diff()\n",
    "    task_data.find_sequence()\n",
    "    \n",
    "    magic_numbers = get_magic_numbers(task_data)\n",
    "    \n",
    "    # candidate functions which when combined could deliver the correct solution program.\n",
    "    pred_functions = function_filter(task_data, DSL_fs_names)  \n",
    "    #print(\"pred_functions\", pred_functions)\n",
    "    \n",
    "    for in_out_pair in task_data.train_tensors:\n",
    "        t_in = in_out_pair[0]\n",
    "        t_out = in_out_pair[1]\n",
    "        \n",
    "        pred_similarities = []\n",
    "        for pred_func in pred_functions:\n",
    "            # run over all magic arguments\n",
    "            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "            for mn in magic_args:\n",
    "                # evaluate all the pred_functions on the t_in Tensor and keep track of their score\n",
    "                pred_generate = pred_wrapper(t_in.grid, t_in, task_data, pred_func, *mn)\n",
    "                sim_score = get_sim_score(pred_generate, t_out.grid)\n",
    "                list.append(pred_similarities,Program([pred_func],sim_score,\"Tensor\",[mn]))    \n",
    "            \n",
    "        \n",
    "        # keep the first n best scoring programs \n",
    "        n = len(pred_similarities)  \n",
    "        pred_similarities = sorted(pred_similarities, key=lambda x: x.sim_score, reverse=True)[:n]\n",
    "        trained_similarities = []\n",
    "        \n",
    "        \n",
    "        prediction_flags = [True] * len(pred_similarities) # flag if keep searching to update the function. \n",
    "        \n",
    "        # print(\"Seek Better Solution...\")\n",
    "        for j, program in enumerate(pred_similarities):\n",
    "            \n",
    "            current_prog = [program]\n",
    "            # If False, No Better program, store the program as it is now.\n",
    "            while prediction_flags[j] == True:\n",
    "                        \n",
    "                current_pred_func = None\n",
    "                current_pred_magic_numbers = None\n",
    "                new_current_prog = []\n",
    "                updated_flag = [False] * len(current_prog) # flag if the functions are being updated\n",
    "                \n",
    "                for k, prog in enumerate(current_prog):\n",
    "                    \n",
    "                                           \n",
    "                    # if the chains of functions is longer than allowed, add it to the functions to select\n",
    "                    if (len(prog.functions) >= max_solution_length):\n",
    "                        list.append(trained_similarities, prog)\n",
    "                        continue \n",
    "                        \n",
    "                    # compose the program\n",
    "                    pred_generate = t_in.grid \n",
    "                    for num, pred_func in enumerate(prog.functions):\n",
    "                        pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *prog.magic_numbers[num]) # function composition\n",
    "                    task_sim_score = get_sim_score(pred_generate.copy(), t_out.grid)\n",
    "                    current_pred_func = prog.functions\n",
    "                    current_pred_magic_numbers = prog.magic_numbers\n",
    "                    \n",
    "                                    \n",
    "                    look_for_updates = True  # Just put False if debugging\n",
    "                    if look_for_updates:\n",
    "                        updated_similarities = []\n",
    "\n",
    "                        # Iterate over all the functions to generate a new composite function\n",
    "                        for pred_func in pred_functions:\n",
    "                            if forbidden_composition([pred_func], current_pred_func): # skip this function, if composition is forbidden\n",
    "                                continue\n",
    "                            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "                            for mn in magic_args:\n",
    "                                pred_func_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *mn)\n",
    "                                task_sim_score = get_sim_score(pred_func_generate, t_out.grid)\n",
    "                                list.append(updated_similarities,Program([pred_func],task_sim_score,\"Tensor\",[mn]))\n",
    "\n",
    "                        \n",
    "                        # check if the new composite function scores better than the current_pred_func\n",
    "                        for p in updated_similarities:\n",
    "                            if forbidden_composition(p.functions, current_pred_func): # skip this function, if composition is forbidden\n",
    "                                continue\n",
    "                            if prog.sim_score == 1:\n",
    "                                improvement_threshold = 0 # DEBUG Normally this should be positive! \n",
    "                            else:\n",
    "                                improvement_threshold = -0.1 # DEBUG Normally this should be positive! (assuming max(score)= 1)\n",
    "                            if (p.sim_score > prog.sim_score + improvement_threshold): \n",
    "                                # the function have been improved! Now it will over the whole process again, to see if it can be improved further.\n",
    "                                \n",
    "                                new_current_prog.append(Program(current_pred_func + p.functions ,p.sim_score,\"Tensor\",current_pred_magic_numbers +p.magic_numbers)) \n",
    "                                if not updated_flag[k]:\n",
    "                                    updated_flag[k] = True     # at least one new function has been generated\n",
    "                            else:\n",
    "                                pass\n",
    "                  \n",
    "                    # the functions cannot be improved further (at least not with 1 step), add it to the functions to select\n",
    "                    if not updated_flag[k]: # no updates\n",
    "                        list.append(trained_similarities, prog)\n",
    "                \n",
    "                \n",
    "                #print(\"current_prog loop end\")\n",
    "                #print(\"...\")\n",
    "                current_prog = new_current_prog\n",
    "                \n",
    "                if len(current_prog)==0:\n",
    "                    prediction_flags[j] = False \n",
    "            #print(\"End prediction_flags[j] == True while loop\")\n",
    "            #print(\"-----------\")\n",
    "          \n",
    "        #print(\"End pred_similarities for loop\")\n",
    "        #print(\"-----------\")       \n",
    "        #print(\"trained_similarities\",[(x.functions,x.magic_numbers) for x in trained_similarities])\n",
    "        \n",
    "        return trained_similarities\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the programs which predict the same magic numbers on the test\n",
    "def filter_programs_with_same_magic_numbers(programs, task_data):\n",
    "    \n",
    "    ok_programs = []\n",
    "    ok_magic_numbers = []\n",
    "    n_programs = 3\n",
    "    \n",
    "    # Iterate Through Test Tasks\n",
    "    for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "        t_in = in_out_pair[0]\n",
    "\n",
    "        for prog_ram in programs: \n",
    "            \n",
    "            # stop if we find 3 different programs\n",
    "            if len(ok_programs) == n_programs:\n",
    "                return ok_programs\n",
    "            \n",
    "            get_magic_numbers_from_logic(prog_ram, t_in, task_data) \n",
    "            \n",
    "            mns_are_duplicate = False\n",
    "            for mns in ok_magic_numbers:\n",
    "                if (mns == prog_ram.magic_numbers):\n",
    "                    mns_are_duplicate = True\n",
    "                    break\n",
    "            if not mns_are_duplicate:\n",
    "                ok_magic_numbers.append(prog_ram.magic_numbers)\n",
    "                ok_programs.append(prog_ram)\n",
    "                \n",
    "    return ok_programs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Program ...\n",
      "--- 0.0025911331176757812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Select Program ...\")\n",
    "\n",
    "def select_programs(task_data, generated_programs):\n",
    "    \n",
    "    programs_without_logic = [] # when a program has a logic, add also a copy program without logic\n",
    "    programs_with_alternative_logic = [] # if the program has multiple valid logic, generate different programs from all the logic combinations\n",
    "    \n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(generated_programs):\n",
    "        program.task_accuracy = 0\n",
    "        logic_understood = []  # list of bools\n",
    "        logic_nums = [] # list of list of strings, containing the logic associated to the respective magic numbers\n",
    "    \n",
    "        # Iterate Through Train Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "        \n",
    "            pred_generate = t_in.grid\n",
    "            # predict\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "                             \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid):\n",
    "                program.task_accuracy += 1\n",
    "                \n",
    "                # check if the magic numbers follow a logic\n",
    "                program.logic_num = [-1] * len(program.functions) # -1 is a flag for bad outcome\n",
    "                for num, pred_func in enumerate(program.functions):\n",
    "                    program.logic_num[num] = [[] for _ in program.magic_numbers[num]] # define a list [[],[],[],...] https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "                    \n",
    "                    for j, n in enumerate(program.magic_numbers[num]):\n",
    "                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"color_related\"] > 0:\n",
    "                            # logic coming from a single grid\n",
    "                            if t_in.attributes[\"most_common_color\"] == n:\n",
    "                                program.logic_num[num][j].append(\"most_common_color\")\n",
    "                            if (\"second_most_common_color\" in t_in.attributes) and (t_in.attributes[\"second_most_common_color\"] == n):\n",
    "                                program.logic_num[num][j].append(\"second_most_common_color\")\n",
    "                            if t_in.attributes[\"least_common_color\"] == n:\n",
    "                                program.logic_num[num][j].append(\"least_common_color\")\n",
    "                            # logic coming from all the in-out train pairs\n",
    "                            for i, cnc in enumerate(task_data.sequences[\"common_new_colors\"]):\n",
    "                                if cnc == n:\n",
    "                                    program.logic_num[num][j].append(\"common_new_colors\" + \"_\" + str(i))\n",
    "                                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"shape_related\"] > 0:\n",
    "                            if (\"out_shape_0\" in task_data.sequences) and (task_data.sequences[\"out_shape_0\"] == n):\n",
    "                                program.logic_num[num][j].append(\"out_shape_0\")\n",
    "                            if (\"out_shape_1\" in task_data.sequences) and (task_data.sequences[\"out_shape_1\"] == n):\n",
    "                                program.logic_num[num][j].append(\"out_shape_1\")\n",
    "                            if t_in.attributes[\"v_shape\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape\")\n",
    "                            if t_in.attributes[\"h_shape\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape\")\n",
    "                            if t_in.attributes[\"v_shape_half\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape_half\")\n",
    "                            if t_in.attributes[\"h_shape_half\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape_half\")\n",
    "                            if t_in.attributes[\"v_shape_third\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape_third\")\n",
    "                            if t_in.attributes[\"h_shape_third\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape_third\")\n",
    "                            if t_in.attributes[\"n_unique_colors\"] == n:\n",
    "                                program.logic_num[num][j].append(\"n_unique_colors\")\n",
    "                            if t_in.attributes[\"n_unique_non_backg_colors\"] == n:\n",
    "                                program.logic_num[num][j].append(\"n_unique_non_backg_colors\")\n",
    "                                \n",
    "                        if fs_argument_structure[pred_func.__name__][\"object_related\"] > 0:\n",
    "                            if t_in.attributes[\"top_left_corner\"] == n:\n",
    "                                program.logic_num[num][j].append(\"top_left_corner\")\n",
    "                            if t_in.attributes[\"top_mid_point\"] == n:\n",
    "                                program.logic_num[num][j].append(\"top_mid_point\")\n",
    "                            if t_in.attributes[\"left_mid_point\"] == n:\n",
    "                                program.logic_num[num][j].append(\"left_mid_point\")\n",
    "                        \n",
    "                        program.logic_num[num][j] = list(set(program.logic_num[num][j]))\n",
    "                        \n",
    "                # if all the numbers are recognized in some attribute, then we undestood the logic of the task (at least regarding magic numbers)\n",
    "                log_und = []\n",
    "                for k, logi in enumerate(program.logic_num):\n",
    "                    if (len(logi) == 0) and (number_of_magic_arguments(program.functions[k]) > 0):\n",
    "                        log_und.append(False)\n",
    "                    # handle the case in which the function takes no magic arguments\n",
    "                    elif (len(logi) == 0) and (number_of_magic_arguments(program.functions[k]) == 0):\n",
    "                        log_und.append(\"No Logic by default\")\n",
    "                \n",
    "                if not all(log_und):\n",
    "                    log_und = False\n",
    "                elif ((\"No Logic by default\" in log_und) and (all(log_und))):\n",
    "                    log_und = True\n",
    "                else:\n",
    "                    log_und = True\n",
    "                        \n",
    "                    \n",
    "                logic_understood.append(log_und)\n",
    "                logic_nums.append(program.logic_num)\n",
    "         \n",
    "        # END OF INPUT_OUTPUT PAIRS LOOP\n",
    "               \n",
    "        #print(\"program.functions\",program.functions) \n",
    "        #print(\"program.logic_num\",program.logic_num) \n",
    "        #print(\"program.logic_nums\",logic_nums) \n",
    "        \n",
    "        # generate programs with the combinations of all the logics\n",
    "        mns_fs = []*len(program.functions)\n",
    "        for lnms in program.logic_num: # iterate over the logic_num for each function\n",
    "            mns_fs.append([list(elem) for elem in list(itertools.product(*lnms))] ) \n",
    "        mns_fs = [list(elem) for elem in list(itertools.product(*mns_fs))]\n",
    "\n",
    "        for el in mns_fs:\n",
    "            prog_with_alternative_logic = copy.deepcopy(program)\n",
    "            prog_with_alternative_logic.logic_num = el  \n",
    "            prog_with_alternative_logic.magic_logic_understood = all(logic_understood) and (len(logic_understood)> 0)\n",
    "            #print(\"logic_understood\",logic_understood, el)\n",
    "            #print(\"prog_with_alternative_logic.magic_logic_understood\",prog_with_alternative_logic.magic_logic_understood, el)\n",
    "            for logi in el:\n",
    "                for ll in logi:\n",
    "                    # check that the logic appears in all the input-output pairs\n",
    "                    if not (all( ll in flatten_rec(sublist) for sublist in logic_nums)) : # this is not totally correct, as ll could be in the wrong nested list of sublist. So this check is too permissive.\n",
    "                        prog_with_alternative_logic.magic_logic_understood = False\n",
    "            if prog_with_alternative_logic.magic_logic_understood:\n",
    "                programs_with_alternative_logic.append(prog_with_alternative_logic)\n",
    "         \n",
    "        # append also a program without logic, it may actually solve the task!\n",
    "        prog_without_logic = program # this modifies the original program, as it is not deepcopied\n",
    "        prog_without_logic.logic_num = []\n",
    "        prog_without_logic.magic_logic_understood = False\n",
    "        programs_without_logic.append(prog_without_logic)\n",
    "        \n",
    "    \n",
    "    generated_programs.extend(programs_without_logic)\n",
    "    generated_programs.extend(programs_with_alternative_logic)\n",
    "    \n",
    "    # filter by requiring the prediction to have the expected attributes and that magic numbers are not None on test\n",
    "    generated_programs = filter_programs(generated_programs, task_data)\n",
    "    \n",
    "    # Select Best 3 Solutions\n",
    "    best_programs = list(set(generated_programs)) # remove duplicates\n",
    "    best_programs = sorted(best_programs, key=lambda x: x.magic_logic_understood, reverse=True) # give priority to programs which understood the logic\n",
    "    best_programs = sorted(best_programs, key=lambda x: len(x.functions), reverse=False) # give priority to short programs\n",
    "    best_programs = sorted(best_programs, key=lambda x: x.task_accuracy, reverse=True)\n",
    "    #print(\"best_programs sorted\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs])\n",
    "    best_programs = best_programs[:30]\n",
    "    best_programs = filter_programs_with_same_magic_numbers(best_programs, task_data)\n",
    "    print(\"best_programs filtered\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs]) \n",
    "    return best_programs\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the logic has been understood from the in-out pairs, use this logic to generate the magic numbers\n",
    "# which will solve the test prediction\n",
    "def get_magic_numbers_from_logic(program, t_in, task_data):\n",
    "    \n",
    "    if program.magic_logic_understood:\n",
    "        for num, logic_n in enumerate(program.logic_num):\n",
    "            for l,logic in enumerate(logic_n):\n",
    "                if logic in t_in.attributes: # logic coming from a single grid\n",
    "                    program.magic_numbers[num][l] = t_in.attributes[logic]\n",
    "                if logic in task_data.sequences: # logic coming from all the in-out train pairs\n",
    "                    program.magic_numbers[num][l] = task_data.sequences[logic] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Program Application Framework ...\n",
      "--- 0.0010309219360351562 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Program Application Framework ...\")\n",
    "\n",
    "# apply on the test tasks\n",
    "def compute_test_accuracy(task_n, task_data, best_programs):\n",
    "\n",
    "    # Initialize Local Variables\n",
    "    output_test = 0\n",
    "    good_programs = []\n",
    "    good_logics = []\n",
    "    num_test = len(task_data.test_tensors)\n",
    "\n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(best_programs):\n",
    "        program.task_accuracy = 0\n",
    "\n",
    "        # Iterate Through Test Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "\n",
    "            pred_generate = t_in.grid\n",
    "            \n",
    "            # build magic numbers from the logic\n",
    "            get_magic_numbers_from_logic(program, t_in, task_data)                       \n",
    "            \n",
    "            # make the prediction\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "            \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid): \n",
    "                program.task_accuracy += 1\n",
    "\n",
    "        if program.task_accuracy >= 1:\n",
    "            good_programs.append(program.functions)\n",
    "            good_logics.append(program.logic_num)\n",
    "            output_test += 1\n",
    "         \n",
    "        # Print Log of Task, Program, Accuracy, Percentage Accurate\n",
    "        percent_accuracy = np.round((program.task_accuracy / num_test * 100), 2)\n",
    "        print(\"(Test:{}.{:02d})-(Program:{}, MNs:{}, logic:{})- Acc:{}/{}\".format(\n",
    "            task_n, i, [f.__name__ for f in program.functions], [mn for mn in program.magic_numbers], program.logic_num, program.task_accuracy, num_test))\n",
    "\n",
    "    # Return Accuracy\n",
    "    output_test = int(output_test >= 1)\n",
    "    return {\"accuracy\":output_test,\"good_programs\":[[f.__name__ for f in fs] for fs in good_programs],\"logic\":good_logics}\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Program Submission Framework ...\n",
      "--- 0.00048613548278808594 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Program Submission Framework ...\")\n",
    "\n",
    "def submit_program_to_LB(task_data, selected_programs):\n",
    "\n",
    "    # Initialize Local Variables\n",
    "    output_data = \"\"    \n",
    "    \n",
    "    # Iterate Through Selected Programs\n",
    "    for i, program in enumerate(selected_programs):\n",
    "\n",
    "        # Iterate Through Test Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            \n",
    "            pred_generate = t_in.grid\n",
    "            \n",
    "            # build magic numbers from the logic\n",
    "            get_magic_numbers_from_logic(program, t_in, task_data)                       \n",
    "            \n",
    "            # make the prediction\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "    \n",
    "            # Format Output Data as String\n",
    "            output_data += (flattener(pred_generate) + ' ')\n",
    "    \n",
    "    # Return Output\n",
    "    return output_data\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Training Set) ...\n",
      "Generating Program for Task 0\n",
      "diff {'color_changed': -1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': 0, 'second_most_common_color_changed': 0, 'least_common_color_changed': 0, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': 1, 'is_out_in_in': -1}\n",
      "functions removed {'color_2', 'color_ob_1', 'draw_reg_2', 'superp_7', 'draw_reg_3', 'superp_reg_3', 'color_1', 'superp_reg_2', 'superp_reg_4', 'superp_1', 'superp_4', 'superp_3', 'superp_6', 'superp_5', 'color_3', 'superp_2', 'superp_reg_1', 'draw_reg_1', 'special_1', 'superp_8', 'special_2'}\n",
      "best_programs filtered [([<function repeat_2 at 0x126e9e710>], [[]], 5, True, [[]]), ([<function rotate_3 at 0x126b9b050>, <function rescale_1 at 0x126de1200>], [[], [4, 2]], 0, False, []), ([<function rescale_1 at 0x126de1200>, <function repeat_1 at 0x127d964d0>], [[6, 1], [1, 2]], 0, False, [])]\n",
      "(Test:0.00)-(Program:['repeat_2'], MNs:[[]], logic:[[]])- Acc:1/1\n",
      "(Test:0.01)-(Program:['rotate_3', 'rescale_1'], MNs:[[], [4, 2]], logic:[])- Acc:0/1\n",
      "(Test:0.02)-(Program:['rescale_1', 'repeat_1'], MNs:[[6, 1], [1, 2]], logic:[])- Acc:0/1\n",
      "Generation Took 3.616086006164551 Seconds\n",
      "Training Set - Final Accuracy: 1 / 1 \n",
      " Training Set - Accurate Tasks: [0] \n",
      " --------------------\n",
      "--- 3.617326259613037 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Training Set) ...\")\n",
    "\n",
    "accuracy_full = 0\n",
    "accuracy_tasks = []\n",
    "detailed_accuracy_tasks = []\n",
    "slow_tasks = []\n",
    "training_flag = True \n",
    "start=0 # [2, 128, 226, 258, 346, 394]\n",
    "finish=start+1\n",
    "if (training_flag == True) and DEBUG:\n",
    "    for task_n in range(start,finish):\n",
    "        task_time = time.time()\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        accuracy = []\n",
    "        \n",
    "        train_data = build_trainlist(train_task_data[task_n])\n",
    "        test_data = build_testlist(train_task_data[task_n])\n",
    "        task_data = Task(train_data, test_data)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        res = compute_test_accuracy(task_n, task_data, best_programs)\n",
    "        \n",
    "        time_spent = time.time() - task_time\n",
    "        print(\"Generation Took %s Seconds\" % (time_spent))\n",
    "        accuracy_full += res[\"accuracy\"]\n",
    "\n",
    "        if res[\"accuracy\"] >= 1:\n",
    "            list.append(accuracy_tasks, task_n)\n",
    "            list.append(detailed_accuracy_tasks, [task_n,res[\"good_programs\"],res[\"logic\"]])\n",
    "    \n",
    "        if time_spent > 60:\n",
    "            slow_tasks.append([task_n,time_spent])\n",
    "            \n",
    "        report_0 = \"Training Set - Final Accuracy: {} / {}\".format(accuracy_full, finish-start)\n",
    "        report_1 = \"Training Set - Accurate Tasks: {}\".format(accuracy_tasks)\n",
    "        report_2 = \"Training Set - Detailed Accurate Tasks: {}\".format(detailed_accuracy_tasks)\n",
    "        report_slow = \"Training Set - Slow Tasks: {}\".format(slow_tasks)\n",
    "        print(report_0, \"\\n\", report_1, \"\\n\", \"--------------------\" )\n",
    "        final_report = report_0 + \" \\n \" + report_1 + \" \\n \" + report_2 + \" \\n \" + report_slow + \" \\n \" + str(time.time() - start_time) + \" seconds\"\n",
    "        if (((task_n%50==0) or (task_n==finish-start-1)) and (task_n!=0)) and DEBUG:\n",
    "            #send_slack_report(final_report)\n",
    "            pass\n",
    "            \n",
    "if DEBUG and I_AM_IN_KAGGLE:\n",
    "    send_slack_report(final_report)\n",
    "    pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Evaluation Set) ...\n",
      "--- 0.0013489723205566406 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Evaluation Set) ...\")\n",
    "\n",
    "accuracy_full = 0\n",
    "accuracy_tasks = []\n",
    "detailted_accuracy_tasks = []\n",
    "evaluation_flag = False\n",
    "start=42#0\n",
    "finish=43 #400\n",
    "if evaluation_flag == True:\n",
    "    for task_n in range(start,finish):\n",
    "        task_time = time.time()\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        accuracy = []\n",
    "        \n",
    "        train_data = build_trainlist(eval_task_data[task_n])\n",
    "        test_data = build_testlist(eval_task_data[task_n])\n",
    "        task_data = Task(train_data, test_data)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        res = compute_test_accuracy(task_n, task_data, best_programs)\n",
    "        \n",
    "        print(\"Generation Took %s Seconds\" % (time.time() - task_time))\n",
    "        accuracy_full += res[\"accuracy\"]\n",
    "\n",
    "        if res[\"accuracy\"] >= 1:\n",
    "            list.append(accuracy_tasks, task_n)\n",
    "            list.append(detailted_accuracy_tasks, [task_n,res[\"good_programs\"],res[\"logic\"]])\n",
    "            \n",
    "        report_0 = \"Evaluation Set - Final Accuracy: {} / {}\".format(accuracy_full, finish-start)\n",
    "        report_1 = \"Evaluation Set - Accurate Tasks: {}\".format(accuracy_tasks)\n",
    "        report_2 = \"Evaluation Set - Detailed Accurate Tasks: {}\".format(detailted_accuracy_tasks)\n",
    "        print(report_0, \"\\n\", report_1, \"\\n\", \"--------------------\" )\n",
    "        final_report = report_0 + \" \\n \" + report_1 + \" \\n \" + report_2 + \" \\n \" + str(time.time() - start_time) + \" seconds\"\n",
    "        if (((task_n%50==0) or (task_n==finish-start-1)) and (task_n!=0)) and DEBUG:\n",
    "            #send_slack_report(final_report)\n",
    "            pass\n",
    "            \n",
    "if DEBUG:\n",
    "    #send_slack_report(final_report)\n",
    "    pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Submission to LB) ...\n",
      "\n",
      "\n",
      "--- 0.0005161762237548828 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Submission to LB) ...\\n\")\n",
    "\n",
    "task_n = 0\n",
    "submit_to_LB_flag = I_AM_IN_KAGGLE and (not DEBUG)\n",
    "if submit_to_LB_flag == True:\n",
    "    for output_id in submission.index:\n",
    "\n",
    "        task_id = output_id.split('_')[0]\n",
    "        pair_id = int(output_id.split('_')[1])\n",
    "        if pair_id == 1:\n",
    "            task_n -= 1 # there are 100 tasks, but 4 of them have a second version with pair_id = 1 instead of = 0.\n",
    "        f = str(testing_path / str(task_id + '.json'))\n",
    "        with open(f, 'r') as read_file:\n",
    "            task = json.load(read_file)\n",
    "\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        train_data = build_trainlist(test_task_data[task_n])\n",
    "        test_data = build_testlist(test_task_data[task_n], LB_submission=True, pair_id=pair_id)\n",
    "        task_data = Task(train_data, test_data, LB_submission=True)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        program_data = submit_program_to_LB(task_data, best_programs)\n",
    "        submission.loc[output_id, 'output'] = program_data \n",
    "        task_n += 1\n",
    "        print(\"-------\")\n",
    "    \n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Submission to CSV ...\n",
      "--- 0.017663955688476562 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Output Submission to CSV ...\")\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work Area. Feel free to clean if it gets too messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff {'color_changed': -1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': 0, 'second_most_common_color_changed': 0, 'least_common_color_changed': 0, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': 1, 'is_out_in_in': -1}\n",
      "functions removed {'color_2', 'color_ob_1', 'draw_reg_2', 'superp_7', 'draw_reg_3', 'superp_reg_3', 'color_1', 'superp_reg_2', 'superp_reg_4', 'superp_1', 'superp_4', 'superp_3', 'superp_6', 'superp_5', 'color_3', 'superp_2', 'superp_reg_1', 'draw_reg_1', 'special_1', 'superp_8', 'special_2'}\n",
      "{'color_related': [0, 2, 4, 6, 7], 'shape_related': [1, 2, 3, 4, 6, 9], 'regions_related': [], 'object_related': [], 'layer_related': [], 'axis_related': []}\n",
      "len(prepare_magic_arguments(special_1, magic_numbers) 180\n",
      "{'color_changed': False, 'new_colors': [], 'color_perc_changed': True, 'most_common_color_changed': False, 'second_most_common_color_changed': False, 'least_common_color_changed': False, 'shape_changed': True, 'h_shape_changed': True, 'v_shape_changed': True, 'h_symm_changed': False, 'v_symm_changed': False, 'ld_symm_changed': False, 'rd_symm_changed': False, 'is_in_in_out': [(0, 3), (0, 6), (3, 0), (3, 3), (3, 6), (6, 3), (6, 6)], 'is_out_in_in': []}\n",
      "{'color_changed': -1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': 0, 'second_most_common_color_changed': 0, 'least_common_color_changed': 0, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': 1, 'is_out_in_in': -1}\n",
      "{'common_new_colors': [], 'out_shape_0': 9, 'out_shape_1': 9, 'max_in_shape': 3, 'min_in_shape': 3, 'max_out_shape': 9, 'min_out_shape': 9, 'prime_in_shape_0': True, 'prime_in_shape_1': True, 'n_colors': 2, 'max_n_objects_in': 3, 'min_n_objects_in': 1, 'max_n_objects_out': 9, 'min_n_objects_out': 1, 'max_n_regions_in': 2, 'min_n_regions_in': 1, 'max_n_regions_out': 1, 'min_n_regions_out': 1, 'max_max_color_perc_in': 0.7777777777777778, 'min_max_color_perc_in': 0.5555555555555556, 'max_max_color_perc_out': 0.8888888888888888, 'min_max_color_perc_out': 0.6049382716049383}\n",
      "{'unique_colors': [0, 7], 'n_unique_colors': 2, 'n_unique_non_backg_colors': 1, 'grid_colors_perc': OrderedDict([(7, 0.7777777777777778), (0, 0.2222222222222222), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (8, 0.0), (9, 0.0)]), 'max_color_perc': 0.7777777777777778, 'most_common_color': 7, 'second_most_common_color': 0, 'least_common_color': 0, 'grid_shape': (3, 3), 'v_shape': 3, 'h_shape': 3, 'v_shape_half': None, 'h_shape_half': None, 'v_shape_third': None, 'h_shape_third': None, 'h_symm': True, 'v_symm': False, 'ld_symm': False, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': None, 'left_mid_point': None, 'lines': {'h_lines': [1], 'v_lines': [1, 2], 'rd_lines': [], 'ld_lines': []}, 'n_objects': 1, 'n_regions': 2}\n"
     ]
    }
   ],
   "source": [
    "task_n = 0 #[2, 128, 226, 258, 346, 394]\n",
    "train_data = build_trainlist(train_task_data[task_n])\n",
    "test_data = build_testlist(train_task_data[task_n])\n",
    "task_data = Task(train_data, test_data)\n",
    "task_data.compute_train_attributes()\n",
    "task_data.compute_test_attributes()\n",
    "task_data.compute_diff_attributes()\n",
    "task_data.find_common_diff()\n",
    "task_data.find_sequence()\n",
    "magic_numbers = get_magic_numbers(task_data)\n",
    "pred_functions = function_filter(task_data, DSL_fs_names) \n",
    "print(magic_numbers)\n",
    "print(\"len(prepare_magic_arguments(special_1, magic_numbers)\",len(prepare_magic_arguments(special_1, magic_numbers)))\n",
    "#print(prepare_magic_arguments(special_1, magic_numbers))\n",
    "print(task_data.train_diff[0])\n",
    "print(task_data.common_diff)\n",
    "print(task_data.sequences)\n",
    "print(task_data.train_tensors[0][0].attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Manual) ...\n",
      "--- 1.431844711303711 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Manual) ...\")\n",
    "\n",
    "def combine_tasks(a):\n",
    "    b = a.copy()\n",
    "    t_in = task_data.train_tensors[0][0]\n",
    "    try:\n",
    "        #t_in = task_data.test_tensors[0][0]\n",
    "        b = repeat_2(b,t_in, task_data)\n",
    "        #b = superp_2(b,t_in, task_data,*[0,1,2])\n",
    "        #b = symmetric_1(b,t_in, task_data)\n",
    "        #b = superp_reg_3(b,t_in, task_data,*[0,3])\n",
    "        #b = draw_reg_1(b,t_in, task_data,*[])\n",
    "        #b = color_ob_1(b,t_in, task_data,*[3])\n",
    "        #b = special_2(b,t_in, task_data,*[4])\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return b\n",
    "    \n",
    "    return b\n",
    "\n",
    "tasks_indices = [task_n]\n",
    "for task in tasks_indices:\n",
    "    check_p(train_task_data[task], combine_tasks)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeit flip_2(tt,task_data.train_tensors[0][0], task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_colors': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_unique_colors': 10, 'n_unique_non_backg_colors': 9, 'grid_colors_perc': OrderedDict([(0, 0.5077777777777778), (1, 0.09111111111111111), (6, 0.06666666666666667), (3, 0.06333333333333334), (7, 0.06333333333333334), (8, 0.06222222222222222), (9, 0.06222222222222222), (5, 0.03), (4, 0.028888888888888888), (2, 0.024444444444444446)]), 'max_color_perc': 0.5077777777777778, 'most_common_color': 0, 'second_most_common_color': 1, 'least_common_color': 2, 'grid_shape': (30, 30), 'v_shape': 30, 'h_shape': 30, 'v_shape_half': 15, 'h_shape_half': 15, 'v_shape_third': 10, 'h_shape_third': 10, 'h_symm': False, 'v_symm': False, 'ld_symm': False, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': (0, 15), 'left_mid_point': (15, 0), 'lines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}, 'has_hole': True, 'holes_coords_obj': [[1, 9], [1, 11], [1, 12], [1, 19], [1, 20], [2, 7], [2, 13], [2, 18], [3, 6], [3, 7], [3, 9], [3, 11], [3, 12], [3, 13], [3, 18], [3, 19], [3, 20], [4, 9], [4, 11], [4, 13], [4, 15], [4, 16], [4, 18], [4, 20], [5, 8], [5, 10], [5, 11], [5, 12], [5, 14], [5, 15], [5, 16], [5, 17], [5, 19], [5, 20], [5, 21], [5, 23], [6, 3], [6, 6], [6, 9], [6, 13], [6, 18], [6, 22], [6, 25], [7, 2], [7, 3], [7, 8], [7, 9], [7, 12], [7, 13], [7, 15], [7, 16], [7, 18], [7, 19], [7, 22], [7, 23], [8, 5], [8, 7], [8, 8], [8, 9], [8, 11], [8, 12], [8, 15], [8, 16], [8, 19], [8, 20], [8, 22], [8, 23], [8, 24], [8, 26], [9, 1], [9, 3], [9, 4], [9, 6], [9, 7], [9, 8], [9, 10], [9, 11], [9, 13], [9, 14], [9, 17], [9, 18], [9, 20], [9, 21], [9, 23], [9, 24], [9, 25], [9, 27], [9, 28], [10, 5], [10, 9], [10, 13], [10, 14], [10, 17], [10, 18], [10, 22], [11, 1], [11, 3], [11, 4], [11, 5], [11, 8], [11, 9], [11, 11], [11, 12], [11, 15], [11, 16], [11, 19], [11, 20], [11, 22], [11, 23], [12, 1], [12, 3], [12, 5], [12, 7], [12, 8], [12, 11], [12, 12], [12, 14], [12, 15], [12, 16], [12, 17], [12, 19], [12, 20], [12, 23], [12, 24], [13, 2], [13, 3], [13, 4], [13, 6], [13, 7], [13, 9], [13, 10], [13, 14], [13, 15], [13, 16], [13, 17], [13, 21], [13, 22], [13, 24], [13, 25], [14, 5], [14, 9], [14, 10], [14, 12], [14, 13], [14, 14], [14, 15], [14, 16], [14, 17], [14, 18], [14, 19], [14, 21], [14, 22], [14, 26], [15, 4], [15, 5], [15, 7], [15, 8], [15, 11], [15, 12], [15, 13], [15, 14], [15, 17], [15, 18], [15, 19], [15, 20], [15, 23], [15, 24], [15, 26], [15, 27], [16, 4], [16, 5], [16, 7], [16, 8], [16, 11], [16, 12], [16, 13], [16, 14], [16, 17], [16, 18], [16, 19], [16, 20], [16, 23], [16, 24], [16, 26], [16, 27], [17, 5], [17, 12], [17, 13], [17, 14], [17, 15], [17, 16], [17, 17], [17, 18], [17, 19], [17, 21], [17, 22], [17, 26], [18, 2], [18, 3], [18, 4], [18, 6], [18, 7], [18, 9], [18, 10], [18, 14], [18, 15], [18, 16], [18, 17], [18, 24], [18, 25], [19, 1], [19, 3], [19, 5], [19, 7], [19, 8], [19, 11], [19, 12], [19, 14], [19, 15], [19, 16], [19, 17], [19, 19], [19, 20], [19, 23], [19, 24], [20, 1], [20, 3], [20, 4], [20, 5], [20, 8], [20, 9], [20, 11], [20, 12], [20, 15], [20, 16], [20, 19], [20, 20], [20, 23], [21, 5], [21, 9], [21, 13], [21, 14], [21, 17], [21, 18], [21, 22], [22, 1], [22, 3], [22, 4], [22, 6], [22, 7], [22, 8], [22, 10], [22, 11], [22, 13], [22, 14], [22, 17], [22, 18], [22, 20], [22, 21], [22, 23], [22, 24], [22, 25], [22, 27], [22, 28], [23, 5], [23, 7], [23, 8], [23, 9], [23, 11], [23, 12], [23, 15], [23, 16], [23, 19], [23, 20], [23, 22], [23, 23], [23, 24], [23, 26], [24, 2], [24, 3], [24, 8], [24, 9], [24, 12], [24, 13], [24, 15], [24, 16], [24, 18], [24, 19], [24, 22], [24, 23], [25, 3], [25, 6], [25, 9], [25, 13], [25, 18], [26, 8], [26, 14], [26, 15], [26, 16], [26, 17], [26, 19], [27, 9], [27, 15], [27, 16], [27, 18], [27, 20], [27, 22], [28, 9]], 'holes_coords_parent': [[1, 9], [1, 11], [1, 12], [1, 19], [1, 20], [2, 7], [2, 13], [2, 18], [3, 6], [3, 7], [3, 9], [3, 11], [3, 12], [3, 13], [3, 18], [3, 19], [3, 20], [4, 9], [4, 11], [4, 13], [4, 15], [4, 16], [4, 18], [4, 20], [5, 8], [5, 10], [5, 11], [5, 12], [5, 14], [5, 15], [5, 16], [5, 17], [5, 19], [5, 20], [5, 21], [5, 23], [6, 3], [6, 6], [6, 9], [6, 13], [6, 18], [6, 22], [6, 25], [7, 2], [7, 3], [7, 8], [7, 9], [7, 12], [7, 13], [7, 15], [7, 16], [7, 18], [7, 19], [7, 22], [7, 23], [8, 5], [8, 7], [8, 8], [8, 9], [8, 11], [8, 12], [8, 15], [8, 16], [8, 19], [8, 20], [8, 22], [8, 23], [8, 24], [8, 26], [9, 1], [9, 3], [9, 4], [9, 6], [9, 7], [9, 8], [9, 10], [9, 11], [9, 13], [9, 14], [9, 17], [9, 18], [9, 20], [9, 21], [9, 23], [9, 24], [9, 25], [9, 27], [9, 28], [10, 5], [10, 9], [10, 13], [10, 14], [10, 17], [10, 18], [10, 22], [11, 1], [11, 3], [11, 4], [11, 5], [11, 8], [11, 9], [11, 11], [11, 12], [11, 15], [11, 16], [11, 19], [11, 20], [11, 22], [11, 23], [12, 1], [12, 3], [12, 5], [12, 7], [12, 8], [12, 11], [12, 12], [12, 14], [12, 15], [12, 16], [12, 17], [12, 19], [12, 20], [12, 23], [12, 24], [13, 2], [13, 3], [13, 4], [13, 6], [13, 7], [13, 9], [13, 10], [13, 14], [13, 15], [13, 16], [13, 17], [13, 21], [13, 22], [13, 24], [13, 25], [14, 5], [14, 9], [14, 10], [14, 12], [14, 13], [14, 14], [14, 15], [14, 16], [14, 17], [14, 18], [14, 19], [14, 21], [14, 22], [14, 26], [15, 4], [15, 5], [15, 7], [15, 8], [15, 11], [15, 12], [15, 13], [15, 14], [15, 17], [15, 18], [15, 19], [15, 20], [15, 23], [15, 24], [15, 26], [15, 27], [16, 4], [16, 5], [16, 7], [16, 8], [16, 11], [16, 12], [16, 13], [16, 14], [16, 17], [16, 18], [16, 19], [16, 20], [16, 23], [16, 24], [16, 26], [16, 27], [17, 5], [17, 12], [17, 13], [17, 14], [17, 15], [17, 16], [17, 17], [17, 18], [17, 19], [17, 21], [17, 22], [17, 26], [18, 2], [18, 3], [18, 4], [18, 6], [18, 7], [18, 9], [18, 10], [18, 14], [18, 15], [18, 16], [18, 17], [18, 24], [18, 25], [19, 1], [19, 3], [19, 5], [19, 7], [19, 8], [19, 11], [19, 12], [19, 14], [19, 15], [19, 16], [19, 17], [19, 19], [19, 20], [19, 23], [19, 24], [20, 1], [20, 3], [20, 4], [20, 5], [20, 8], [20, 9], [20, 11], [20, 12], [20, 15], [20, 16], [20, 19], [20, 20], [20, 23], [21, 5], [21, 9], [21, 13], [21, 14], [21, 17], [21, 18], [21, 22], [22, 1], [22, 3], [22, 4], [22, 6], [22, 7], [22, 8], [22, 10], [22, 11], [22, 13], [22, 14], [22, 17], [22, 18], [22, 20], [22, 21], [22, 23], [22, 24], [22, 25], [22, 27], [22, 28], [23, 5], [23, 7], [23, 8], [23, 9], [23, 11], [23, 12], [23, 15], [23, 16], [23, 19], [23, 20], [23, 22], [23, 23], [23, 24], [23, 26], [24, 2], [24, 3], [24, 8], [24, 9], [24, 12], [24, 13], [24, 15], [24, 16], [24, 18], [24, 19], [24, 22], [24, 23], [25, 3], [25, 6], [25, 9], [25, 13], [25, 18], [26, 8], [26, 14], [26, 15], [26, 16], [26, 17], [26, 19], [27, 9], [27, 15], [27, 16], [27, 18], [27, 20], [27, 22], [28, 9]]}\n",
      "[[3 0 0 0 0 0 0 0 0 8 3 3 1 0 8 0 0 8 0 1 3 3 8 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 8 0 3 0 0 1 0 0 0 0 1 0 0 9 9 9 9 9 0 0 0 0]\n",
      " [0 0 7 7 0 0 4 0 3 3 4 4 8 0 6 6 6 6 0 8 4 9 9 9 9 9 0 0 7 7]\n",
      " [0 0 7 0 0 3 0 0 3 0 4 0 0 0 6 6 6 6 0 0 0 9 9 9 9 9 3 0 0 7]\n",
      " [0 0 0 0 0 0 1 1 1 0 8 0 3 0 8 0 0 8 0 3 0 9 9 9 9 9 0 0 0 0]\n",
      " [0 0 0 3 0 0 1 1 0 1 0 0 0 3 0 0 0 0 3 0 0 0 1 0 1 1 0 0 3 0]\n",
      " [0 0 4 0 1 1 0 2 8 0 6 6 8 0 1 1 1 1 0 8 6 6 0 8 2 0 1 1 0 4]\n",
      " [0 3 0 0 1 1 2 2 0 0 6 6 0 0 1 0 0 1 0 0 6 6 0 0 2 2 1 1 0 0]\n",
      " [0 8 3 3 1 0 8 0 0 0 1 0 0 5 7 0 0 7 5 0 0 1 0 0 0 8 0 1 3 3]\n",
      " [8 0 3 0 0 1 0 0 0 8 0 0 5 0 0 7 7 0 0 5 0 0 8 0 0 0 1 0 0 3]\n",
      " [3 3 4 4 8 0 6 6 1 0 2 2 7 0 0 7 7 0 0 7 2 2 0 1 6 6 0 8 4 4]\n",
      " [3 0 4 0 0 0 6 6 0 0 2 0 0 7 7 0 0 7 7 0 0 2 0 0 6 6 0 0 0 4]\n",
      " [1 0 8 0 3 0 8 0 0 5 7 0 0 5 0 0 0 0 5 0 0 7 5 0 0 8 0 3 0 8]\n",
      " [0 1 0 0 0 3 0 0 5 0 0 7 5 5 0 0 0 0 5 5 7 0 0 5 0 0 3 0 0 0]\n",
      " [8 0 6 6 8 0 1 1 7 0 0 7 0 0 0 0 0 0 0 0 7 0 0 7 1 1 0 8 6 6]\n",
      " [0 0 6 6 0 0 1 0 0 7 7 0 0 0 0 8 8 0 0 0 0 7 7 0 0 1 0 0 6 6]\n",
      " [0 0 6 6 0 0 1 0 0 9 9 0 0 0 0 8 8 0 0 0 0 7 7 0 0 1 0 0 6 6]\n",
      " [8 0 6 6 8 0 1 1 7 9 9 7 0 0 0 0 0 0 0 0 7 0 0 7 1 1 0 8 6 6]\n",
      " [0 1 0 0 0 3 0 0 5 0 0 7 5 5 0 0 0 0 5 5 7 9 9 5 0 0 3 0 0 0]\n",
      " [1 0 8 0 3 0 8 0 0 5 7 0 0 5 0 0 0 0 5 0 0 9 9 0 0 8 0 3 0 8]\n",
      " [3 0 4 0 0 0 6 6 0 0 2 0 0 7 7 0 0 7 7 0 0 9 9 0 6 6 0 0 0 4]\n",
      " [3 3 4 4 8 0 6 6 1 0 2 2 7 0 0 7 7 0 0 7 2 2 0 1 6 6 0 8 4 4]\n",
      " [8 0 3 0 0 1 0 0 0 8 0 0 5 0 0 7 7 0 0 5 0 0 8 0 0 0 1 0 0 3]\n",
      " [0 8 3 3 1 0 8 0 0 0 1 0 0 5 7 0 0 7 5 0 0 1 0 0 0 8 0 1 3 3]\n",
      " [0 3 0 0 1 1 2 2 0 0 6 6 0 0 1 0 0 1 0 0 6 6 0 0 2 2 1 1 0 0]\n",
      " [0 0 4 0 1 1 0 2 8 0 6 6 8 0 1 1 1 1 0 8 9 9 9 9 9 9 1 1 0 4]\n",
      " [0 0 0 3 0 0 1 1 0 1 0 0 0 3 0 0 0 0 3 0 9 9 9 9 9 9 0 0 3 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 8 0 3 0 8 0 0 8 0 3 0 8 0 1 1 1 0 0 0 0]\n",
      " [0 0 7 0 0 3 0 0 3 0 4 0 0 0 6 6 6 9 9 9 9 9 9 9 0 0 3 0 0 7]\n",
      " [0 0 7 7 0 0 4 0 3 3 4 4 8 0 6 6 6 9 9 9 9 9 9 9 0 4 0 0 7 7]]\n",
      "[[3 0 0 0 0 0 0 0 0 8 3 3 1 0 8 0 0 8 0 1 3 3 8 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 8 0 3 0 0 1 0 0 0 0 1 0 0 9 9 9 9 9 0 0 0 0]\n",
      " [0 0 7 7 0 0 4 0 3 3 4 4 8 0 6 6 6 6 0 8 4 9 9 9 9 9 0 0 7 7]\n",
      " [0 0 7 0 0 3 0 0 3 0 4 0 0 0 6 6 6 6 0 0 0 9 9 9 9 9 3 0 0 7]\n",
      " [0 0 0 0 0 0 1 1 1 0 8 0 3 0 8 0 0 8 0 3 0 9 9 9 9 9 0 0 0 0]\n",
      " [0 0 0 3 0 0 1 1 0 1 0 0 0 3 0 0 0 0 3 0 0 0 1 0 1 1 0 0 3 0]\n",
      " [0 0 4 0 1 1 0 2 8 0 6 6 8 0 1 1 1 1 0 8 6 6 0 8 2 0 1 1 0 4]\n",
      " [0 3 0 0 1 1 2 2 0 0 6 6 0 0 1 0 0 1 0 0 6 6 0 0 2 2 1 1 0 0]\n",
      " [0 8 3 3 1 0 8 0 0 0 1 0 0 5 7 0 0 7 5 0 0 1 0 0 0 8 0 1 3 3]\n",
      " [8 0 3 0 0 1 0 0 0 8 0 0 5 0 0 7 7 0 0 5 0 0 8 0 0 0 1 0 0 3]\n",
      " [3 3 4 4 8 0 6 6 1 0 2 2 7 0 0 7 7 0 0 7 2 2 0 1 6 6 0 8 4 4]\n",
      " [3 0 4 0 0 0 6 6 0 0 2 0 0 7 7 0 0 7 7 0 0 2 0 0 6 6 0 0 0 4]\n",
      " [1 0 8 0 3 0 8 0 0 5 7 0 0 5 0 0 0 0 5 0 0 7 5 0 0 8 0 3 0 8]\n",
      " [0 1 0 0 0 3 0 0 5 0 0 7 5 5 0 0 0 0 5 5 7 0 0 5 0 0 3 0 0 0]\n",
      " [8 0 6 6 8 0 1 1 7 0 0 7 0 0 0 0 0 0 0 0 7 0 0 7 1 1 0 8 6 6]\n",
      " [0 0 6 6 0 0 1 0 0 7 7 0 0 0 0 8 8 0 0 0 0 7 7 0 0 1 0 0 6 6]\n",
      " [0 0 6 6 0 0 1 0 0 9 9 0 0 0 0 8 8 0 0 0 0 7 7 0 0 1 0 0 6 6]\n",
      " [8 0 6 6 8 0 1 1 7 9 9 7 0 0 0 0 0 0 0 0 7 0 0 7 1 1 0 8 6 6]\n",
      " [0 1 0 0 0 3 0 0 5 0 0 7 5 5 0 0 0 0 5 5 7 9 9 5 0 0 3 0 0 0]\n",
      " [1 0 8 0 3 0 8 0 0 5 7 0 0 5 0 0 0 0 5 0 0 9 9 0 0 8 0 3 0 8]\n",
      " [3 0 4 0 0 0 6 6 0 0 2 0 0 7 7 0 0 7 7 0 0 9 9 0 6 6 0 0 0 4]\n",
      " [3 3 4 4 8 0 6 6 1 0 2 2 7 0 0 7 7 0 0 7 2 2 0 1 6 6 0 8 4 4]\n",
      " [8 0 3 0 0 1 0 0 0 8 0 0 5 0 0 7 7 0 0 5 0 0 8 0 0 0 1 0 0 3]\n",
      " [0 8 3 3 1 0 8 0 0 0 1 0 0 5 7 0 0 7 5 0 0 1 0 0 0 8 0 1 3 3]\n",
      " [0 3 0 0 1 1 2 2 0 0 6 6 0 0 1 0 0 1 0 0 6 6 0 0 2 2 1 1 0 0]\n",
      " [0 0 4 0 1 1 0 2 8 0 6 6 8 0 1 1 1 1 0 8 9 9 9 9 9 9 1 1 0 4]\n",
      " [0 0 0 3 0 0 1 1 0 1 0 0 0 3 0 0 0 0 3 0 9 9 9 9 9 9 0 0 3 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 8 0 3 0 8 0 0 8 0 3 0 8 0 1 1 1 0 0 0 0]\n",
      " [0 0 7 0 0 3 0 0 3 0 4 0 0 0 6 6 6 9 9 9 9 9 9 9 0 0 3 0 0 7]\n",
      " [0 0 7 7 0 0 4 0 3 3 4 4 8 0 6 6 6 9 9 9 9 9 9 9 0 4 0 0 7 7]]\n",
      "[[ 0  9]\n",
      " [ 0 10]\n",
      " [ 0 11]\n",
      " [ 0 12]\n",
      " [ 0 14]\n",
      " [ 0 17]\n",
      " [ 0 19]\n",
      " [ 0 20]\n",
      " [ 0 21]\n",
      " [ 0 22]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1 10]\n",
      " [ 1 13]\n",
      " [ 1 18]\n",
      " [ 1 21]\n",
      " [ 1 22]\n",
      " [ 1 23]\n",
      " [ 1 24]\n",
      " [ 1 25]\n",
      " [ 2  6]\n",
      " [ 2  8]\n",
      " [ 2  9]\n",
      " [ 2 10]\n",
      " [ 2 11]\n",
      " [ 2 12]\n",
      " [ 2 14]\n",
      " [ 2 15]\n",
      " [ 2 16]\n",
      " [ 2 17]\n",
      " [ 2 19]\n",
      " [ 2 20]\n",
      " [ 2 21]\n",
      " [ 2 22]\n",
      " [ 2 23]\n",
      " [ 2 24]\n",
      " [ 2 25]\n",
      " [ 3  5]\n",
      " [ 3  8]\n",
      " [ 3 10]\n",
      " [ 3 14]\n",
      " [ 3 15]\n",
      " [ 3 16]\n",
      " [ 3 17]\n",
      " [ 3 21]\n",
      " [ 3 22]\n",
      " [ 3 23]\n",
      " [ 3 24]\n",
      " [ 3 25]\n",
      " [ 3 26]\n",
      " [ 4  6]\n",
      " [ 4  7]\n",
      " [ 4  8]\n",
      " [ 4 10]\n",
      " [ 4 12]\n",
      " [ 4 14]\n",
      " [ 4 17]\n",
      " [ 4 19]\n",
      " [ 4 21]\n",
      " [ 4 22]\n",
      " [ 4 23]\n",
      " [ 4 24]\n",
      " [ 4 25]\n",
      " [ 5  3]\n",
      " [ 5  6]\n",
      " [ 5  7]\n",
      " [ 5  9]\n",
      " [ 5 13]\n",
      " [ 5 18]\n",
      " [ 5 22]\n",
      " [ 5 24]\n",
      " [ 5 25]\n",
      " [ 5 28]\n",
      " [ 6  2]\n",
      " [ 6  4]\n",
      " [ 6  5]\n",
      " [ 6  7]\n",
      " [ 6  8]\n",
      " [ 6 10]\n",
      " [ 6 11]\n",
      " [ 6 12]\n",
      " [ 6 14]\n",
      " [ 6 15]\n",
      " [ 6 16]\n",
      " [ 6 17]\n",
      " [ 6 19]\n",
      " [ 6 20]\n",
      " [ 6 21]\n",
      " [ 6 23]\n",
      " [ 6 24]\n",
      " [ 6 26]\n",
      " [ 6 27]\n",
      " [ 6 29]\n",
      " [ 7  1]\n",
      " [ 7  4]\n",
      " [ 7  5]\n",
      " [ 7  6]\n",
      " [ 7  7]\n",
      " [ 7 10]\n",
      " [ 7 11]\n",
      " [ 7 14]\n",
      " [ 7 17]\n",
      " [ 7 20]\n",
      " [ 7 21]\n",
      " [ 7 24]\n",
      " [ 7 25]\n",
      " [ 7 26]\n",
      " [ 7 27]\n",
      " [ 8  1]\n",
      " [ 8  2]\n",
      " [ 8  3]\n",
      " [ 8  4]\n",
      " [ 8  6]\n",
      " [ 8 10]\n",
      " [ 8 13]\n",
      " [ 8 14]\n",
      " [ 8 17]\n",
      " [ 8 18]\n",
      " [ 8 21]\n",
      " [ 8 25]\n",
      " [ 8 27]\n",
      " [ 8 28]\n",
      " [ 8 29]\n",
      " [ 9  0]\n",
      " [ 9  2]\n",
      " [ 9  5]\n",
      " [ 9  9]\n",
      " [ 9 12]\n",
      " [ 9 15]\n",
      " [ 9 16]\n",
      " [ 9 19]\n",
      " [ 9 22]\n",
      " [ 9 26]\n",
      " [ 9 29]\n",
      " [10  0]\n",
      " [10  1]\n",
      " [10  2]\n",
      " [10  3]\n",
      " [10  4]\n",
      " [10  6]\n",
      " [10  7]\n",
      " [10  8]\n",
      " [10 10]\n",
      " [10 11]\n",
      " [10 12]\n",
      " [10 15]\n",
      " [10 16]\n",
      " [10 19]\n",
      " [10 20]\n",
      " [10 21]\n",
      " [10 23]\n",
      " [10 24]\n",
      " [10 25]\n",
      " [10 27]\n",
      " [10 28]\n",
      " [10 29]\n",
      " [11  0]\n",
      " [11  2]\n",
      " [11  6]\n",
      " [11  7]\n",
      " [11 10]\n",
      " [11 13]\n",
      " [11 14]\n",
      " [11 17]\n",
      " [11 18]\n",
      " [11 21]\n",
      " [11 24]\n",
      " [11 25]\n",
      " [11 29]\n",
      " [12  0]\n",
      " [12  2]\n",
      " [12  4]\n",
      " [12  6]\n",
      " [12  9]\n",
      " [12 10]\n",
      " [12 13]\n",
      " [12 18]\n",
      " [12 21]\n",
      " [12 22]\n",
      " [12 25]\n",
      " [12 27]\n",
      " [12 29]\n",
      " [13  1]\n",
      " [13  5]\n",
      " [13  8]\n",
      " [13 11]\n",
      " [13 12]\n",
      " [13 13]\n",
      " [13 18]\n",
      " [13 19]\n",
      " [13 20]\n",
      " [13 23]\n",
      " [13 26]\n",
      " [14  0]\n",
      " [14  2]\n",
      " [14  3]\n",
      " [14  4]\n",
      " [14  6]\n",
      " [14  7]\n",
      " [14  8]\n",
      " [14 11]\n",
      " [14 20]\n",
      " [14 23]\n",
      " [14 24]\n",
      " [14 25]\n",
      " [14 27]\n",
      " [14 28]\n",
      " [14 29]\n",
      " [15  2]\n",
      " [15  3]\n",
      " [15  6]\n",
      " [15  9]\n",
      " [15 10]\n",
      " [15 21]\n",
      " [15 22]\n",
      " [15 25]\n",
      " [15 28]\n",
      " [15 29]\n",
      " [16  2]\n",
      " [16  3]\n",
      " [16  6]\n",
      " [16  9]\n",
      " [16 10]\n",
      " [16 21]\n",
      " [16 22]\n",
      " [16 25]\n",
      " [16 28]\n",
      " [16 29]\n",
      " [17  0]\n",
      " [17  2]\n",
      " [17  3]\n",
      " [17  4]\n",
      " [17  6]\n",
      " [17  7]\n",
      " [17  8]\n",
      " [17  9]\n",
      " [17 10]\n",
      " [17 11]\n",
      " [17 20]\n",
      " [17 23]\n",
      " [17 24]\n",
      " [17 25]\n",
      " [17 27]\n",
      " [17 28]\n",
      " [17 29]\n",
      " [18  1]\n",
      " [18  5]\n",
      " [18  8]\n",
      " [18 11]\n",
      " [18 12]\n",
      " [18 13]\n",
      " [18 18]\n",
      " [18 19]\n",
      " [18 20]\n",
      " [18 21]\n",
      " [18 22]\n",
      " [18 23]\n",
      " [18 26]\n",
      " [19  0]\n",
      " [19  2]\n",
      " [19  4]\n",
      " [19  6]\n",
      " [19  9]\n",
      " [19 10]\n",
      " [19 13]\n",
      " [19 18]\n",
      " [19 21]\n",
      " [19 22]\n",
      " [19 25]\n",
      " [19 27]\n",
      " [19 29]\n",
      " [20  0]\n",
      " [20  2]\n",
      " [20  6]\n",
      " [20  7]\n",
      " [20 10]\n",
      " [20 13]\n",
      " [20 14]\n",
      " [20 17]\n",
      " [20 18]\n",
      " [20 21]\n",
      " [20 22]\n",
      " [20 24]\n",
      " [20 25]\n",
      " [20 29]\n",
      " [21  0]\n",
      " [21  1]\n",
      " [21  2]\n",
      " [21  3]\n",
      " [21  4]\n",
      " [21  6]\n",
      " [21  7]\n",
      " [21  8]\n",
      " [21 10]\n",
      " [21 11]\n",
      " [21 12]\n",
      " [21 15]\n",
      " [21 16]\n",
      " [21 19]\n",
      " [21 20]\n",
      " [21 21]\n",
      " [21 23]\n",
      " [21 24]\n",
      " [21 25]\n",
      " [21 27]\n",
      " [21 28]\n",
      " [21 29]\n",
      " [22  0]\n",
      " [22  2]\n",
      " [22  5]\n",
      " [22  9]\n",
      " [22 12]\n",
      " [22 15]\n",
      " [22 16]\n",
      " [22 19]\n",
      " [22 22]\n",
      " [22 26]\n",
      " [22 29]\n",
      " [23  1]\n",
      " [23  2]\n",
      " [23  3]\n",
      " [23  4]\n",
      " [23  6]\n",
      " [23 10]\n",
      " [23 13]\n",
      " [23 14]\n",
      " [23 17]\n",
      " [23 18]\n",
      " [23 21]\n",
      " [23 25]\n",
      " [23 27]\n",
      " [23 28]\n",
      " [23 29]\n",
      " [24  1]\n",
      " [24  4]\n",
      " [24  5]\n",
      " [24  6]\n",
      " [24  7]\n",
      " [24 10]\n",
      " [24 11]\n",
      " [24 14]\n",
      " [24 17]\n",
      " [24 20]\n",
      " [24 21]\n",
      " [24 24]\n",
      " [24 25]\n",
      " [24 26]\n",
      " [24 27]\n",
      " [25  2]\n",
      " [25  4]\n",
      " [25  5]\n",
      " [25  7]\n",
      " [25  8]\n",
      " [25 10]\n",
      " [25 11]\n",
      " [25 12]\n",
      " [25 14]\n",
      " [25 15]\n",
      " [25 16]\n",
      " [25 17]\n",
      " [25 19]\n",
      " [25 20]\n",
      " [25 21]\n",
      " [25 22]\n",
      " [25 23]\n",
      " [25 24]\n",
      " [25 25]\n",
      " [25 26]\n",
      " [25 27]\n",
      " [25 29]\n",
      " [26  3]\n",
      " [26  6]\n",
      " [26  7]\n",
      " [26  9]\n",
      " [26 13]\n",
      " [26 18]\n",
      " [26 20]\n",
      " [26 21]\n",
      " [26 22]\n",
      " [26 23]\n",
      " [26 24]\n",
      " [26 25]\n",
      " [26 28]\n",
      " [27  6]\n",
      " [27  7]\n",
      " [27  8]\n",
      " [27 10]\n",
      " [27 12]\n",
      " [27 14]\n",
      " [27 17]\n",
      " [27 19]\n",
      " [27 21]\n",
      " [27 23]\n",
      " [27 24]\n",
      " [27 25]\n",
      " [28  5]\n",
      " [28  8]\n",
      " [28 10]\n",
      " [28 14]\n",
      " [28 15]\n",
      " [28 16]\n",
      " [28 17]\n",
      " [28 18]\n",
      " [28 19]\n",
      " [28 20]\n",
      " [28 21]\n",
      " [28 22]\n",
      " [28 23]\n",
      " [28 26]\n",
      " [29  6]\n",
      " [29  8]\n",
      " [29  9]\n",
      " [29 10]\n",
      " [29 11]\n",
      " [29 12]\n",
      " [29 14]\n",
      " [29 15]\n",
      " [29 16]\n",
      " [29 17]\n",
      " [29 18]\n",
      " [29 19]\n",
      " [29 20]\n",
      " [29 21]\n",
      " [29 22]\n",
      " [29 23]\n",
      " [29 25]]\n"
     ]
    }
   ],
   "source": [
    "dd = task_data.train_tensors[1][0].objects[1]\n",
    "print(dd.attributes)\n",
    "print(dd.grid)\n",
    "print(dd.parent_grid)\n",
    "print(dd.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_colors': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_unique_colors': 10, 'n_unique_non_backg_colors': 9, 'grid_colors_perc': OrderedDict([(0, 0.5933333333333334), (9, 0.13666666666666666), (7, 0.09111111111111111), (1, 0.04888888888888889), (5, 0.044444444444444446), (4, 0.04), (2, 0.016666666666666666), (6, 0.013333333333333334), (8, 0.012222222222222223), (3, 0.0033333333333333335)]), 'max_color_perc': 0.5933333333333334, 'most_common_color': 0, 'second_most_common_color': 9, 'least_common_color': 3, 'grid_shape': (30, 30), 'v_shape': 30, 'h_shape': 30, 'v_shape_half': 15, 'h_shape_half': 15, 'v_shape_third': 10, 'h_shape_third': 10, 'h_symm': False, 'v_symm': False, 'ld_symm': False, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': (0, 15), 'left_mid_point': (15, 0), 'lines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}}\n",
      "[[0 0 0 0 0 0 0 0 6 6 5 5 0 1 0 0 0 0 1 0 5 5 6 6 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 6 6 5 0 1 0 0 7 7 0 0 1 0 5 6 6 0 0 5 0 0 0]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 7 0 8 0 0 9 9 9 9 9 9 9 0 0 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 4 0 0 5 9 9 9 9 9 9 9 0 5 0 9 9 9 9 9 9 9 9]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 9 9 9 9 9 9 9 0 0 5 9 9 9 9 9 9 4 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 9 9 9 9 9 9 9 1 0 0 9 9 9 9 9 9 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 9 9 9 9 9 9 9 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 9 9 9 9 9 9 9 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 0 1 1 0 0 1 1 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 4 0 7 0 0]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 0 0 7 0 0 7 0 0 0 5 0 0 2 0 7 0 4 0]\n",
      " [5 5 4 0 0 0 0 0 4 0 0 5 0 0 0 7 7 0 0 0 5 0 0 4 0 0 0 0 0 4]\n",
      " [6 6 5 0 1 0 0 7 0 8 0 0 0 0 0 0 0 0 0 0 0 0 8 0 7 0 0 1 0 5]\n",
      " [6 6 5 5 0 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 1 0 5 5]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 7 0 0 0 0 0 0 7]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 0 0 0 3 0 0 7 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]]\n",
      "[[0 0 0 0 0 0 0 0 6 6 5 5 0 1 0 0 0 0 1 0 5 5 6 6 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 6 6 5 0 1 0 0 7 7 0 0 1 0 5 6 6 0 0 5 0 0 0]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 7 0 8 0 0 9 9 9 9 9 9 9 0 0 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 4 0 0 5 9 9 9 9 9 9 9 0 5 0 9 9 9 9 9 9 9 9]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 9 9 9 9 9 9 9 0 0 5 9 9 9 9 9 9 4 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 9 9 9 9 9 9 9 1 0 0 9 9 9 9 9 9 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 9 9 9 9 9 9 9 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 9 9 9 9 9 9 9 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 0 1 1 0 0 1 1 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 4 0 7 0 0]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 0 0 7 0 0 7 0 0 0 5 0 0 2 0 7 0 4 0]\n",
      " [5 5 4 0 0 0 0 0 4 0 0 5 0 0 0 7 7 0 0 0 5 0 0 4 0 0 0 0 0 4]\n",
      " [6 6 5 0 1 0 0 7 0 8 0 0 0 0 0 0 0 0 0 0 0 0 8 0 7 0 0 1 0 5]\n",
      " [6 6 5 5 0 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 1 0 5 5]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 7 0 0 0 0 0 0 7]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 0 0 0 3 0 0 7 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]]\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [0, 14], [0, 15], [0, 16], [0, 17], [0, 18], [0, 19], [0, 20], [0, 21], [0, 22], [0, 23], [0, 24], [0, 25], [0, 26], [0, 27], [0, 28], [0, 29], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [1, 15], [1, 16], [1, 17], [1, 18], [1, 19], [1, 20], [1, 21], [1, 22], [1, 23], [1, 24], [1, 25], [1, 26], [1, 27], [1, 28], [1, 29], [2, 0], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [2, 15], [2, 16], [2, 17], [2, 18], [2, 19], [2, 20], [2, 21], [2, 22], [2, 23], [2, 24], [2, 25], [2, 26], [2, 27], [2, 28], [2, 29], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14], [3, 15], [3, 16], [3, 17], [3, 18], [3, 19], [3, 20], [3, 21], [3, 22], [3, 23], [3, 24], [3, 25], [3, 26], [3, 27], [3, 28], [3, 29], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [4, 15], [4, 16], [4, 17], [4, 18], [4, 19], [4, 20], [4, 21], [4, 22], [4, 23], [4, 24], [4, 25], [4, 26], [4, 27], [4, 28], [4, 29], [5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [5, 15], [5, 16], [5, 17], [5, 18], [5, 19], [5, 20], [5, 21], [5, 22], [5, 23], [5, 24], [5, 25], [5, 26], [5, 27], [5, 28], [5, 29], [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [6, 15], [6, 16], [6, 17], [6, 18], [6, 19], [6, 20], [6, 21], [6, 22], [6, 23], [6, 24], [6, 25], [6, 26], [6, 27], [6, 28], [6, 29], [7, 0], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 17], [7, 18], [7, 19], [7, 20], [7, 21], [7, 22], [7, 23], [7, 24], [7, 25], [7, 26], [7, 27], [7, 28], [7, 29], [8, 0], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [8, 15], [8, 16], [8, 17], [8, 18], [8, 19], [8, 20], [8, 21], [8, 22], [8, 23], [8, 24], [8, 25], [8, 26], [8, 27], [8, 28], [8, 29], [9, 0], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14], [9, 15], [9, 16], [9, 17], [9, 18], [9, 19], [9, 20], [9, 21], [9, 22], [9, 23], [9, 24], [9, 25], [9, 26], [9, 27], [9, 28], [9, 29], [10, 0], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [10, 14], [10, 15], [10, 16], [10, 17], [10, 18], [10, 19], [10, 20], [10, 21], [10, 22], [10, 23], [10, 24], [10, 25], [10, 26], [10, 27], [10, 28], [10, 29], [11, 0], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [11, 14], [11, 15], [11, 16], [11, 17], [11, 18], [11, 19], [11, 20], [11, 21], [11, 22], [11, 23], [11, 24], [11, 25], [11, 26], [11, 27], [11, 28], [11, 29], [12, 0], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [12, 14], [12, 15], [12, 16], [12, 17], [12, 18], [12, 19], [12, 20], [12, 21], [12, 22], [12, 23], [12, 24], [12, 25], [12, 26], [12, 27], [12, 28], [12, 29], [13, 0], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13], [13, 14], [13, 15], [13, 16], [13, 17], [13, 18], [13, 19], [13, 20], [13, 21], [13, 22], [13, 23], [13, 24], [13, 25], [13, 26], [13, 27], [13, 28], [13, 29], [14, 0], [14, 1], [14, 2], [14, 3], [14, 4], [14, 5], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 11], [14, 12], [14, 13], [14, 14], [14, 15], [14, 16], [14, 17], [14, 18], [14, 19], [14, 20], [14, 21], [14, 22], [14, 23], [14, 24], [14, 25], [14, 26], [14, 27], [14, 28], [14, 29], [15, 0], [15, 1], [15, 2], [15, 3], [15, 4], [15, 5], [15, 6], [15, 7], [15, 8], [15, 9], [15, 10], [15, 11], [15, 12], [15, 13], [15, 14], [15, 15], [15, 16], [15, 17], [15, 18], [15, 19], [15, 20], [15, 21], [15, 22], [15, 23], [15, 24], [15, 25], [15, 26], [15, 27], [15, 28], [15, 29], [16, 0], [16, 1], [16, 2], [16, 3], [16, 4], [16, 5], [16, 6], [16, 7], [16, 8], [16, 9], [16, 10], [16, 11], [16, 12], [16, 13], [16, 14], [16, 15], [16, 16], [16, 17], [16, 18], [16, 19], [16, 20], [16, 21], [16, 22], [16, 23], [16, 24], [16, 25], [16, 26], [16, 27], [16, 28], [16, 29], [17, 0], [17, 1], [17, 2], [17, 3], [17, 4], [17, 5], [17, 6], [17, 7], [17, 8], [17, 9], [17, 10], [17, 11], [17, 12], [17, 13], [17, 14], [17, 15], [17, 16], [17, 17], [17, 18], [17, 19], [17, 20], [17, 21], [17, 22], [17, 23], [17, 24], [17, 25], [17, 26], [17, 27], [17, 28], [17, 29], [18, 0], [18, 1], [18, 2], [18, 3], [18, 4], [18, 5], [18, 6], [18, 7], [18, 8], [18, 9], [18, 10], [18, 11], [18, 12], [18, 13], [18, 14], [18, 15], [18, 16], [18, 17], [18, 18], [18, 19], [18, 20], [18, 21], [18, 22], [18, 23], [18, 24], [18, 25], [18, 26], [18, 27], [18, 28], [18, 29], [19, 0], [19, 1], [19, 2], [19, 3], [19, 4], [19, 5], [19, 6], [19, 7], [19, 8], [19, 9], [19, 10], [19, 11], [19, 12], [19, 13], [19, 14], [19, 15], [19, 16], [19, 17], [19, 18], [19, 19], [19, 20], [19, 21], [19, 22], [19, 23], [19, 24], [19, 25], [19, 26], [19, 27], [19, 28], [19, 29], [20, 0], [20, 1], [20, 2], [20, 3], [20, 4], [20, 5], [20, 6], [20, 7], [20, 8], [20, 9], [20, 10], [20, 11], [20, 12], [20, 13], [20, 14], [20, 15], [20, 16], [20, 17], [20, 18], [20, 19], [20, 20], [20, 21], [20, 22], [20, 23], [20, 24], [20, 25], [20, 26], [20, 27], [20, 28], [20, 29], [21, 0], [21, 1], [21, 2], [21, 3], [21, 4], [21, 5], [21, 6], [21, 7], [21, 8], [21, 9], [21, 10], [21, 11], [21, 12], [21, 13], [21, 14], [21, 15], [21, 16], [21, 17], [21, 18], [21, 19], [21, 20], [21, 21], [21, 22], [21, 23], [21, 24], [21, 25], [21, 26], [21, 27], [21, 28], [21, 29], [22, 0], [22, 1], [22, 2], [22, 3], [22, 4], [22, 5], [22, 6], [22, 7], [22, 8], [22, 9], [22, 10], [22, 11], [22, 12], [22, 13], [22, 14], [22, 15], [22, 16], [22, 17], [22, 18], [22, 19], [22, 20], [22, 21], [22, 22], [22, 23], [22, 24], [22, 25], [22, 26], [22, 27], [22, 28], [22, 29], [23, 0], [23, 1], [23, 2], [23, 3], [23, 4], [23, 5], [23, 6], [23, 7], [23, 8], [23, 9], [23, 10], [23, 11], [23, 12], [23, 13], [23, 14], [23, 15], [23, 16], [23, 17], [23, 18], [23, 19], [23, 20], [23, 21], [23, 22], [23, 23], [23, 24], [23, 25], [23, 26], [23, 27], [23, 28], [23, 29], [24, 0], [24, 1], [24, 2], [24, 3], [24, 4], [24, 5], [24, 6], [24, 7], [24, 8], [24, 9], [24, 10], [24, 11], [24, 12], [24, 13], [24, 14], [24, 15], [24, 16], [24, 17], [24, 18], [24, 19], [24, 20], [24, 21], [24, 22], [24, 23], [24, 24], [24, 25], [24, 26], [24, 27], [24, 28], [24, 29], [25, 0], [25, 1], [25, 2], [25, 3], [25, 4], [25, 5], [25, 6], [25, 7], [25, 8], [25, 9], [25, 10], [25, 11], [25, 12], [25, 13], [25, 14], [25, 15], [25, 16], [25, 17], [25, 18], [25, 19], [25, 20], [25, 21], [25, 22], [25, 23], [25, 24], [25, 25], [25, 26], [25, 27], [25, 28], [25, 29], [26, 0], [26, 1], [26, 2], [26, 3], [26, 4], [26, 5], [26, 6], [26, 7], [26, 8], [26, 9], [26, 10], [26, 11], [26, 12], [26, 13], [26, 14], [26, 15], [26, 16], [26, 17], [26, 18], [26, 19], [26, 20], [26, 21], [26, 22], [26, 23], [26, 24], [26, 25], [26, 26], [26, 27], [26, 28], [26, 29], [27, 0], [27, 1], [27, 2], [27, 3], [27, 4], [27, 5], [27, 6], [27, 7], [27, 8], [27, 9], [27, 10], [27, 11], [27, 12], [27, 13], [27, 14], [27, 15], [27, 16], [27, 17], [27, 18], [27, 19], [27, 20], [27, 21], [27, 22], [27, 23], [27, 24], [27, 25], [27, 26], [27, 27], [27, 28], [27, 29], [28, 0], [28, 1], [28, 2], [28, 3], [28, 4], [28, 5], [28, 6], [28, 7], [28, 8], [28, 9], [28, 10], [28, 11], [28, 12], [28, 13], [28, 14], [28, 15], [28, 16], [28, 17], [28, 18], [28, 19], [28, 20], [28, 21], [28, 22], [28, 23], [28, 24], [28, 25], [28, 26], [28, 27], [28, 28], [28, 29], [29, 0], [29, 1], [29, 2], [29, 3], [29, 4], [29, 5], [29, 6], [29, 7], [29, 8], [29, 9], [29, 10], [29, 11], [29, 12], [29, 13], [29, 14], [29, 15], [29, 16], [29, 17], [29, 18], [29, 19], [29, 20], [29, 21], [29, 22], [29, 23], [29, 24], [29, 25], [29, 26], [29, 27], [29, 28], [29, 29]]\n"
     ]
    }
   ],
   "source": [
    "#rr = Region(task_data.train_tensors[0][0].grid,regions[0])\n",
    "#rr.compute_attributes()\n",
    "rr = task_data.train_tensors[0][0].regions[0]\n",
    "print(rr.attributes)\n",
    "print(rr.grid)\n",
    "print(rr.parent_grid)\n",
    "print(rr.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newly solved tasks:  [1, 48, 186, 250, 337]\n",
      "old broken tasks:  [371]\n"
     ]
    }
   ],
   "source": [
    "score_old =   [2, 5, 13, 25, 30, 35, 38, 47, 55, 56, 71, 82, 86, 99, 102, 112, 115, 128, 134, 139, 141, 143, 145, 149, 151, 152, 154, 163, 171, 176, 178, 187, 195, 206, 209, 210, 222, 226, 230, 235, 240, 243, 248, 258, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 317, 318, 325, 346, 371, 379, 383, 384, 385, 388, 394]\n",
    "score_new = [1, 2, 5, 13, 25, 30, 35, 38, 47, 48, 55, 56, 71, 82, 86, 99, 102, 112, 115, 128, 134, 139, 141, 143, 145, 149, 151, 152, 154, 163, 171, 176, 178, 186, 187, 195, 206, 209, 210, 222, 226, 230, 235, 240, 243, 248, 250, 258, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 317, 318, 325, 337, 346, 379, 383, 384, 385, 388, 394]\n",
    "\n",
    "print(\"newly solved tasks: \", [item for item in score_new if item not in score_old]) #[1, 48, 186, 250, 337]\n",
    "print(\"old broken tasks: \", [item for item in score_old if item not in score_new])\n",
    "# TODO tasks solved with filter_programs: 66,..\n",
    "# TODO tasks solved at some point: 48, 52, 128, 258, 345, 371...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}\n",
      "[[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [2, 0], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [7, 0], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [8, 0], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [9, 0], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [10, 0], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [11, 0], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [12, 0], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [13, 0], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = detect_lines(task_data.train_tensors[0][0].grid)\n",
    "#lines = detect_lines(task_data.test_tensors[0][0].grid)\n",
    "print(lines)\n",
    "#print(count_lines_regions(lines))\n",
    "regions = detect_regions(task_data.train_tensors[0][0].grid, lines)\n",
    "print(regions)\n",
    "len(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_task(train_task_data[48]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
