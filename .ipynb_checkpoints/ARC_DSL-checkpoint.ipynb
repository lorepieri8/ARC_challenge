{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 version:  4.1.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy\n",
    "import gc\n",
    "import cv2\n",
    "import requests\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as colors_mat\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "from skimage import measure\n",
    "from skimage.segmentation import flood, flood_fill\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from itertools import product\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.signal import convolve2d\n",
    "from collections import Counter\n",
    "from cv2 import matchTemplate as cv2m\n",
    "from math import sqrt; from itertools import count, islice\n",
    "print(\"cv2 version: \",cv2.__version__)\n",
    "\n",
    "DEBUG = True # Active logging, printing, etc. False when committing to the LB. \n",
    "url_slack = \"https://hooks.slack.com/services/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\"  # This is secret, do not share.\n",
    "headers = {'Content-type': 'application/json'}\n",
    "MAX_DIM_MATRIX = 30\n",
    "MAX_magic_args_number = 1000\n",
    "I_AM_IN_KAGGLE = os.path.isdir(\"/kaggle/input/abstraction-and-reasoning-challenge/\")\n",
    "black_square = np.full((2,2),0)\n",
    "DUMMY_COLOR = 17\n",
    "MAX_N_OBJECTS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Initial Data ...\n",
      "--- 0.012970924377441406 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Initial Data ...\")\n",
    "\n",
    "if I_AM_IN_KAGGLE:\n",
    "    data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "else:\n",
    "    data_path = Path('')\n",
    "training_path = data_path / 'training'\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "testing_path = data_path / 'test'\n",
    "\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "evaluation_tasks = sorted(os.listdir(evaluation_path))\n",
    "testing_tasks = sorted(os.listdir(testing_path))\n",
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Functions ...\n",
      "--- 0.005153179168701172 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Functions ...\")\n",
    "\n",
    "def flattener(pred):\n",
    "    \n",
    "    str_pred = str([row for row in pred.tolist()])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    \n",
    "    return str_pred\n",
    "\n",
    "def build_trainlist(task):\n",
    "    \n",
    "    task_data = []\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "        list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "    \n",
    "    return task_data\n",
    "\n",
    "def build_testlist(task, LB_submission=False, pair_id=0):\n",
    "    \n",
    "    task_data = []\n",
    "    \n",
    "    if LB_submission:\n",
    "        t_in = np.array(task[\"test\"][pair_id][\"input\"]).astype('uint8')       \n",
    "        list.append(task_data, (t_in.copy()))\n",
    "    else:\n",
    "        for i, t in enumerate(task[\"test\"]):\n",
    "            t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "            list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "          \n",
    "    return task_data\n",
    "\n",
    "def load_data(p, phase=None):\n",
    "    \n",
    "    if phase in {'training', 'test', 'evaluation'}:\n",
    "        p = data_path / phase / p\n",
    "    \n",
    "    task = json.loads(Path(p).read_text())\n",
    "    dict_vals_to_np = lambda x: { k : np.array(v) for k, v in x.items() }\n",
    "    assert set(task) == {'test', 'train'}\n",
    "    res = dict(test=[], train=[])\n",
    "    \n",
    "    for t in task['train']:\n",
    "        assert set(t) == {'input', 'output'}\n",
    "        res['train'].append(dict_vals_to_np(t))\n",
    "    for t in task['test']:\n",
    "        res['test'].append(dict_vals_to_np(t))\n",
    "        \n",
    "    return res\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Files ...\n",
      "--- 1.0167739391326904 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Files ...\")\n",
    "\n",
    "train_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(training_tasks[i], phase='training')\n",
    "    list.append(train_task_data, task)\n",
    "\n",
    "eval_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(evaluation_tasks[i], phase='evaluation')\n",
    "    list.append(eval_task_data, task)\n",
    "\n",
    "test_task_data = []\n",
    "for i in range(0, 100):\n",
    "    task = load_data(testing_tasks[i], phase='test')\n",
    "    list.append(test_task_data, task)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checking Functions\n",
      "--- 0.0024530887603759766 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Checking Functions\")\n",
    "\n",
    "cmap = colors_mat.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors_mat.Normalize(vmin=0, vmax=9)\n",
    "num2color = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\n",
    "color2num = {c: n for n, c in enumerate(num2color)}\n",
    "\n",
    "def plot_one(task, ax, i,train_or_test,input_or_output):\n",
    "    \n",
    "    input_matrix = task[train_or_test][i][input_or_output]\n",
    "    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
    "    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
    "    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(train_or_test + ' '+ input_or_output)\n",
    "    \n",
    "def plot_task(task):\n",
    "\n",
    "    num_train = len(task['train'])\n",
    "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
    "    for i in range(num_train):     \n",
    "        plot_one(task, axs[0,i],i,'train','input')\n",
    "        plot_one(task, axs[1,i],i,'train','output')        \n",
    "    plt.tight_layout()\n",
    "    plt.show()        \n",
    "        \n",
    "    num_test = len(task['test'])\n",
    "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
    "    if num_test==1: \n",
    "        plot_one(task, axs[0],0,'test','input')\n",
    "        plot_one(task, axs[1],0,'test','output')     \n",
    "    else:\n",
    "        for i in range(num_test):      \n",
    "            plot_one(task, axs[0,i],i,'test','input')\n",
    "            plot_one(task, axs[1,i],i,'test','output')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def check_p(task, pred_func):\n",
    "    \n",
    "    fig_num = 0\n",
    "    n = len(task[\"train\"]) + len(task[\"test\"])\n",
    "    fig, axs = plt.subplots(3, n, figsize=(4*n,12), dpi=50)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # All Data for Task\n",
    "    train_data = build_trainlist(task)\n",
    "    test_data = build_testlist(task)\n",
    "    task_data = Task(train_data, test_data)\n",
    "    \n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')   \n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Train-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Train-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Train-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "        \n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')\n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Test-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Test-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Test-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Main)\n",
      "--- 0.0019960403442382812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Main)\")\n",
    "\n",
    "# color the given coordinates points, passed as list of 2d list. Example: [[0,1],[2,3],[2,4]]\n",
    "def color_points(t,points_coord,color):\n",
    "    \n",
    "    t_copy = np.copy(t)\n",
    "    for point in points_coord:\n",
    "        t_copy[point[0],point[1]] = color\n",
    "    return t_copy\n",
    "\n",
    "# https://stackoverflow.com/questions/10823877/what-is-the-fastest-way-to-flatten-arbitrarily-nested-lists-in-python\n",
    "# flatten a list of nested lists\n",
    "def flatten_rec(container):\n",
    "    for i in container:\n",
    "        if isinstance(i, (list,tuple)):\n",
    "            for j in flatten_rec(i):\n",
    "                yield j\n",
    "        else:\n",
    "            yield i\n",
    "            \n",
    "#https://stackoverflow.com/questions/32531377/how-can-i-check-if-one-two-dimensional-numpy-array-contains-a-specific-pattern-o\n",
    "# return the coords of all the instances of template in grid (upper left corner)\n",
    "def match_template(grid, template):\n",
    "    \n",
    "    # check that the shapes are consinstent\n",
    "    if grid.shape == (1,):\n",
    "        return []\n",
    "    if template.shape == (1,):\n",
    "        pass \n",
    "    else:\n",
    "        if (grid.shape[0] < template.shape[0]) or (grid.shape[1] < template.shape[1]):\n",
    "            return []\n",
    "        \n",
    "    M = cv2m(grid.astype('uint8'),template.astype('uint8'),cv2.TM_SQDIFF)\n",
    "    x,y = np.where(M<0.01) # =0 can fail with floats\n",
    "    coords = list(zip(x, y))\n",
    "    return coords\n",
    "\n",
    "# https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical\n",
    "def checkEqual1(iterator):\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all(first == rest for rest in iterator)\n",
    "\n",
    "# expect a list of lists, check that all of them have more than N elements\n",
    "def checkAllMoreN(iterator, N):\n",
    "    if iterator == []:\n",
    "        return False\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "        if not (len(first) > N):\n",
    "            return False\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all( (len(rest) > N) for rest in iterator)\n",
    "\n",
    "def is_prime(n):\n",
    "    return n > 1 and all(n%i for i in islice(count(2), int(sqrt(n)-1)))\n",
    "\n",
    "# return max and min lenght objects in llist\n",
    "def checkMaxMinLen(llist):\n",
    "    max_len = 0\n",
    "    min_len = 100\n",
    "    for el in llist:\n",
    "        if len(el) > max_len:\n",
    "            max_len = len(el)\n",
    "        if len(el) < min_len:   \n",
    "            min_len = len(el)\n",
    "    return {\"min_len\":min_len, \"max_len\":max_len}\n",
    "        \n",
    "\n",
    "def send_slack_report(message):\n",
    "    data = {'auth_token': 'auth1', 'widget': 'id1', 'text': message}\n",
    "    r = requests.post(url_slack, data=json.dumps(data), headers=headers)\n",
    "\n",
    "def get_neighbors(grid, i, j):\n",
    "    \n",
    "    nbh = lambda x, i, j: { \n",
    "        (ip, jp) : x[i+ip, j+jp] \n",
    "            for ip, jp in product([1, -1, 0], repeat=2) \n",
    "                if 0 <= i+ip < x.shape[0] and 0 <= j+jp < x.shape[1]\n",
    "    }\n",
    "        \n",
    "    nbh_data = nbh(grid, i, j)\n",
    "    nbh_values = [(1, 1), (1, -1), (1, 0), (-1, 1), (-1, -1), \n",
    "                  (-1, 0), (0, 1), (0, -1), (0, 0)]\n",
    "\n",
    "    for val in nbh_values:\n",
    "        if val not in nbh_data:\n",
    "            nbh_data[val] = 0\n",
    "    \n",
    "    return nbh_data\n",
    "\n",
    "def get_background_color(grid):\n",
    "    \n",
    "    try:    \n",
    "        background_color = 0\n",
    "        cnt = np.bincount(grid.flatten())[1:]\n",
    "        bg_color = [i + 1 for i, x in enumerate(cnt) if x == max(cnt)][0]\n",
    "        if np.nonzero(cnt)[0].shape[0] >= 2:\n",
    "            if max(cnt) >= (grid.shape[0] * grid.shape[1] * 0.25):\n",
    "                background_color = bg_color\n",
    "        return background_color    \n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "# return a list with all the colors available in grid\n",
    "def get_unique_colors(grid):\n",
    "        return np.unique(grid).tolist()\n",
    "    \n",
    "# Return a dictionary color:percentage, for instance: {0: 0.666,1: 0.333, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}\n",
    "def color_percentage(grid, sorted_dict=True):\n",
    "    \n",
    "    n_elements = grid.shape[0] * grid.shape[1]\n",
    "    if ( n_elements <= 0):\n",
    "        raise ValueError(\"n_elements <= 0\")\n",
    "    unique, counts = np.unique(grid, return_counts=True)\n",
    "    if not (all(j < 10 for j in unique)):\n",
    "        raise ValueError(\"Uknown color! unique:\", unique)\n",
    "        \n",
    "    percentages =  dict(zip(unique, counts))\n",
    "    for color in range(0,10):\n",
    "        if color not in percentages.keys():\n",
    "            percentages[color] = 0.0\n",
    "    percentages.update((x, y*1.0/n_elements) for x, y in percentages.items())\n",
    "    \n",
    "    if sorted_dict:\n",
    "        percentages = collections.OrderedDict(sorted(percentages.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return percentages\n",
    "\n",
    "# Return True if symmetric\n",
    "def horizontal_symmetric(grid):\n",
    "    return np.array_equal(grid, np.flipud(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def vertical_symmetric(grid):\n",
    "    return np.array_equal(grid, np.fliplr(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def left_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid.T)\n",
    "\n",
    "# Return True if symmetric\n",
    "def right_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid[::-1,::-1].T) # or np.rot90(grid,2).T\n",
    "\n",
    "# If yes, return the color, else None\n",
    "def is_border_monocolor(a):\n",
    "    \n",
    "    color = a[0,0]\n",
    "    for x in range(0,a.shape[1]-1):\n",
    "        if (a[0,x] != color) or (a[a.shape[0]-1,x] != color):\n",
    "            return None\n",
    "    for x in range(0,a.shape[0]-1):\n",
    "        if (a[x,0] != color) or (a[x,a.shape[1]-1] != color):\n",
    "            return None\n",
    "    return color\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Detection)\n",
      "--- 0.0034301280975341797 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Detection)\")\n",
    "       \n",
    "## OBJECTS ######################\n",
    "\n",
    "# detect all the objects (a cluster of pixels colored differently from the background, without making distinction of colors)\n",
    "# Return a list of arrays, containing the coordinates of the objects in the parent grid.\n",
    "def detect_objects(grid, include_diag=True):\n",
    "    \n",
    "    structure = [[1,1,1],[1,1,1],[1,1,1]]\n",
    "    if not include_diag:\n",
    "        structure = [[0,1,0],[1,1,1],[0,1,0]]\n",
    "        \n",
    "    t_copy = np.copy(grid)\n",
    "    background_color = get_background_color(grid)\n",
    "    u_colors = np.unique(grid)\n",
    "    colors = np.delete(u_colors, np.where(u_colors == background_color))\n",
    "    t_copy[t_copy != background_color] = DUMMY_COLOR\n",
    "    \n",
    "    indices = []\n",
    "    labels, num_labels = label(t_copy == DUMMY_COLOR, structure=structure)\n",
    "    \n",
    "    for i in range(0, num_labels):\n",
    "        idx = np.column_stack(np.where(labels == i + 1))\n",
    "        list.append(indices, idx)\n",
    "    \n",
    "    if len(indices) > MAX_N_OBJECTS:\n",
    "        return []\n",
    "    return indices\n",
    "\n",
    "# Take an array with the object coordinates in the parent grid, and return useful stats.\n",
    "def matrix_rect(obj, add_border=0):\n",
    "    \n",
    "    x_max, x_min, y_max, y_min = 0, 99, 0, 99\n",
    "    \n",
    "    for point in obj:\n",
    "        if point[0] < x_min:\n",
    "            x_min = point[0]\n",
    "        if point[1] < y_min:\n",
    "            y_min = point[1]\n",
    "        if point[0] > x_max:\n",
    "            x_max = point[0]\n",
    "        if point[1] > y_max:\n",
    "            y_max = point[1]\n",
    "            \n",
    "    x_min = x_min - add_border\n",
    "    y_min = y_min - add_border\n",
    "    x_max = x_max + add_border\n",
    "    y_max = y_max + add_border\n",
    "\n",
    "    for i in range(x_min,x_max + 1):\n",
    "        for j in range(y_min,y_max + 1):\n",
    "            new_point = [i,j]\n",
    "            if not (new_point in obj):\n",
    "                obj.append(new_point)\n",
    "                \n",
    "    x_dim = x_max + 1 - x_min\n",
    "    y_dim = y_max + 1 - y_min\n",
    "    \n",
    "    return {\"obj\":obj, \n",
    "            \"x_dim\": x_dim, \n",
    "            \"y_dim\": y_dim, \n",
    "            \"x_max\": x_max, \n",
    "            \"y_max\": y_max, \n",
    "            \"x_min\": x_min, \n",
    "            \"y_min\": y_min}\n",
    "    \n",
    "    \n",
    "# fill a contiguous space with fill_color, percolating from starting_point\n",
    "def fill_holes(t,fill_color,starting_point=(0,0)):\n",
    "    t_copy = np.copy(t)\n",
    "    filled = flood_fill(t_copy, starting_point,fill_color,connectivity=0) #  TODO, should fill holes also diagonally\n",
    "    return filled\n",
    "    \n",
    "# is this value(color) on the border of the grid?\n",
    "def is_value_on_border(t,value):\n",
    "    for i in range(0,t.shape[0]):\n",
    "        if (t[i,0]==value): \n",
    "                return True\n",
    "        if (t[i,t.shape[1]-1]==value): \n",
    "                return True\n",
    "    for j in range(0,t.shape[1]):\n",
    "        if (t[0,j]==value): \n",
    "                return True\n",
    "        if (t[t.shape[0]-1,j]==value): \n",
    "                return True         \n",
    "    return False\n",
    "\n",
    "# return the coordinates of all the holes in t. An hole is defined as a region which does not percolate to the border.\n",
    "def flood_scan(t, count_only_background_holes = True):\n",
    "    holes_coordinates = []\n",
    "    t_copy = np.copy(t)\n",
    "    for i in range(0,t.shape[0]):\n",
    "        for j in range(0,t.shape[1]):\n",
    "            filled = fill_holes(t_copy,DUMMY_COLOR,starting_point=(i,j))\n",
    "            if not is_value_on_border(filled,DUMMY_COLOR):\n",
    "                holes_coordinates.append([i,j])\n",
    "    \n",
    "    # remove \"border regions\" inside the grid from the holes coordinates\n",
    "    if count_only_background_holes:\n",
    "        new_holes_coordinates = []\n",
    "        background_color = get_background_color(t)\n",
    "        for point in holes_coordinates:\n",
    "            if (t[point[0],point[1]] == background_color):\n",
    "                new_holes_coordinates.append(point)\n",
    "        return new_holes_coordinates\n",
    "        \n",
    "    return holes_coordinates\n",
    "\n",
    "## REGIONS ######################\n",
    "\n",
    "# detect lines which span the whole grid. Return the associated index.\n",
    "def detect_lines(a): \n",
    "    \n",
    "    lines = {\"h_lines\":[],\"v_lines\":[],\"rd_lines\":[],\"ld_lines\":[]}\n",
    "    try:\n",
    "        for i in range(a.shape[1]):\n",
    "            if np.all(a[:,i]==([a[0,i]]*a.shape[0])):\n",
    "                lines[\"v_lines\"].append(i)\n",
    "\n",
    "        for j in range(a.shape[0]):\n",
    "            if np.all(a[j,:]==([a[j,0]]*a.shape[1])):\n",
    "                lines[\"h_lines\"].append(j) \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    b = np.copy(a)\n",
    "    \n",
    "    for key, value in lines.items():      \n",
    "        if key==\"h_lines\":\n",
    "            b = np.delete(b, value, axis=0)\n",
    "        if key==\"v_lines\":\n",
    "            b = np.delete(b, value, axis=1)\n",
    "        \n",
    "    # eliminate lines which are not real separators\n",
    "    h_lines = []\n",
    "    v_lines = []\n",
    "    \n",
    "    for key, value in lines.items():\n",
    "        for line_index in value:\n",
    "            line_color = 0\n",
    "            if key==\"h_lines\":\n",
    "                line_color = a[line_index,0]\n",
    "                if line_color not in b:\n",
    "                    h_lines.append(line_index)\n",
    "            if key==\"v_lines\":\n",
    "                line_color = a[0,line_index]\n",
    "                if line_color not in b:\n",
    "                    v_lines.append(line_index)\n",
    "        \n",
    "    lines[\"h_lines\"] = h_lines\n",
    "    lines[\"v_lines\"] = v_lines\n",
    "    \n",
    "    return lines\n",
    "\n",
    "# get the number of regions separated by lines (thee lines span the whole grid)\n",
    "# need to pass lines = detect_lines(a)\n",
    "def count_lines_regions(lines): \n",
    "    n_regions = (1+len(lines[\"h_lines\"])) * (1+len(lines[\"v_lines\"]))\n",
    "    return n_regions\n",
    "\n",
    "# return the coordinates of all the regions separated by lines\n",
    "# need to pass lines = detect_lines(a)\n",
    "def detect_regions(a, lines,random_lines=False):\n",
    "    \n",
    "    b = np.full(a.shape,0)\n",
    "    regions = []\n",
    "    \n",
    "    if random_lines: # arbitrary (but all connected) lines, see task 144\n",
    "        #coords = get_random_lines_coords(a)\n",
    "        #b = fill_holes(b,DUMMY_COLOR,starting_point=(coords[0][0],coords[0][1]))\n",
    "        pass\n",
    "    else: # scenario with only h and v straight lines\n",
    "        for row in lines[\"h_lines\"]:\n",
    "            b[row,:] = DUMMY_COLOR\n",
    "        for col in lines[\"v_lines\"]:\n",
    "            b[:,col] = DUMMY_COLOR\n",
    "     \n",
    "    # fill the regions with dummy colors, then find their coordinates\n",
    "    k = 1\n",
    "    used_dummy_colors = []\n",
    "    for x in range(0,b.shape[0]):\n",
    "        for y in range(0,b.shape[1]):\n",
    "            if (b[x,y]!= DUMMY_COLOR) and (not b[x,y] in used_dummy_colors):\n",
    "                b = fill_holes(b,DUMMY_COLOR + k,starting_point=(x,y))\n",
    "                used_dummy_colors.append(DUMMY_COLOR + k)\n",
    "                k += 1\n",
    "       \n",
    "    for colo in used_dummy_colors:        \n",
    "        regions.append(np.argwhere(b == colo).tolist())\n",
    "    \n",
    "    return regions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Entity)\n",
      "--- 0.007721900939941406 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Entity)\")\n",
    "\n",
    "# Fundamental Entity (Tensors, Objects, etc). \n",
    "# Contains all Basic Methods acting on Task Samples.\n",
    "class Entity():\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        self.grid = grid\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        self.attributes = {}\n",
    "        \n",
    "        # Color Related\n",
    "        self.attributes[\"unique_colors\"] = get_unique_colors(self.grid)\n",
    "        self.attributes[\"n_unique_colors\"] = len(self.attributes[\"unique_colors\"])\n",
    "        self.attributes[\"n_unique_non_backg_colors\"] = self.attributes[\"n_unique_colors\"] - 1\n",
    "        self.attributes[\"grid_colors_perc\"] = color_percentage(self.grid)\n",
    "        self.attributes[\"max_color_perc\"] = max(self.attributes[\"grid_colors_perc\"].values()) \n",
    "    \n",
    "        existing_colors = {k: v for k, v in self.attributes[\"grid_colors_perc\"].items() if v > 0}\n",
    "        existing_colors = list(existing_colors.keys())\n",
    "\n",
    "        self.attributes[\"most_common_color\"] = existing_colors[0]\n",
    "        try:\n",
    "            self.attributes[\"second_most_common_color\"] = existing_colors[1]\n",
    "        except:\n",
    "            pass\n",
    "        self.attributes[\"least_common_color\"] = existing_colors[-1]\n",
    "        self.attributes[\"border_color\"] = is_border_monocolor(self.grid)\n",
    "        \n",
    "        # Shape Related\n",
    "        self.attributes[\"grid_shape\"] = self.grid.shape\n",
    "        self.attributes[\"v_shape\"] = self.attributes[\"grid_shape\"][0]\n",
    "        self.attributes[\"h_shape\"] = self.attributes[\"grid_shape\"][1]\n",
    "        if (self.attributes[\"v_shape\"]%2)==0:\n",
    "            self.attributes[\"v_shape_half\"] = self.attributes[\"v_shape\"] // 2\n",
    "        else:\n",
    "            self.attributes[\"v_shape_half\"] = None\n",
    "        if (self.attributes[\"h_shape\"]%2)==0:\n",
    "            self.attributes[\"h_shape_half\"] = self.attributes[\"h_shape\"] // 2\n",
    "        else:\n",
    "            self.attributes[\"h_shape_half\"] = None\n",
    "        if (self.attributes[\"v_shape\"]%2)==0:\n",
    "            self.attributes[\"v_shape_third\"] = self.attributes[\"v_shape\"] // 3\n",
    "        else:\n",
    "            self.attributes[\"v_shape_third\"] = None\n",
    "        if (self.attributes[\"h_shape\"]%2)==0:\n",
    "            self.attributes[\"h_shape_third\"] = self.attributes[\"h_shape\"] // 3 \n",
    "        else:\n",
    "            self.attributes[\"h_shape_third\"] = None\n",
    "        \n",
    "        # Symmetry Related\n",
    "        self.attributes[\"h_symm\"] = horizontal_symmetric(self.grid)\n",
    "        self.attributes[\"v_symm\"] = vertical_symmetric(self.grid)\n",
    "        self.attributes[\"ld_symm\"] = left_diagonal_symmetric(self.grid)\n",
    "        self.attributes[\"rd_symm\"] = right_diagonal_symmetric(self.grid)\n",
    "        \n",
    "        # Object Related\n",
    "        self.attributes[\"top_left_corner\"] = (0,0)\n",
    "        if not self.attributes[\"h_shape_half\"] is None:\n",
    "            self.attributes[\"top_mid_point\"] = (0,self.attributes[\"h_shape_half\"])\n",
    "        else:\n",
    "            self.attributes[\"top_mid_point\"] = None\n",
    "        if not self.attributes[\"v_shape_half\"] is None:\n",
    "            self.attributes[\"left_mid_point\"] = (self.attributes[\"v_shape_half\"],0)\n",
    "        else:\n",
    "            self.attributes[\"left_mid_point\"] = None\n",
    "            \n",
    "        self.attributes[\"lines\"] = detect_lines(self.grid)\n",
    "        \n",
    "    \n",
    "class Obj(Entity):\n",
    "    \n",
    "    def __init__(self, parent_grid, obj_coords_in_parent_grid):            \n",
    "        obj_data = matrix_rect(obj_coords_in_parent_grid)  \n",
    "        self.obj_data = obj_data\n",
    "        new_obj = np.full((obj_data[\"x_dim\"], obj_data[\"y_dim\"]), 0) # TODO here 0 should be background color\n",
    "        # the object is always embedded in a rectangolar grid for simplicity\n",
    "        for i in range(obj_data[\"x_dim\"]):\n",
    "            for j in range(obj_data[\"y_dim\"]):\n",
    "                new_obj[i,j] = (parent_grid[obj_data[\"x_min\"] + i, obj_data[\"y_min\"] + j])\n",
    "                \n",
    "        super().__init__(new_obj) # define the entity with the object grid\n",
    "        self.parent_grid = parent_grid\n",
    "        self.coords = obj_coords_in_parent_grid  # these coordinates are exact, so in general it is not a rectangle\n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "        \n",
    "        self.attributes[\"has_hole\"] = False\n",
    "        self.attributes[\"holes_coords_obj\"] = None # coords with respect to the object\n",
    "        self.attributes[\"holes_coords_parent\"] = None # coords with respect to the parent\n",
    "        if len(self.coords) != self.grid.size: \n",
    "            holes_coords = flood_scan(self.grid)\n",
    "            self.attributes[\"has_hole\"] = len(holes_coords) > 0\n",
    "            if self.attributes[\"has_hole\"]:\n",
    "                self.attributes[\"holes_coords_obj\"] = holes_coords\n",
    "                self.attributes[\"holes_coords_parent\"] = [[x + self.obj_data[\"x_min\"],y + self.obj_data[\"y_min\"]] for x,y in holes_coords]\n",
    "                \n",
    "class Region(Entity):\n",
    "    \n",
    "    def __init__(self, parent_grid, reg_coords_in_parent_grid):            \n",
    "        reg_data = matrix_rect(reg_coords_in_parent_grid)   \n",
    "        new_region = np.full((reg_data[\"x_dim\"], reg_data[\"y_dim\"]), 0) \n",
    "        for i in range(reg_data[\"x_dim\"]):\n",
    "            for j in range(reg_data[\"y_dim\"]):\n",
    "                new_region[i,j] = (parent_grid[reg_data[\"x_min\"] + i, reg_data[\"y_min\"] + j])\n",
    "    \n",
    "        super().__init__(new_region) \n",
    "        self.parent_grid = parent_grid\n",
    "        self.coords = reg_coords_in_parent_grid  \n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "        \n",
    "# Contains Entire Data for Input/Output\n",
    "class Tensor(Entity):\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        super().__init__(grid)\n",
    "        self.objects = []\n",
    "        self.regions = [] \n",
    "        self.layers = [] # TODO\n",
    "        \n",
    "        \n",
    "    # detect objects, layer and regions\n",
    "    def detect_entities(self):\n",
    "        objects_coords = detect_objects(self.grid)\n",
    "        for obj_coords in objects_coords:\n",
    "            self.objects.append(Obj(self.grid,obj_coords))\n",
    "        \n",
    "        regions_coords = detect_regions(self.grid, self.attributes[\"lines\"])\n",
    "        for region_coords in regions_coords:\n",
    "            self.regions.append(Region(self.grid,region_coords))\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        # compute the attributes of the whole grid\n",
    "        super().compute_attributes()  \n",
    "        # find the entities (objects, layer and regions)\n",
    "        self.detect_entities()\n",
    "        \n",
    "        # compute the attributes of the objects in the grid\n",
    "        for obj in self.objects:\n",
    "            obj.compute_attributes()\n",
    "        # compute the attributes of the whole grid referred to entities\n",
    "        self.attributes[\"n_objects\"] = len(self.objects)\n",
    "        \n",
    "        for region in self.regions:\n",
    "            region.compute_attributes()\n",
    "        self.attributes[\"n_regions\"] = len(self.regions)\n",
    "            \n",
    "\n",
    "# Fundamental Class for ALL Tasks\n",
    "# Contains all Basic Methods acting on Tasks.\n",
    "class Task():\n",
    "    \n",
    "    def __init__(self, train_data, test_data, LB_submission=False):\n",
    "        \n",
    "        # Lists of Train/Test Tensors\n",
    "        self.train_tensors = [] # Explicitly:  [[t_in_1,t_out_1],[t_in_2,t_out_2],...\n",
    "        self.train_diff = []  # For every in-out pair, difference between in and out attributes\n",
    "        self.common_diff = {} # For all the in-out pairs, common differences (Example: All of the in-out pairs change color)\n",
    "        self.sequences = {} # Sequences or patterns among all the in-out pairs \n",
    "        self.test_tensors = []\n",
    "        self.LB_submission = LB_submission\n",
    "        \n",
    "        # Compute Train Tensors\n",
    "        for t_in, t_out in train_data:\n",
    "            tensor_in = Tensor(t_in)\n",
    "            tensor_out = Tensor(t_out)\n",
    "            list.append(self.train_tensors, [tensor_in, tensor_out])\n",
    "            \n",
    "        # Compute Test Tensors\n",
    "        if self.LB_submission:\n",
    "            for t_in in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                list.append(self.test_tensors, [tensor_in])\n",
    "        else:\n",
    "            for t_in, t_out in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                tensor_out = Tensor(t_out)\n",
    "                list.append(self.test_tensors, [tensor_in, tensor_out])\n",
    "        \n",
    "           \n",
    "    # Compute Task Train Attributes \n",
    "    def compute_train_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            for t in in_out_pair:\n",
    "                t.compute_attributes()\n",
    "    \n",
    "    # Compute Task Test Attributes \n",
    "    def compute_test_attributes(self):\n",
    "        if self.LB_submission:\n",
    "            for t in self.test_tensors:\n",
    "                t[0].compute_attributes()\n",
    "        else:\n",
    "            for in_out_pair in self.test_tensors:\n",
    "                for t in in_out_pair:\n",
    "                    t.compute_attributes()\n",
    "    \n",
    "    # Compute Attribute Differences for every in-out pair\n",
    "    def compute_diff_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            diff = {}\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            \n",
    "            # Color Related\n",
    "            diff[\"color_changed\"] = set(t_in.attributes[\"unique_colors\"]) != set(t_out.attributes[\"unique_colors\"])\n",
    "            diff[\"new_colors\"] = list(set(t_out.attributes[\"unique_colors\"]) - set(t_in.attributes[\"unique_colors\"]))\n",
    "            \n",
    "            keylist = t_in.attributes[\"grid_colors_perc\"].keys()\n",
    "            color_perc_in = np.array([t_in.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            color_perc_out = np.array([t_out.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            diff[\"color_perc_changed\"] = not np.allclose(color_perc_in, color_perc_out)\n",
    "            \n",
    "            diff[\"most_common_color_changed\"] = t_in.attributes[\"most_common_color\"] != t_out.attributes[\"most_common_color\"]\n",
    "            try:\n",
    "                diff[\"second_most_common_color_changed\"] = t_in.attributes[\"second_most_common_color\"] != t_out.attributes[\"second_most_common_color\"]\n",
    "            except:\n",
    "                pass\n",
    "            diff[\"least_common_color_changed\"] = t_in.attributes[\"least_common_color\"] != t_out.attributes[\"least_common_color\"]\n",
    "            \n",
    "            # Shape Related\n",
    "            diff[\"shape_changed\"] = t_in.attributes[\"grid_shape\"] != t_out.attributes[\"grid_shape\"]\n",
    "            diff[\"h_shape_changed\"] = t_in.attributes[\"grid_shape\"][1] != t_out.attributes[\"grid_shape\"][1]\n",
    "            diff[\"v_shape_changed\"] = t_in.attributes[\"grid_shape\"][0] != t_out.attributes[\"grid_shape\"][0]\n",
    "           \n",
    "            \n",
    "            # Symmetry Related\n",
    "            diff[\"h_symm_changed\"] = t_in.attributes[\"h_symm\"] != t_out.attributes[\"h_symm\"]\n",
    "            diff[\"v_symm_changed\"] = t_in.attributes[\"v_symm\"] != t_out.attributes[\"v_symm\"]\n",
    "            diff[\"ld_symm_changed\"] = t_in.attributes[\"ld_symm\"] != t_out.attributes[\"ld_symm\"]\n",
    "            diff[\"rd_symm_changed\"] = t_in.attributes[\"rd_symm\"] != t_out.attributes[\"rd_symm\"]\n",
    "            \n",
    "            # Objects Related\n",
    "            # diff[\"n_objects_changed\"] = t_in.attributes[\"n_objects\"] != t_out.attributes[\"n_objects\"]\n",
    "            \n",
    "            # Other\n",
    "            diff[\"is_in_in_out\"] = match_template(t_out.grid, t_in.grid)\n",
    "            diff[\"is_out_in_in\"] = match_template(t_in.grid, t_out.grid)\n",
    "            \n",
    "            \n",
    "            list.append(self.train_diff,diff)\n",
    "        \n",
    "    # Find Common Differences in Input/Output Pairs. Return a dict \"diff\":int, such as {'color_changed': -1, 'color_perc_changed': 1, 'shape_changed': 1}.\n",
    "    def find_common_diff(self):\n",
    "        \n",
    "        diffs = self.train_diff[0].keys()\n",
    "        \n",
    "        for k in diffs:\n",
    "            try:\n",
    "                truth_values = []\n",
    "                for i, diff in enumerate(self.train_diff): \n",
    "                    truth_values.append(diff[k])\n",
    "\n",
    "                if all(truth_values): \n",
    "                    self.common_diff[k] = 1 # this difference k is common in all the in-out pairs and it is True.\n",
    "                elif (not all(truth_values)) and (not any(truth_values)):\n",
    "                    self.common_diff[k] = -1 # this difference k is common in all the in-out pairs and it is False.\n",
    "                else:\n",
    "                    self.common_diff[k] = 0 # the difference is not common to all the in-out pairs.\n",
    "            except KeyError as error:\n",
    "                self.common_diff[k] = 0\n",
    "                \n",
    "        \n",
    "    # Find Sequences or patterns in Common Differences or in the outputs. \n",
    "    # For instance a color/shape common to all the outputs.\n",
    "    def find_sequence(self):\n",
    "        \n",
    "        # find which colors do not appear in train input, but appear in all the outputs\n",
    "        common_new_colors = [0,1,2,3,4,5,6,7,8,9]\n",
    "        for in_out_pair in self.train_diff:\n",
    "            common_new_colors = list(set(common_new_colors).intersection(in_out_pair[\"new_colors\"]))\n",
    "        self.sequences[\"common_new_colors\"] = common_new_colors\n",
    "        for i, cnc in enumerate(self.sequences[\"common_new_colors\"]):\n",
    "            self.sequences[\"common_new_colors\" + \"_\" + str(i)] = cnc\n",
    "            \n",
    "        # memorize the shape, if all the output shapes are the same\n",
    "        out_shapes_0 = []\n",
    "        out_shapes_1 = []\n",
    "        in_shapes_0 = []\n",
    "        in_shapes_1 = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            out_shapes_0.append(t_out.grid.shape[0])\n",
    "            out_shapes_1.append(t_out.grid.shape[1])\n",
    "            in_shapes_0.append(t_in.grid.shape[0])\n",
    "            in_shapes_1.append(t_in.grid.shape[1])\n",
    "        self.sequences[\"out_shape_0\"] = -1\n",
    "        self.sequences[\"out_shape_1\"] = -1\n",
    "        if checkEqual1(out_shapes_0):\n",
    "            self.sequences[\"out_shape_0\"] = out_shapes_0[0]\n",
    "        if checkEqual1(out_shapes_1):\n",
    "            self.sequences[\"out_shape_1\"] = out_shapes_1[0]\n",
    "        self.sequences[\"max_in_shape\"] = max(in_shapes_0 + in_shapes_1)\n",
    "        self.sequences[\"min_in_shape\"] = min(in_shapes_0 + in_shapes_1)\n",
    "        self.sequences[\"max_out_shape\"] = max(out_shapes_0 + out_shapes_1)\n",
    "        self.sequences[\"min_out_shape\"] = min(out_shapes_0 + out_shapes_1)\n",
    "        self.sequences[\"prime_in_shape_0\"] = any(is_prime(ele) for ele in in_shapes_0)\n",
    "        self.sequences[\"prime_in_shape_1\"] = any(is_prime(ele) for ele in in_shapes_1)\n",
    "            \n",
    "            \n",
    "         \n",
    "        # check if all the outputs have the same number of colors\n",
    "        n_colors = []\n",
    "        for in_out_pair in task_data.train_tensors:\n",
    "            t_out = in_out_pair[1]\n",
    "            n_colors.append(t_out.attributes[\"n_unique_colors\"])\n",
    "        self.sequences[\"n_colors\"] = 0\n",
    "        if checkEqual1(n_colors):\n",
    "            self.sequences[\"n_colors\"] = n_colors[0]\n",
    "            \n",
    "        # check in and out objects\n",
    "        in_objs = []\n",
    "        out_objs = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_objs.append(t_in.objects)\n",
    "            out_objs.append(t_out.objects)\n",
    "        self.sequences[\"max_n_objects_in\"] = checkMaxMinLen(in_objs)[\"max_len\"]\n",
    "        self.sequences[\"min_n_objects_in\"] = checkMaxMinLen(in_objs)[\"min_len\"]\n",
    "        self.sequences[\"max_n_objects_out\"] = checkMaxMinLen(out_objs)[\"max_len\"]\n",
    "        self.sequences[\"min_n_objects_out\"] = checkMaxMinLen(out_objs)[\"min_len\"]\n",
    "              \n",
    "            \n",
    "        # check in and out regions\n",
    "        in_regions = []\n",
    "        out_regions = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_regions.append(t_in.regions)\n",
    "            out_regions.append(t_out.regions)\n",
    "        self.sequences[\"max_n_regions_in\"] = checkMaxMinLen(in_regions)[\"max_len\"]\n",
    "        self.sequences[\"min_n_regions_in\"] = checkMaxMinLen(in_regions)[\"min_len\"]\n",
    "        self.sequences[\"max_n_regions_out\"] = checkMaxMinLen(out_regions)[\"max_len\"]\n",
    "        self.sequences[\"min_n_regions_out\"] = checkMaxMinLen(out_regions)[\"min_len\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # check in and out color_perc\n",
    "        in_cp = []\n",
    "        out_cp = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_cp.append(t_in.attributes[\"max_color_perc\"])\n",
    "            out_cp.append(t_out.attributes[\"max_color_perc\"])\n",
    "        self.sequences[\"max_max_color_perc_in\"] = max(in_cp)\n",
    "        self.sequences[\"min_max_color_perc_in\"] = min(in_cp)\n",
    "        self.sequences[\"max_max_color_perc_out\"] = max(out_cp)\n",
    "        self.sequences[\"min_max_color_perc_out\"] = min(out_cp)\n",
    "            \n",
    "        \n",
    "                               \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Rotates) ...\n",
      "--- 0.0014548301696777344 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Rotates) ...\")\n",
    "\n",
    "# Rotate Image 90 Degrees\n",
    "def rotate_1(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 1, axes=(0,1))\n",
    "\n",
    "# Rotate Image 180 Degrees\n",
    "def rotate_2(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 2, axes=(0,1))\n",
    "\n",
    "# Rotate Image 270 Degrees\n",
    "def rotate_3(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 3, axes=(0,1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Flips) ...\n",
      "--- 0.0003070831298828125 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Flips) ...\")\n",
    "\n",
    "# Flip Image Along X-Axis\n",
    "def flip_1(a, a_t, task_data, *args):\n",
    "    return np.flip(a, 0)\n",
    "\n",
    "# Flip Image Along Y-Axis\n",
    "def flip_2(a, a_t, task_data, *args):\n",
    "    return np.flip(a, 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Mirrors) ...\n",
      "--- 0.0006439685821533203 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Mirrors) ...\")\n",
    "\n",
    "# Mirror Image Along Top Side of Frame\n",
    "def mirror_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=0), a), axis=0)\n",
    "\n",
    "# Mirror Image Along Right Side of Frame\n",
    "def mirror_2(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=1)), axis=1)\n",
    "\n",
    "# Mirror Image Along Bottom Side of Frame\n",
    "def mirror_3(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=0)), axis=0)\n",
    "\n",
    "# Mirror Image Along Left Side of Frame\n",
    "def mirror_4(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=1), a), axis=1)  \n",
    "\n",
    "# Get Transpose of Image\n",
    "def mirror_5(a, a_t, task_data, *args):\n",
    "    return a.T\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.0005280971527099609 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Duplicate Original grid args[0] times vertically and args[1] horizontally\n",
    "def repeat_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.tile(a,(args[0],args[1]))\n",
    "\n",
    "# Repeat the grid, only in correspondents of positions where there are non background colors\n",
    "def repeat_2(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * a.shape[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * a.shape[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    c = np.tile(a, a.shape)\n",
    "    c_mask = a.repeat(a.shape[0], axis=0).repeat(a.shape[1], axis=1)\n",
    "    return c & c_mask\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.0013031959533691406 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Elastically rescales up grid args[0] times vertically and args[1] horizontally\n",
    "def rescale_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.kron(a, np.ones((args[0],args[1]), dtype=np.uint8)) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Crop) ...\n",
      "--- 0.002908945083618164 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Crop) ...\")\n",
    "\n",
    "# Crop using the coordinates of a color as a reference.\n",
    "def crop_1(a, a_t, task_data, *args):\n",
    "    color = args[0]\n",
    "    coords = np.argwhere(a==color)\n",
    "    x_min, y_min = coords.min(axis=0)\n",
    "    x_max, y_max = coords.max(axis=0)\n",
    "    return a[x_min:x_max+1, y_min:y_max+1]\n",
    "    \n",
    "# Crop using the top left corner and two dimensions\n",
    "def crop_2(a, a_t, task_data, *args):\n",
    "    shape_v = args[0]\n",
    "    shape_h = args[1]\n",
    "    top_left_coords = args[2]\n",
    "    if ((top_left_coords[0]  + shape_v) > a.shape[0]) or ((top_left_coords[1]  + shape_h) > a.shape[1]):\n",
    "        #print(\"Out of bounds B\", shape_v ,shape_h ,top_left_coords, a.shape[0], a.shape[1])\n",
    "        raise ValueError(\"Out of bounds\")  \n",
    "    return a[top_left_coords[0]:top_left_coords[0]+shape_v, top_left_coords[1]:top_left_coords[1]+shape_h]\n",
    "\n",
    "# Crop the border\n",
    "def crop_3(a, a_t, task_data, *args):\n",
    "    thickness = args[0]\n",
    "    if (thickness==0) or (thickness>a.shape[0]//2) or (thickness>a.shape[1]//2):\n",
    "        raise ValueError(\"Bad thickness\") \n",
    "    return a[thickness:a.shape[0]-thickness, thickness:a.shape[1]-thickness]\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Symmetric) ...\n",
      "--- 0.0007231235504150391 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Symmetric) ...\")\n",
    "\n",
    "# Make Image Symmetric Along X-Axis\n",
    "def symmetric_1(a, a_t, task_data, *args):\n",
    "    b1 = flip_1(a, a_t, task_data, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "# Make Image Symmetric Along Y-Axis\n",
    "def symmetric_2(a, a_t, task_data, *args):\n",
    "    b1 = flip_2(a, a_t, task_data, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Color) ...\n",
      "--- 0.0018749237060546875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Color) ...\")\n",
    "\n",
    "# Substitute Color1 with Color2 (NOT viceversa) \n",
    "def color_1(a, a_t, task_data, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    a[b_first] = color2\n",
    "    return a \n",
    "\n",
    "# Swap Color1 with Color2 and Color2 with Color1\n",
    "def color_2(a, a_t, task_data, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    b_second = a == color2\n",
    "    a[b_first] = color2\n",
    "    a[b_second] = color1\n",
    "    return a\n",
    "\n",
    "# Substitute all colors different from Color1 with Color2 (NOT viceversa) \n",
    "def color_3(a, a_t, task_data, *args):\n",
    "    if (len(get_unique_colors(a)) < 3):\n",
    "        raise ValueError(\"Not enough colors in this grid\")\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a != color1\n",
    "    a[b_first] = color2\n",
    "    return a\n",
    "\n",
    "# Color objects with a given attribute\n",
    "def color_ob(a, a_t, task_data, key ,*args):\n",
    "    new_color = args[0]\n",
    "    objs_to_color = []\n",
    "    for obj in a_t.objects:\n",
    "        if obj.attributes[key]:\n",
    "            objs_to_color.append(obj)\n",
    "            \n",
    "    if (len(objs_to_color) == 0):\n",
    "        raise ValueError(\"No objects to color\")\n",
    "      \n",
    "    for obj in objs_to_color:\n",
    "        a = color_points(a,obj.coords,new_color)\n",
    "    return a\n",
    "\n",
    "# Color objects with holes in them\n",
    "def color_ob_1(a, a_t, task_data, *args):\n",
    "    return color_ob(a, a_t, task_data,\"has_hole\",*args)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Superpose) ...\n",
      "--- 0.001313924789428711 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Superpose) ...\")\n",
    "\n",
    "\n",
    "\n",
    "# superpose all the regions with an operation given by op. Here the regions are just inferred from splicing the grid.\n",
    "def superp(a, a_t, task_data,*args,op=\"AND\",axis=0):\n",
    "    \n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    n_regions = args[2]\n",
    "    if (n_regions > 5):\n",
    "        raise ValueError(\"Too many regions\")\n",
    "    axis = axis #args[3] # 0 or 1\n",
    "    regions = np.split(a,n_regions,axis=axis)\n",
    "    for previous, current in zip(regions, regions[1:]):\n",
    "        if op==\"AND\":\n",
    "            b = np.where((previous !=background_color) & (current !=background_color), new_color, background_color)\n",
    "        if op==\"OR\":\n",
    "            b = np.where((previous !=background_color) | (current !=background_color), new_color, background_color)\n",
    "        if op==\"XOR\":\n",
    "            b = np.where((previous !=background_color) ^ (current !=background_color), new_color, background_color)\n",
    "        if op==\"ADD\":\n",
    "            b =  np.where((previous + current) < 10, previous + current, background_color)\n",
    "    return b\n",
    "\n",
    "def superp_1(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"AND\",axis=0)\n",
    "def superp_2(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"OR\",axis=0)\n",
    "def superp_3(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"XOR\",axis=0)\n",
    "def superp_4(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"ADD\",axis=0)\n",
    "def superp_5(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"AND\",axis=1)\n",
    "def superp_6(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"OR\",axis=1)\n",
    "def superp_7(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"XOR\",axis=1)\n",
    "def superp_8(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"ADD\",axis=1)\n",
    "\n",
    "# superpose all the regions with an operation given by op\n",
    "def superp_reg(a, a_t, task_data,*args, key=None, op=\"AND\"):\n",
    "    \n",
    "    b = black_square\n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    for previous, current in zip(a_t.regions, a_t.regions[1:]):\n",
    "        if not (key is None):\n",
    "            pass\n",
    "        else:\n",
    "            if op==\"AND\":\n",
    "                b = np.where((previous.grid !=background_color) & (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"OR\":\n",
    "                b = np.where((previous.grid !=background_color) | (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"XOR\":\n",
    "                b = np.where((previous.grid !=background_color) ^ (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"ADD\":\n",
    "                b =  np.where((previous.grid + current.grid) < 10, previous.grid + current.grid, background_color)\n",
    "    return b\n",
    "\n",
    "\n",
    "def superp_reg_1(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"AND\")\n",
    "def superp_reg_2(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"OR\")\n",
    "def superp_reg_3(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"XOR\")\n",
    "def superp_reg_4(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"ADD\")\n",
    "        \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Draw) ...\n",
      "--- 0.0005729198455810547 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Draw) ...\")\n",
    "\n",
    "# superpose all the regions with an operation given by op\n",
    "def draw_reg(a, a_t, task_data,*args, key=\"most_common_color\"):\n",
    "    \n",
    "    lines = a_t.attributes[\"lines\"]\n",
    "    n_h_lines = len(lines[\"h_lines\"])\n",
    "    n_v_lines = len(lines[\"v_lines\"])\n",
    "    \n",
    "    b = np.full((n_h_lines +1, n_v_lines +1),0)\n",
    "    i = 0\n",
    "    for x in range(0,n_h_lines +1):\n",
    "        for y in range(0,n_v_lines +1): \n",
    "            b[x,y] = a_t.regions[i].attributes[key]\n",
    "            i +=1\n",
    "    \n",
    "    return b\n",
    "\n",
    "def draw_reg_1(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"most_common_color\")\n",
    "def draw_reg_2(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"second_most_common_color\")\n",
    "def draw_reg_3(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"least_common_color\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Special) ...\n",
      "--- 0.0006699562072753906 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Special) ...\")\n",
    "\n",
    "# create a uniformely colored new grid from scratch\n",
    "def special_1(a, a_t, task_data, *args):\n",
    "    color = args[0]\n",
    "    shape_v = args[1]\n",
    "    shape_h = args[2]\n",
    "    if (color > 9):\n",
    "        raise ValueError(\"Bad color!\")\n",
    "    return np.full((shape_v,shape_h), color, dtype=np.uint8)\n",
    "\n",
    "\n",
    "# fill holes in the objects\n",
    "def special_2(a, a_t, task_data, *args):\n",
    "    \n",
    "    fill_color = args[0]\n",
    "    objs = a_t.objects\n",
    "    if len(objs) == 0:\n",
    "        raise ValueError(\"No Objects!\")\n",
    "    for ob in objs:\n",
    "        if ob.attributes[\"has_hole\"]:\n",
    "            for hole_coord in ob.attributes[\"holes_coords_parent\"]:\n",
    "                if (a[hole_coord[0],hole_coord[1]] != fill_color):\n",
    "                    a = fill_holes(a,fill_color,starting_point=tuple(hole_coord))\n",
    "            \n",
    "    return a       \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine DSL Functions ...\n",
      "DSL_fs_names  ['rotate_1', 'rotate_2', 'rotate_3', 'flip_1', 'flip_2', 'mirror_1', 'mirror_2', 'mirror_3', 'mirror_4', 'mirror_5', 'repeat_1', 'repeat_2', 'rescale_1', 'crop_1', 'crop_2', 'crop_3', 'symmetric_1', 'symmetric_2', 'color_1', 'color_2', 'color_3', 'color_ob_1', 'superp_1', 'superp_2', 'superp_3', 'superp_4', 'superp_5', 'superp_6', 'superp_7', 'superp_8', 'superp_reg_1', 'superp_reg_2', 'superp_reg_3', 'superp_reg_4', 'draw_reg_1', 'draw_reg_2', 'draw_reg_3', 'special_1', 'special_2']\n",
      "Total number of functions:  39\n",
      "--- 0.004450082778930664 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Combine DSL Functions ...\")\n",
    "\n",
    "rotate = [rotate_1, rotate_2, rotate_3\n",
    "         ]\n",
    "flip = [flip_1, flip_2\n",
    "       ]\n",
    "mirror = [mirror_1,mirror_2,mirror_3,mirror_4,mirror_5]\n",
    "repeat = [repeat_1, repeat_2]\n",
    "rescale = [rescale_1]\n",
    "crop = [\n",
    "    crop_1, \n",
    "    crop_2, \n",
    "    crop_3\n",
    "]\n",
    "symmetric = [symmetric_1, symmetric_2]\n",
    "color = [color_1, color_2, color_3, color_ob_1\n",
    "        ]\n",
    "\n",
    "superpose = [superp_1, superp_2, superp_3, superp_4,superp_5, superp_6, superp_7, superp_8, superp_reg_1,superp_reg_2,superp_reg_3,superp_reg_4]\n",
    "draw = [draw_reg_1,draw_reg_2,draw_reg_3]\n",
    "special = [special_1, special_2]\n",
    "\n",
    "DSL_functions = rotate + flip + mirror + repeat + rescale + crop + symmetric + color + superpose + draw + special \n",
    "DSL_fs_names = [f.__name__ for f in DSL_functions]\n",
    "print(\"DSL_fs_names \", DSL_fs_names)\n",
    "print(\"Total number of functions: \", len(DSL_functions))\n",
    "\n",
    "# Return True if the new_function should not compose with the current_functions\n",
    "def forbidden_composition(new_function, current_functions):\n",
    "    \n",
    "    f_names = [f.__name__ for f in current_functions]\n",
    "    new_f_names = [f.__name__ for f in new_function]\n",
    "    forbidden_combos = [\"rescale\", \"repeat\"]\n",
    "    \n",
    "    for keyword in forbidden_combos:\n",
    "        if (keyword in '\\t'.join(new_f_names)) and (keyword in '\\t'.join(f_names)):\n",
    "            return True\n",
    "        \n",
    "    forbidden_duos = [[\"crop_1\",\"crop_1\"],[\"crop_1\",\"crop_2\"],[\"crop_2\",\"crop_2\"]]\n",
    "    for duo in forbidden_duos:\n",
    "        if ((duo[0] in '\\t'.join(new_f_names)) and (duo[1] in '\\t'.join(f_names))) or ((duo[1] in '\\t'.join(new_f_names)) and (duo[0] in '\\t'.join(f_names))):\n",
    "            return True\n",
    "        \n",
    "    functions_that_must_go_first = [\"repeat_2\",\"special_2\", \"crop_2\",\"color_ob_1\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\n",
    "                                   \"draw_reg_1\",\"draw_reg_2\",\"draw_reg_3\",\n",
    "                                   \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"]\n",
    "    for keyword in functions_that_must_go_first:\n",
    "        if (keyword in '\\t'.join(new_f_names)):\n",
    "            return True\n",
    "        \n",
    "    functions_that_cannot_go_first = [\"crop_3\"]\n",
    "    \n",
    "    for keyword in functions_that_cannot_go_first:\n",
    "        if (keyword in '\\t'.join(f_names)):\n",
    "            return True\n",
    "      \n",
    "    functions_that_must_go_alone = [\"special_1\",\"color_3\"]\n",
    "    for keyword in functions_that_must_go_alone:\n",
    "        if ((keyword in '\\t'.join(new_f_names)) or (keyword in '\\t'.join(f_names)) ):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Actions ...\n",
      "--- 0.002110004425048828 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Actions ...\")\n",
    "\n",
    "# Return the action is defined by the dict above. Put \"UNDEF\" is the function may or may not change the attribute.\n",
    "# Notice that some \"UNDEF\" actions can actually be defined if we add more info.\n",
    "def get_functions_actions(entity):\n",
    "    \n",
    "    shape = entity.attributes[\"grid_shape\"]\n",
    "    is_a_square =  shape[0] == shape[1]\n",
    "    is_h_symm = entity.attributes[\"h_symm\"]\n",
    "    is_v_symm = entity.attributes[\"v_symm\"]\n",
    "    \n",
    "    go_from_h_symm_to_v_or_viceversa = ((is_h_symm) and (not is_v_symm)) or ((is_v_symm) and (not is_h_symm))\n",
    "    \n",
    "    functions_actions = {\n",
    "    \"rotate_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\": not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}, \n",
    "    \"rotate_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"rotate_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}, \n",
    "    \"flip_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"flip_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_4\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_5\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"repeat_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"repeat_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"rescale_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"crop_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"crop_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"crop_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"symmetric_1\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":not is_h_symm,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"symmetric_2\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":not is_v_symm,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"color_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_ob_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_4\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_5\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_6\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_7\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_8\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_4\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"special_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":\"UNDEF\",\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"special_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}\n",
    "                   }\n",
    "    return functions_actions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Filtering ...\n",
      "--- 0.0018329620361328125 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Filtering ...\")\n",
    "\n",
    "# Filter the functions which will enter the generate loops. Run over all the test_in and take only the functions that are compatible with all the test_in.\n",
    "def function_filter(task_data, fs_names):\n",
    "\n",
    "    test_t_ins = task_data.test_tensors\n",
    "    functions_to_select = fs_names\n",
    "    functions_removed = []\n",
    "    \n",
    "    for t_in in test_t_ins:\n",
    "        \n",
    "        functions_actions = get_functions_actions(t_in[0])\n",
    "        diff = task_data.common_diff\n",
    "        \n",
    "        d1 = [\"color_changed\",\"color_perc_changed\",\"most_common_color_changed\",\"second_most_common_color_changed\",\"least_common_color_changed\",\"shape_changed\",\"h_shape_changed\",\"v_shape_changed\"]\n",
    "        d2 = [\"new_colors\", \"h_symm_changed\",\"v_symm_changed\",\"ld_symm_changed\",\"rd_symm_changed\",\"is_in_in_out\", \"is_out_in_in\"] \n",
    "        print(\"diff\",diff)\n",
    "        d_final =  [x for x in list(diff.keys()) if x not in d2]\n",
    "\n",
    "        # remove the functions (from the list of all function) which make undesired changes. \n",
    "        for f,v in functions_actions.items():\n",
    "            \n",
    "            for diff_name in d_final:\n",
    "                if diff[diff_name]==-1: # Example: if the task is preserving the color. \n",
    "                    if v[diff_name]==True: # Example: check if the function modifies colors. Explicit ==True check is important here.\n",
    "                        if f in functions_to_select: \n",
    "                            functions_removed.append(f) # Example: If so, remove function which modify colors.\n",
    "           \n",
    "    # if the outputs are not mono-color\n",
    "    if task_data.sequences[\"n_colors\"] ==1:\n",
    "        functions_removed.extend([\"special_2\", \"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "    else:\n",
    "        functions_removed.append(\"special_1\")\n",
    "      \n",
    "    # if out is always in in, the solution is likely crop or similar\n",
    "    if diff[\"is_out_in_in\"]==1:\n",
    "        functions_removed.extend(set(fs_names) - set([\"crop_1\",\"crop_2\",\"crop_3\",\"special_1\"]))\n",
    "        \n",
    "    # if in is very small\n",
    "    if (task_data.sequences[\"max_in_shape\"]<6):\n",
    "        functions_removed.extend([\"special_2\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "        \n",
    "    # if out is very small\n",
    "    if (task_data.sequences[\"out_shape_0\"]!=-1) and (task_data.sequences[\"out_shape_0\"]<3) and (task_data.sequences[\"out_shape_1\"]!=-1) and (task_data.sequences[\"out_shape_1\"]<3) :\n",
    "        functions_removed.extend([\"rescale_1\",\"repeat_1\",\"mirror_1\",\"mirror_2\",\"mirror_3\",\"mirror_4\"])\n",
    "     \n",
    "    # if out is only 1 dim\n",
    "    if (task_data.sequences[\"min_out_shape\"]==1):\n",
    "        functions_removed.extend([\"special_2\", \"repeat_1\",\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "    \n",
    "    # if out is very large\n",
    "    if (task_data.sequences[\"out_shape_0\"]>13) and (task_data.sequences[\"out_shape_1\"]>13):\n",
    "        functions_removed.extend([\"crop_1\",\"crop_2\",\"special_1\"])\n",
    "        \n",
    "    # if out is bigger than in\n",
    "    if (task_data.sequences[\"min_out_shape\"] > task_data.sequences[\"max_in_shape\"]):\n",
    "        functions_removed.extend([\"special_1\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "        \n",
    "    # if there aren't at least 2 objects in all the inputs\n",
    "    if task_data.sequences[\"min_n_objects_in\"] < 2:\n",
    "        functions_removed.extend([\"color_ob_1\"])\n",
    "        \n",
    "    # if there are many objects in input\n",
    "    if task_data.sequences[\"min_n_objects_in\"] > 3:\n",
    "        functions_removed.extend([\"special_1\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "        \n",
    "    # if there aren't at least 2 regions in all the inputs\n",
    "    if task_data.sequences[\"min_n_regions_in\"] < 2:\n",
    "        functions_removed.extend([\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\"draw_reg_1\",\"draw_reg_2\",\"draw_reg_3\"])\n",
    "    else:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "     \n",
    "    # if the input dimension is not divisible\n",
    "    if task_data.sequences[\"prime_in_shape_0\"]:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\"])\n",
    "    if task_data.sequences[\"prime_in_shape_1\"]:\n",
    "        functions_removed.extend([\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "        \n",
    "    # if the input is mainly background\n",
    "    if task_data.sequences[\"min_max_color_perc_in\"] > 0.7:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\"])\n",
    "   \n",
    "    print(\"functions removed\", set(functions_removed))\n",
    "    functions_to_select = [item for item in fs_names if item not in functions_removed]\n",
    "    functions_to_select = [func for func in DSL_functions if func.__name__ in functions_to_select] # convert from string to function\n",
    "    return functions_to_select\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic Numbers ...\n",
      "--- 0.0026090145111083984 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Magic Numbers ...\")\n",
    "\n",
    "# How many additional arguments every functions is taking, for each kind of argument. The order is important here.\n",
    "fs_argument_structure = {\n",
    "\"rotate_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0}, \n",
    "    \"rotate_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"rotate_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"flip_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"flip_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_4\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_5\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"repeat_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"repeat_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"rescale_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_2\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":1,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_3\":{\"color_related\":0, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"symmetric_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"symmetric_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_1\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_2\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_3\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_ob_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_1\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_2\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_3\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_4\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_5\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_6\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_7\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_8\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_1\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_2\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_3\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_4\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"special_1\":{\"color_related\":1, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"special_2\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0}\n",
    "                    }\n",
    "\n",
    "# how many magic arguments this function takes\n",
    "def number_of_magic_arguments(function):\n",
    "    args = fs_argument_structure[function.__name__]\n",
    "    return sum(args.values())\n",
    "\n",
    "# helper to get_magic_numbers from a single tensor. Only color related magic numbers.\n",
    "def get_magic_numbers_color_single(t, magic_numbers_colors):\n",
    "    #colors_perc = t.attributes[\"grid_colors_perc\"] \n",
    "    magic_numbers_colors.append(t.attributes[\"most_common_color\"])\n",
    "    try:\n",
    "        magic_numbers_colors.append(t.attributes[\"second_most_common_color\"])\n",
    "    except:\n",
    "        pass\n",
    "    magic_numbers_colors.append(t.attributes[\"least_common_color\"])\n",
    "    \n",
    "    return magic_numbers_colors \n",
    "\n",
    "# helper\n",
    "def compute_shape_variations(diff,direction, magic_numbers_shape, t_out_shape, t_in_shape): \n",
    "    # append ratios and differences. This is useful for functions like repeat, crop and resize.\n",
    "    if diff:\n",
    "        ratio_1 = t_out_shape[direction]//t_in_shape[direction]\n",
    "        ratio_2 = t_in_shape[direction]//t_out_shape[direction]\n",
    "        diff_1 = t_out_shape[direction]-t_in_shape[direction]\n",
    "        diff_2 = t_in_shape[direction]-t_out_shape[direction]\n",
    "        \n",
    "        if (ratio_1 > 1) and ((t_out_shape[direction]%t_in_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_1)\n",
    "        if (ratio_2 > 1) and ((t_in_shape[direction]%t_out_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_2)\n",
    "        if diff_1 > 0:\n",
    "            magic_numbers_shape.append(diff_1)\n",
    "        if diff_2 > 0:\n",
    "            magic_numbers_shape.append(diff_2)\n",
    "\n",
    "# helper to get_magic_numbers from a pair of tensors. Only shape related magic numbers.\n",
    "def get_magic_numbers_shape_pair(in_out_pair, magic_numbers_shape,task_data,pair_n):\n",
    "    \n",
    "    t_in = in_out_pair[0]\n",
    "    t_out = in_out_pair[1]\n",
    "    MAX_SHAPE_MAGIC_NUMBER = 10\n",
    "    \n",
    "    t_in_shape = t_in.attributes[\"grid_shape\"] \n",
    "    t_out_shape = t_out.attributes[\"grid_shape\"] \n",
    "    \n",
    "    # do not append t_in shapes, as they should not be predictive\n",
    "    magic_numbers_shape.extend([1,2,3,4]) # these are pretty basic shape numbers always worth trying \n",
    "    magic_numbers_shape.append(t_out_shape[0])\n",
    "    magic_numbers_shape.append(t_out_shape[1])\n",
    "    \n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"h_shape_changed\"],0, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"v_shape_changed\"],1, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    \n",
    "    magic_numbers_shape = [mn for mn in magic_numbers_shape if mn <= MAX_SHAPE_MAGIC_NUMBER]\n",
    "    \n",
    "    return magic_numbers_shape \n",
    "\n",
    "# helper to get_magic_numbers from a pair of tensors. Only object related magic numbers.\n",
    "def get_magic_numbers_object_pair(in_out_pair, magic_numbers_object,task_data,pair_n):\n",
    "    positions_of_out_in_in = task_data.train_diff[pair_n][\"is_out_in_in\"]\n",
    "    if (len(positions_of_out_in_in) < 5): # avoid edge cases in with output is just a pixel, repeated a lot of times in input.\n",
    "        magic_numbers_object.extend(positions_of_out_in_in) \n",
    "    return magic_numbers_object \n",
    "\n",
    "# prepare the magic numbers for all the categories. Example: {'color_related': [0, 2, 3, 4, 6, 8], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "def get_magic_numbers(task_data):\n",
    "    \n",
    "    magic_numbers = {\"color_related\":[], \"shape_related\":[],\"regions_related\":[],\"object_related\":[],\"layer_related\":[],\"axis_related\":[]}\n",
    "    \n",
    "    # get magic numbers from train in-out pairs\n",
    "    for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "        magic_numbers[\"shape_related\"] = get_magic_numbers_shape_pair(in_out_pair, magic_numbers[\"shape_related\"],task_data,pair_n)\n",
    "        magic_numbers[\"object_related\"] = get_magic_numbers_object_pair(in_out_pair, magic_numbers[\"object_related\"],task_data,pair_n)\n",
    "        \n",
    "        for color_n, new_color in enumerate(task_data.sequences[\"common_new_colors\"]): \n",
    "            magic_numbers[\"color_related\"].append(new_color)\n",
    "        for t in in_out_pair:         \n",
    "            magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t, magic_numbers[\"color_related\"])\n",
    "       \n",
    "    # get magic numbers from test in samples\n",
    "    for t in task_data.test_tensors:       \n",
    "        magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t[0], magic_numbers[\"color_related\"])    \n",
    "    \n",
    "    \n",
    "    magic_numbers[\"color_related\"] = list(set(magic_numbers[\"color_related\"]))\n",
    "    magic_numbers[\"shape_related\"] = list(set(magic_numbers[\"shape_related\"]))\n",
    "    magic_numbers[\"object_related\"] = list(set(magic_numbers[\"object_related\"]))\n",
    "    #magic_numbers[\"axis_related\"] = [0,1]\n",
    "    return magic_numbers\n",
    "\n",
    "\n",
    "# return all the possible combinations of lists of arguments. For instance, if the function take 2 color_related arguments\n",
    "# and 1 shape_related argument, the function will return a list like: [ [1,2,3], [1,2,4], ... ] with [c1,c2,s1] as ordering.\n",
    "def prepare_magic_arguments(func, magic_numbers):\n",
    "    \n",
    "    func_argument_structure = fs_argument_structure[func.__name__]\n",
    "    magic_args = {'color_related': [], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "    \n",
    "    for x_related,numbers in magic_numbers.items():\n",
    "        if func_argument_structure[x_related] > 0:\n",
    "            # compute all the possible combinations of arguments of the same kind\n",
    "            magic_args[x_related] = list(itertools.product(numbers, repeat=func_argument_structure[x_related]))\n",
    "    \n",
    "    # assemble the arguments of different categories together\n",
    "    magic_args_lists = []\n",
    "    for k,v in magic_args.items():\n",
    "        if len(v) > 0:\n",
    "            magic_args_lists.append(v)\n",
    "    magic_args_mixed = list(itertools.product(*magic_args_lists))\n",
    "    for i in range(len(magic_args_mixed)):\n",
    "        magic_args_mixed[i] = [y for x in magic_args_mixed[i] for y in (x if isinstance(x, tuple) else (x,))]\n",
    "        \n",
    "    if len(magic_args_mixed) > MAX_magic_args_number : # avoid very lengthy computations\n",
    "        return {'color_related': [], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': [], 'axis_related': []}\n",
    "    return magic_args_mixed \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program():\n",
    "    \n",
    "    def __init__(self, functions=[], sim_score=0, acting_on=\"Tensor\", mn=[]):\n",
    "        self.functions = functions # list of functions. The program is the composition of those.\n",
    "        self.sim_score = sim_score # How well the program scores on the expected output.\n",
    "        self.acting_on = acting_on # Is this acting on a Tensor, an Object, a Layer?\n",
    "        self.task_accuracy = 0  # +1 for every time program maps t_in in t_out\n",
    "        self.magic_numbers = mn # list of lists of magic numbers. Every sublist is associated to a function.\n",
    "        self.magic_logic_understood = False\n",
    "        self.logic_num = [] # array which contain strings explaining the logic of the magic numbers\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.functions==other.functions) and (self.magic_numbers==other.magic_numbers) and (self.magic_logic_understood==other.magic_logic_understood) and (self.logic_num==other.logic_num)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(('functions', ','.join(str(v) for v in self.functions),\n",
    "                     'magic_numbers', ','.join(str(v) for v in self.magic_numbers),\n",
    "                     'magic_logic_understood', str(self.magic_logic_understood),\n",
    "                     'logic_num',','.join(str(v) for v in self.logic_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how much the predicted_out coming from entity_in is in line with the expected \n",
    "# attribute differences of the train in-out pairs in task_data.\n",
    "def attributes_similarity(task_data,entity_in,predicted_out_grid, verbose=False):\n",
    "    \n",
    "    sim_score = 0 # sim_score = 1 if the grids are equal\n",
    "    t_in_grid = entity_in.grid\n",
    "    \n",
    "    # slight misuse of the Task object. I'm using it to easily compute \"common_diff\" and \"sequence\" for [entity_in,predicted_out]\n",
    "    train_data = build_trainlist({\"train\":[{\"input\":t_in_grid,\"output\":predicted_out_grid},],})\n",
    "    #print(\"t_in_grid\",t_in_grid)\n",
    "    #print(\"predicted_out_grid\",predicted_out_grid)\n",
    "    t = Task(train_data, train_data)\n",
    "    t.compute_train_attributes()\n",
    "    t.compute_diff_attributes()\n",
    "    t.find_common_diff()\n",
    "    t.find_sequence()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n task_data.common_diff\", task_data.common_diff)\n",
    "        print(\"\\n t.common_diff\", t.common_diff)\n",
    "    \n",
    "    keys_to_exclude = ['color_perc_changed', 'most_common_color_changed', 'second_most_common_color_changed', \n",
    "                       'least_common_color_changed','h_symm_changed', 'v_symm_changed', 'ld_symm_changed',\n",
    "                       'rd_symm_changed', \"is_in_in_out\", \"is_out_in_in\"\n",
    "                       #'color_changed',\n",
    "                       #'new_colors',\n",
    "                       #'shape_changed',\n",
    "                       #\"h_shape_changed\", \"v_shape_changed\"\n",
    "                      ] \n",
    "    \n",
    "    normalisation = 0 # normalise to 1\n",
    "    \n",
    "    for key_diff, value in task_data.common_diff.items():\n",
    "        if (key_diff not in keys_to_exclude) and (task_data.common_diff[key_diff] !=0 ):\n",
    "            normalisation += 1\n",
    "            if (task_data.common_diff[key_diff] == t.common_diff[key_diff]): \n",
    "                sim_score += 1\n",
    "    \n",
    "    return sim_score/normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the programs which do not predict the expected attributes when acting on the test t_in\n",
    "def filter_programs(programs, task_data):\n",
    "    \n",
    "    filtered_trained_similarities = []\n",
    "    # Iterate Through Test Tasks\n",
    "    for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "        t_in = in_out_pair[0]\n",
    "\n",
    "        for prog_ram in programs: \n",
    "            #print(\"prog_ram\",[(x.functions,x.magic_numbers, x.magic_logic_understood) for x in [prog_ram]]) \n",
    "            # make the prediction\n",
    "            pred_generate = t_in.grid\n",
    "            get_magic_numbers_from_logic(prog_ram, t_in, task_data) \n",
    "            \n",
    "            # eliminate all the programs which have undefined magic numbers (the logic is working on the train set, but not on test)\n",
    "            ok_magic_numbers = not None in flatten_rec(prog_ram.magic_numbers)\n",
    "            \n",
    "            for num, func in enumerate(prog_ram.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, func, *prog_ram.magic_numbers[num])\n",
    "\n",
    "            if (pred_generate.size == 0) or (np.array_equal(pred_generate,black_square)):\n",
    "                continue\n",
    "            #print(\"prog_ram\",prog_ram.functions)\n",
    "            #print(\"mns\", prog_ram.magic_numbers)\n",
    "            #print(\"pred_generate\", pred_generate)\n",
    "            #print(\"t_in\", t_in.grid)\n",
    "            at_s = 1.0\n",
    "            if I_AM_IN_KAGGLE and (not DEBUG):\n",
    "                # TODO speedup\n",
    "                pass\n",
    "                at_s = attributes_similarity(task_data,t_in,pred_generate)#, verbose=True)\n",
    "            #print(\"at_s\",at_s)\n",
    "                 \n",
    "            if np.isclose(at_s, 1.0) and ok_magic_numbers:   # the program satisfies all the expected attributes     \n",
    "                filtered_trained_similarities.append(prog_ram)\n",
    "                \n",
    "    return filtered_trained_similarities \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Programs...\n",
      "--- 0.0037238597869873047 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Programs...\")\n",
    "        \n",
    "def pred_wrapper(grid, t, task_data, func, *magic_args):\n",
    "    grid_copy = grid.copy()\n",
    "    if DEBUG:\n",
    "        try:\n",
    "            return func(grid_copy, t, task_data, *magic_args)\n",
    "        except Exception as error:\n",
    "            return black_square\n",
    "    else:\n",
    "        try:\n",
    "            return func(grid_copy, t, task_data, *magic_args)\n",
    "        except:\n",
    "            return black_square\n",
    "        \n",
    "def get_sim_score(pred, reference):\n",
    "    if np.array_equal(pred, reference):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "# generate a candidate program\n",
    "def generate_programs(task_data):\n",
    "    \n",
    "    n_train_pairs = len(task_data.train_tensors)\n",
    "    max_solution_length = 2\n",
    "    \n",
    "    # compute attributes\n",
    "    task_data.compute_train_attributes()\n",
    "    task_data.compute_test_attributes()\n",
    "    task_data.compute_diff_attributes()\n",
    "    task_data.find_common_diff()\n",
    "    task_data.find_sequence()\n",
    "    \n",
    "    magic_numbers = get_magic_numbers(task_data)\n",
    "    \n",
    "    # candidate functions which when combined could deliver the correct solution program.\n",
    "    pred_functions = function_filter(task_data, DSL_fs_names)  \n",
    "    #print(\"pred_functions\", pred_functions)\n",
    "    \n",
    "    for in_out_pair in task_data.train_tensors:\n",
    "        t_in = in_out_pair[0]\n",
    "        t_out = in_out_pair[1]\n",
    "        \n",
    "        pred_similarities = []\n",
    "        for pred_func in pred_functions:\n",
    "            # run over all magic arguments\n",
    "            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "            for mn in magic_args:\n",
    "                # evaluate all the pred_functions on the t_in Tensor and keep track of their score\n",
    "                pred_generate = pred_wrapper(t_in.grid, t_in, task_data, pred_func, *mn)\n",
    "                sim_score = get_sim_score(pred_generate, t_out.grid)\n",
    "                list.append(pred_similarities,Program([pred_func],sim_score,\"Tensor\",[mn]))    \n",
    "            \n",
    "        \n",
    "        # keep the first n best scoring programs \n",
    "        n = len(pred_similarities)  \n",
    "        pred_similarities = sorted(pred_similarities, key=lambda x: x.sim_score, reverse=True)[:n]\n",
    "        trained_similarities = []\n",
    "        \n",
    "        \n",
    "        prediction_flags = [True] * len(pred_similarities) # flag if keep searching to update the function. \n",
    "        \n",
    "        # print(\"Seek Better Solution...\")\n",
    "        for j, program in enumerate(pred_similarities):\n",
    "            \n",
    "            current_prog = [program]\n",
    "            # If False, No Better program, store the program as it is now.\n",
    "            while prediction_flags[j] == True:\n",
    "                        \n",
    "                current_pred_func = None\n",
    "                current_pred_magic_numbers = None\n",
    "                new_current_prog = []\n",
    "                updated_flag = [False] * len(current_prog) # flag if the functions are being updated\n",
    "                \n",
    "                for k, prog in enumerate(current_prog):\n",
    "                    \n",
    "                                           \n",
    "                    # if the chains of functions is longer than allowed, add it to the functions to select\n",
    "                    if (len(prog.functions) >= max_solution_length):\n",
    "                        list.append(trained_similarities, prog)\n",
    "                        continue \n",
    "                        \n",
    "                    # compose the program\n",
    "                    pred_generate = t_in.grid \n",
    "                    for num, pred_func in enumerate(prog.functions):\n",
    "                        pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *prog.magic_numbers[num]) # function composition\n",
    "                    task_sim_score = get_sim_score(pred_generate.copy(), t_out.grid)\n",
    "                    current_pred_func = prog.functions\n",
    "                    current_pred_magic_numbers = prog.magic_numbers\n",
    "                    \n",
    "                                    \n",
    "                    look_for_updates = True  # Just put False if debugging\n",
    "                    if look_for_updates:\n",
    "                        updated_similarities = []\n",
    "\n",
    "                        # Iterate over all the functions to generate a new composite function\n",
    "                        for pred_func in pred_functions:\n",
    "                            if forbidden_composition([pred_func], current_pred_func): # skip this function, if composition is forbidden\n",
    "                                continue\n",
    "                            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "                            for mn in magic_args:\n",
    "                                pred_func_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *mn)\n",
    "                                task_sim_score = get_sim_score(pred_func_generate, t_out.grid)\n",
    "                                list.append(updated_similarities,Program([pred_func],task_sim_score,\"Tensor\",[mn]))\n",
    "\n",
    "                        \n",
    "                        # check if the new composite function scores better than the current_pred_func\n",
    "                        for p in updated_similarities:\n",
    "                            if forbidden_composition(p.functions, current_pred_func): # skip this function, if composition is forbidden\n",
    "                                continue\n",
    "                            if prog.sim_score == 1:\n",
    "                                improvement_threshold = 0 # DEBUG Normally this should be positive! \n",
    "                            else:\n",
    "                                improvement_threshold = -0.1 # DEBUG Normally this should be positive! (assuming max(score)= 1)\n",
    "                            if (p.sim_score > prog.sim_score + improvement_threshold): \n",
    "                                # the function have been improved! Now it will over the whole process again, to see if it can be improved further.\n",
    "                                \n",
    "                                new_current_prog.append(Program(current_pred_func + p.functions ,p.sim_score,\"Tensor\",current_pred_magic_numbers +p.magic_numbers)) \n",
    "                                if not updated_flag[k]:\n",
    "                                    updated_flag[k] = True     # at least one new function has been generated\n",
    "                            else:\n",
    "                                pass\n",
    "                  \n",
    "                    # the functions cannot be improved further (at least not with 1 step), add it to the functions to select\n",
    "                    if not updated_flag[k]: # no updates\n",
    "                        list.append(trained_similarities, prog)\n",
    "                \n",
    "                \n",
    "                #print(\"current_prog loop end\")\n",
    "                #print(\"...\")\n",
    "                current_prog = new_current_prog\n",
    "                \n",
    "                if len(current_prog)==0:\n",
    "                    prediction_flags[j] = False \n",
    "            #print(\"End prediction_flags[j] == True while loop\")\n",
    "            #print(\"-----------\")\n",
    "          \n",
    "        #print(\"End pred_similarities for loop\")\n",
    "        #print(\"-----------\")       \n",
    "        #print(\"trained_similarities\",[(x.functions,x.magic_numbers) for x in trained_similarities])\n",
    "        \n",
    "        return trained_similarities\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the programs which predict the same magic numbers on the test\n",
    "def filter_programs_with_same_magic_numbers(programs, task_data):\n",
    "    \n",
    "    ok_programs = []\n",
    "    ok_magic_numbers = []\n",
    "    n_programs = 3\n",
    "    \n",
    "    # Iterate Through Test Tasks\n",
    "    for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "        t_in = in_out_pair[0]\n",
    "\n",
    "        for prog_ram in programs: \n",
    "            \n",
    "            # stop if we find 3 different programs\n",
    "            if len(ok_programs) == n_programs:\n",
    "                return ok_programs\n",
    "            \n",
    "            get_magic_numbers_from_logic(prog_ram, t_in, task_data) \n",
    "            \n",
    "            mns_are_duplicate = False\n",
    "            for mns in ok_magic_numbers:\n",
    "                if (mns == prog_ram.magic_numbers):\n",
    "                    mns_are_duplicate = True\n",
    "                    break\n",
    "            if not mns_are_duplicate:\n",
    "                ok_magic_numbers.append(prog_ram.magic_numbers)\n",
    "                ok_programs.append(prog_ram)\n",
    "                \n",
    "    return ok_programs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Program ...\n",
      "--- 0.0025522708892822266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Select Program ...\")\n",
    "\n",
    "def select_programs(task_data, generated_programs):\n",
    "    \n",
    "    programs_without_logic = [] # when a program has a logic, add also a copy program without logic\n",
    "    programs_with_alternative_logic = [] # if the program has multiple valid logic, generate different programs from all the logic combinations\n",
    "    \n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(generated_programs):\n",
    "        program.task_accuracy = 0\n",
    "        logic_understood = []  # list of bools\n",
    "        logic_nums = [] # list of list of strings, containing the logic associated to the respective magic numbers\n",
    "    \n",
    "        # Iterate Through Train Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "        \n",
    "            pred_generate = t_in.grid\n",
    "            # predict\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "                             \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid):\n",
    "                program.task_accuracy += 1\n",
    "                \n",
    "                # check if the magic numbers follow a logic\n",
    "                program.logic_num = [-1] * len(program.functions) # -1 is a flag for bad outcome\n",
    "                for num, pred_func in enumerate(program.functions):\n",
    "                    program.logic_num[num] = [[] for _ in program.magic_numbers[num]] # define a list [[],[],[],...] https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "                    \n",
    "                    for j, n in enumerate(program.magic_numbers[num]):\n",
    "                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"color_related\"] > 0:\n",
    "                            # logic coming from a single grid\n",
    "                            if t_in.attributes[\"most_common_color\"] == n:\n",
    "                                program.logic_num[num][j].append(\"most_common_color\")\n",
    "                            if (\"second_most_common_color\" in t_in.attributes) and (t_in.attributes[\"second_most_common_color\"] == n):\n",
    "                                program.logic_num[num][j].append(\"second_most_common_color\")\n",
    "                            if t_in.attributes[\"least_common_color\"] == n:\n",
    "                                program.logic_num[num][j].append(\"least_common_color\")\n",
    "                            if t_in.attributes[\"border_color\"] == n:\n",
    "                                program.logic_num[num][j].append(\"border_color\")                \n",
    "                            # logic coming from all the in-out train pairs\n",
    "                            for i, cnc in enumerate(task_data.sequences[\"common_new_colors\"]):\n",
    "                                if cnc == n:\n",
    "                                    program.logic_num[num][j].append(\"common_new_colors\" + \"_\" + str(i))\n",
    "                                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"shape_related\"] > 0:\n",
    "                            if (\"out_shape_0\" in task_data.sequences) and (task_data.sequences[\"out_shape_0\"] == n):\n",
    "                                program.logic_num[num][j].append(\"out_shape_0\")\n",
    "                            if (\"out_shape_1\" in task_data.sequences) and (task_data.sequences[\"out_shape_1\"] == n):\n",
    "                                program.logic_num[num][j].append(\"out_shape_1\")\n",
    "                            if t_in.attributes[\"v_shape\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape\")\n",
    "                            if t_in.attributes[\"h_shape\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape\")\n",
    "                            if t_in.attributes[\"v_shape_half\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape_half\")\n",
    "                            if t_in.attributes[\"h_shape_half\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape_half\")\n",
    "                            if t_in.attributes[\"v_shape_third\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape_third\")\n",
    "                            if t_in.attributes[\"h_shape_third\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape_third\")\n",
    "                            if t_in.attributes[\"n_unique_colors\"] == n:\n",
    "                                program.logic_num[num][j].append(\"n_unique_colors\")\n",
    "                            if t_in.attributes[\"n_unique_non_backg_colors\"] == n:\n",
    "                                program.logic_num[num][j].append(\"n_unique_non_backg_colors\")\n",
    "                                \n",
    "                        if fs_argument_structure[pred_func.__name__][\"object_related\"] > 0:\n",
    "                            if t_in.attributes[\"top_left_corner\"] == n:\n",
    "                                program.logic_num[num][j].append(\"top_left_corner\")\n",
    "                            if t_in.attributes[\"top_mid_point\"] == n:\n",
    "                                program.logic_num[num][j].append(\"top_mid_point\")\n",
    "                            if t_in.attributes[\"left_mid_point\"] == n:\n",
    "                                program.logic_num[num][j].append(\"left_mid_point\")\n",
    "                        \n",
    "                        program.logic_num[num][j] = list(set(program.logic_num[num][j]))\n",
    "                        \n",
    "                # if all the numbers are recognized in some attribute, then we undestood the logic of the task (at least regarding magic numbers)\n",
    "                log_und = []\n",
    "                for k, logi in enumerate(program.logic_num):\n",
    "                    if (len(logi) == 0) and (number_of_magic_arguments(program.functions[k]) > 0):\n",
    "                        log_und.append(False)\n",
    "                    # handle the case in which the function takes no magic arguments\n",
    "                    elif (len(logi) == 0) and (number_of_magic_arguments(program.functions[k]) == 0):\n",
    "                        log_und.append(\"No Logic by default\")\n",
    "                \n",
    "                if not all(log_und):\n",
    "                    log_und = False\n",
    "                elif ((\"No Logic by default\" in log_und) and (all(log_und))):\n",
    "                    log_und = True\n",
    "                else:\n",
    "                    log_und = True\n",
    "                        \n",
    "                    \n",
    "                logic_understood.append(log_und)\n",
    "                logic_nums.append(program.logic_num)\n",
    "         \n",
    "        # END OF INPUT_OUTPUT PAIRS LOOP\n",
    "               \n",
    "        #print(\"program.functions\",program.functions) \n",
    "        #print(\"program.logic_num\",program.logic_num) \n",
    "        #print(\"program.logic_nums\",logic_nums) \n",
    "        \n",
    "        # generate programs with the combinations of all the logics\n",
    "        mns_fs = []*len(program.functions)\n",
    "        for lnms in program.logic_num: # iterate over the logic_num for each function\n",
    "            mns_fs.append([list(elem) for elem in list(itertools.product(*lnms))] ) \n",
    "        mns_fs = [list(elem) for elem in list(itertools.product(*mns_fs))]\n",
    "\n",
    "        for el in mns_fs:\n",
    "            prog_with_alternative_logic = copy.deepcopy(program)\n",
    "            prog_with_alternative_logic.logic_num = el  \n",
    "            prog_with_alternative_logic.magic_logic_understood = all(logic_understood) and (len(logic_understood)> 0)\n",
    "            #print(\"logic_understood\",logic_understood, el)\n",
    "            #print(\"prog_with_alternative_logic.magic_logic_understood\",prog_with_alternative_logic.magic_logic_understood, el)\n",
    "            for logi in el:\n",
    "                for ll in logi:\n",
    "                    # check that the logic appears in all the input-output pairs\n",
    "                    if not (all( ll in flatten_rec(sublist) for sublist in logic_nums)) : # this is not totally correct, as ll could be in the wrong nested list of sublist. So this check is too permissive.\n",
    "                        prog_with_alternative_logic.magic_logic_understood = False\n",
    "            if prog_with_alternative_logic.magic_logic_understood:\n",
    "                programs_with_alternative_logic.append(prog_with_alternative_logic)\n",
    "         \n",
    "        # append also a program without logic, it may actually solve the task!\n",
    "        prog_without_logic = program # this modifies the original program, as it is not deepcopied\n",
    "        prog_without_logic.logic_num = []\n",
    "        prog_without_logic.magic_logic_understood = False\n",
    "        programs_without_logic.append(prog_without_logic)\n",
    "        \n",
    "    \n",
    "    generated_programs.extend(programs_without_logic)\n",
    "    generated_programs.extend(programs_with_alternative_logic)\n",
    "    \n",
    "    # filter by requiring the prediction to have the expected attributes and that magic numbers are not None on test\n",
    "    generated_programs = filter_programs(generated_programs, task_data)\n",
    "    \n",
    "    # Select Best 3 Solutions\n",
    "    best_programs = list(set(generated_programs)) # remove duplicates\n",
    "    best_programs = sorted(best_programs, key=lambda x: x.magic_logic_understood, reverse=True) # give priority to programs which understood the logic\n",
    "    best_programs = sorted(best_programs, key=lambda x: len(x.functions), reverse=False) # give priority to short programs\n",
    "    best_programs = sorted(best_programs, key=lambda x: x.task_accuracy, reverse=True)\n",
    "    #print(\"best_programs sorted\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs])\n",
    "    best_programs = best_programs[:20]\n",
    "    #best_programs = filter_programs(best_programs, task_data)\n",
    "    best_programs = filter_programs_with_same_magic_numbers(best_programs, task_data)\n",
    "    print(\"best_programs filtered\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs]) \n",
    "    return best_programs\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the logic has been understood from the in-out pairs, use this logic to generate the magic numbers\n",
    "# which will solve the test prediction\n",
    "def get_magic_numbers_from_logic(program, t_in, task_data):\n",
    "    \n",
    "    if program.magic_logic_understood:\n",
    "        for num, logic_n in enumerate(program.logic_num):\n",
    "            for l,logic in enumerate(logic_n):\n",
    "                if logic in t_in.attributes: # logic coming from a single grid\n",
    "                    program.magic_numbers[num][l] = t_in.attributes[logic]\n",
    "                if logic in task_data.sequences: # logic coming from all the in-out train pairs\n",
    "                    program.magic_numbers[num][l] = task_data.sequences[logic] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Program Application Framework ...\n",
      "--- 0.0011851787567138672 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Program Application Framework ...\")\n",
    "\n",
    "# apply on the test tasks\n",
    "def compute_test_accuracy(task_n, task_data, best_programs):\n",
    "\n",
    "    # Initialize Local Variables\n",
    "    output_test = 0\n",
    "    good_programs = []\n",
    "    good_logics = []\n",
    "    num_test = len(task_data.test_tensors)\n",
    "\n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(best_programs):\n",
    "        program.task_accuracy = 0\n",
    "\n",
    "        # Iterate Through Test Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "\n",
    "            pred_generate = t_in.grid\n",
    "            \n",
    "            # build magic numbers from the logic\n",
    "            get_magic_numbers_from_logic(program, t_in, task_data)                       \n",
    "            \n",
    "            # make the prediction\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "            \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid): \n",
    "                program.task_accuracy += 1\n",
    "\n",
    "        if program.task_accuracy >= 1:\n",
    "            good_programs.append(program.functions)\n",
    "            good_logics.append(program.logic_num)\n",
    "            output_test += 1\n",
    "         \n",
    "        # Print Log of Task, Program, Accuracy, Percentage Accurate\n",
    "        percent_accuracy = np.round((program.task_accuracy / num_test * 100), 2)\n",
    "        print(\"(Test:{}.{:02d})-(Program:{}, MNs:{}, logic:{})- Acc:{}/{}\".format(\n",
    "            task_n, i, [f.__name__ for f in program.functions], [mn for mn in program.magic_numbers], program.logic_num, program.task_accuracy, num_test))\n",
    "\n",
    "    # Return Accuracy\n",
    "    output_test = int(output_test >= 1)\n",
    "    return {\"accuracy\":output_test,\"good_programs\":[[f.__name__ for f in fs] for fs in good_programs],\"logic\":good_logics}\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Program Submission Framework ...\n",
      "--- 0.0006148815155029297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Program Submission Framework ...\")\n",
    "\n",
    "def submit_program_to_LB(task_data, selected_programs):\n",
    "\n",
    "    # Initialize Local Variables\n",
    "    output_data = \"\"    \n",
    "    \n",
    "    # Iterate Through Selected Programs\n",
    "    for i, program in enumerate(selected_programs):\n",
    "\n",
    "        # Iterate Through Test Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            \n",
    "            pred_generate = t_in.grid\n",
    "            \n",
    "            # build magic numbers from the logic\n",
    "            get_magic_numbers_from_logic(program, t_in, task_data)                       \n",
    "            \n",
    "            # make the prediction\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "    \n",
    "            # Format Output Data as String\n",
    "            output_data += (flattener(pred_generate) + ' ')\n",
    "    \n",
    "    # Return Output\n",
    "    return output_data\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Training Set) ...\n",
      "Generating Program for Task 99\n",
      "diff {'color_changed': 1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': 1, 'least_common_color_changed': 1, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': 1, 'v_symm_changed': 1, 'ld_symm_changed': 1, 'rd_symm_changed': 1, 'is_in_in_out': -1, 'is_out_in_in': -1}\n",
      "functions removed {'superp_reg_2', 'mirror_2', 'mirror_1', 'superp_8', 'mirror_4', 'color_ob_1', 'superp_3', 'superp_6', 'rescale_1', 'superp_reg_1', 'superp_1', 'mirror_3', 'special_2', 'superp_4', 'superp_reg_4', 'draw_reg_3', 'superp_5', 'superp_2', 'draw_reg_1', 'draw_reg_2', 'superp_reg_3', 'superp_7', 'repeat_1'}\n",
      "best_programs filtered [([<function symmetric_1 at 0x12f9f7560>, <function crop_3 at 0x12fa21e60>], [[], [4]], 2, False, []), ([<function special_1 at 0x12fa30b00>], [[3, 2, 2]], 1, True, [['second_most_common_color', 'out_shape_1', 'n_unique_non_backg_colors']]), ([<function special_1 at 0x12fa30b00>], [[3, 9, 2]], 1, True, [['second_most_common_color', 'least_common_color', 'out_shape_1']])]\n",
      "(Test:99.00)-(Program:['symmetric_1', 'crop_3'], MNs:[[], [4]], logic:[])- Acc:0/1\n",
      "(Test:99.01)-(Program:['special_1'], MNs:[[3, 2, 2]], logic:[['second_most_common_color', 'out_shape_1', 'n_unique_non_backg_colors']])- Acc:1/1\n",
      "(Test:99.02)-(Program:['special_1'], MNs:[[3, 9, 2]], logic:[['second_most_common_color', 'least_common_color', 'out_shape_1']])- Acc:0/1\n",
      "Generation Took 4.235244035720825 Seconds\n",
      "Training Set - Final Accuracy: 1 / 1 \n",
      " Training Set - Accurate Tasks: [99] \n",
      " --------------------\n",
      "--- 4.23708176612854 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Training Set) ...\")\n",
    "\n",
    "accuracy_full = 0\n",
    "accuracy_tasks = []\n",
    "detailed_accuracy_tasks = []\n",
    "slow_tasks = []\n",
    "training_flag = True \n",
    "start=99\n",
    "finish=start+1\n",
    "if (training_flag == True) and DEBUG:\n",
    "    for task_n in range(start,finish):\n",
    "        task_time = time.time()\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        accuracy = []\n",
    "        \n",
    "        train_data = build_trainlist(train_task_data[task_n])\n",
    "        test_data = build_testlist(train_task_data[task_n])\n",
    "        task_data = Task(train_data, test_data)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        res = compute_test_accuracy(task_n, task_data, best_programs)\n",
    "        \n",
    "        time_spent = time.time() - task_time\n",
    "        print(\"Generation Took %s Seconds\" % (time_spent))\n",
    "        accuracy_full += res[\"accuracy\"]\n",
    "\n",
    "        if res[\"accuracy\"] >= 1:\n",
    "            list.append(accuracy_tasks, task_n)\n",
    "            list.append(detailed_accuracy_tasks, [task_n,res[\"good_programs\"],res[\"logic\"]])\n",
    "    \n",
    "        if time_spent > 60:\n",
    "            slow_tasks.append([task_n,time_spent])\n",
    "            \n",
    "        report_0 = \"Training Set - Final Accuracy: {} / {}\".format(accuracy_full, finish-start)\n",
    "        report_1 = \"Training Set - Accurate Tasks: {}\".format(accuracy_tasks)\n",
    "        report_2 = \"Training Set - Detailed Accurate Tasks: {}\".format(detailed_accuracy_tasks)\n",
    "        report_slow = \"Training Set - Slow Tasks: {}\".format(slow_tasks)\n",
    "        print(report_0, \"\\n\", report_1, \"\\n\", \"--------------------\" )\n",
    "        final_report = report_0 + \" \\n \" + report_1 + \" \\n \" + report_2 + \" \\n \" + report_slow + \" \\n \" + str(time.time() - start_time) + \" seconds\"\n",
    "        if (((task_n%50==0) or (task_n==finish-start-1)) and (task_n!=0)) and DEBUG:\n",
    "            #send_slack_report(final_report)\n",
    "            pass\n",
    "            \n",
    "if DEBUG and I_AM_IN_KAGGLE:\n",
    "    send_slack_report(final_report)\n",
    "    pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Evaluation Set) ...\n",
      "--- 0.0017039775848388672 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Evaluation Set) ...\")\n",
    "\n",
    "accuracy_full = 0\n",
    "accuracy_tasks = []\n",
    "detailted_accuracy_tasks = []\n",
    "evaluation_flag = False\n",
    "start=42#0\n",
    "finish=43 #400\n",
    "if evaluation_flag == True:\n",
    "    for task_n in range(start,finish):\n",
    "        task_time = time.time()\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        accuracy = []\n",
    "        \n",
    "        train_data = build_trainlist(eval_task_data[task_n])\n",
    "        test_data = build_testlist(eval_task_data[task_n])\n",
    "        task_data = Task(train_data, test_data)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        res = compute_test_accuracy(task_n, task_data, best_programs)\n",
    "        \n",
    "        print(\"Generation Took %s Seconds\" % (time.time() - task_time))\n",
    "        accuracy_full += res[\"accuracy\"]\n",
    "\n",
    "        if res[\"accuracy\"] >= 1:\n",
    "            list.append(accuracy_tasks, task_n)\n",
    "            list.append(detailted_accuracy_tasks, [task_n,res[\"good_programs\"],res[\"logic\"]])\n",
    "            \n",
    "        report_0 = \"Evaluation Set - Final Accuracy: {} / {}\".format(accuracy_full, finish-start)\n",
    "        report_1 = \"Evaluation Set - Accurate Tasks: {}\".format(accuracy_tasks)\n",
    "        report_2 = \"Evaluation Set - Detailed Accurate Tasks: {}\".format(detailted_accuracy_tasks)\n",
    "        print(report_0, \"\\n\", report_1, \"\\n\", \"--------------------\" )\n",
    "        final_report = report_0 + \" \\n \" + report_1 + \" \\n \" + report_2 + \" \\n \" + str(time.time() - start_time) + \" seconds\"\n",
    "        if (((task_n%50==0) or (task_n==finish-start-1)) and (task_n!=0)) and DEBUG:\n",
    "            #send_slack_report(final_report)\n",
    "            pass\n",
    "            \n",
    "if DEBUG:\n",
    "    #send_slack_report(final_report)\n",
    "    pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Submission to LB) ...\n",
      "\n",
      "\n",
      "--- 0.003504037857055664 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Submission to LB) ...\\n\")\n",
    "\n",
    "task_n = 0\n",
    "submit_to_LB_flag = I_AM_IN_KAGGLE and (not DEBUG)\n",
    "if submit_to_LB_flag == True:\n",
    "    for output_id in submission.index:\n",
    "\n",
    "        task_id = output_id.split('_')[0]\n",
    "        pair_id = int(output_id.split('_')[1])\n",
    "        if pair_id == 1:\n",
    "            task_n -= 1 # there are 100 tasks, but 4 of them have a second version with pair_id = 1 instead of = 0.\n",
    "        f = str(testing_path / str(task_id + '.json'))\n",
    "        with open(f, 'r') as read_file:\n",
    "            task = json.load(read_file)\n",
    "\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        train_data = build_trainlist(test_task_data[task_n])\n",
    "        test_data = build_testlist(test_task_data[task_n], LB_submission=True, pair_id=pair_id)\n",
    "        task_data = Task(train_data, test_data, LB_submission=True)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        program_data = submit_program_to_LB(task_data, best_programs)\n",
    "        submission.loc[output_id, 'output'] = program_data \n",
    "        task_n += 1\n",
    "        print(\"-------\")\n",
    "    \n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Submission to CSV ...\n",
      "--- 0.030968904495239258 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Output Submission to CSV ...\")\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work Area. Feel free to clean if it gets too messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff {'color_changed': 1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': -1, 'second_most_common_color_changed': 0, 'least_common_color_changed': 0, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': -1, 'is_out_in_in': 1}\n",
      "functions removed {'symmetric_2', 'color_2', 'superp_reg_2', 'mirror_2', 'repeat_2', 'mirror_1', 'superp_8', 'mirror_4', 'rotate_3', 'color_3', 'rotate_1', 'mirror_5', 'color_ob_1', 'superp_3', 'rescale_1', 'superp_6', 'superp_reg_1', 'rotate_2', 'color_1', 'superp_1', 'mirror_3', 'special_2', 'superp_4', 'flip_1', 'superp_reg_4', 'draw_reg_3', 'superp_5', 'flip_2', 'special_1', 'superp_2', 'draw_reg_1', 'draw_reg_2', 'repeat_1', 'superp_7', 'superp_reg_3', 'symmetric_1'}\n",
      "{'color_related': [0, 2, 3, 4, 5, 6, 8, 9], 'shape_related': [1, 2, 3, 4, 5, 6, 8, 9, 10], 'regions_related': [], 'object_related': [(4, 5), (7, 3), (3, 4)], 'layer_related': [], 'axis_related': []}\n",
      "len(prepare_magic_arguments(special_1, magic_numbers) 648\n",
      "{'color_changed': True, 'new_colors': [], 'color_perc_changed': True, 'most_common_color_changed': False, 'second_most_common_color_changed': False, 'least_common_color_changed': False, 'shape_changed': True, 'h_shape_changed': True, 'v_shape_changed': True, 'h_symm_changed': False, 'v_symm_changed': False, 'ld_symm_changed': False, 'rd_symm_changed': False, 'is_in_in_out': [], 'is_out_in_in': [(4, 5)]}\n",
      "{'color_changed': 1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': -1, 'second_most_common_color_changed': 0, 'least_common_color_changed': 0, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': -1, 'is_out_in_in': 1}\n",
      "{'common_new_colors': [], 'out_shape_0': -1, 'out_shape_1': -1, 'max_in_shape': 23, 'min_in_shape': 13, 'max_out_shape': 10, 'min_out_shape': 3, 'prime_in_shape_0': True, 'prime_in_shape_1': False, 'n_colors': 0, 'max_n_objects_in': 3, 'min_n_objects_in': 1, 'max_n_objects_out': 1, 'min_n_objects_out': 1, 'max_n_regions_in': 1, 'min_n_regions_in': 1, 'max_n_regions_out': 1, 'min_n_regions_out': 1, 'max_max_color_perc_in': 0.3557692307692308, 'min_max_color_perc_in': 0.2546583850931677, 'max_max_color_perc_out': 0.3375, 'min_max_color_perc_out': 0.26666666666666666}\n",
      "{'unique_colors': [0, 1, 3, 5, 8], 'n_unique_colors': 5, 'n_unique_non_backg_colors': 4, 'grid_colors_perc': OrderedDict([(0, 0.3333333333333333), (3, 0.3333333333333333), (1, 0.16666666666666666), (8, 0.10416666666666667), (5, 0.0625), (2, 0.0), (4, 0.0), (6, 0.0), (7, 0.0), (9, 0.0)]), 'max_color_perc': 0.3333333333333333, 'most_common_color': 0, 'second_most_common_color': 3, 'least_common_color': 5, 'border_color': None, 'grid_shape': (6, 8), 'v_shape': 6, 'h_shape': 8, 'v_shape_half': 3, 'h_shape_half': 4, 'v_shape_third': 2, 'h_shape_third': 2, 'h_symm': False, 'v_symm': False, 'ld_symm': False, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': (0, 4), 'left_mid_point': (3, 0), 'lines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}, 'n_objects': 1, 'n_regions': 1}\n"
     ]
    }
   ],
   "source": [
    "task_n = 28\n",
    "train_data = build_trainlist(train_task_data[task_n])\n",
    "test_data = build_testlist(train_task_data[task_n])\n",
    "task_data = Task(train_data, test_data)\n",
    "task_data.compute_train_attributes()\n",
    "task_data.compute_test_attributes()\n",
    "task_data.compute_diff_attributes()\n",
    "task_data.find_common_diff()\n",
    "task_data.find_sequence()\n",
    "magic_numbers = get_magic_numbers(task_data)\n",
    "pred_functions = function_filter(task_data, DSL_fs_names) \n",
    "print(magic_numbers)\n",
    "print(\"len(prepare_magic_arguments(special_1, magic_numbers)\",len(prepare_magic_arguments(special_1, magic_numbers)))\n",
    "#print(prepare_magic_arguments(special_1, magic_numbers))\n",
    "print(task_data.train_diff[0])\n",
    "print(task_data.common_diff)\n",
    "print(task_data.sequences)\n",
    "print(task_data.train_tensors[0][1].attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Manual) ...\n",
      "2\n",
      "Error: zero-size array to reduction operation minimum which has no identity\n",
      "None\n",
      "None\n",
      "--- 0.7749691009521484 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Manual) ...\")\n",
    "\n",
    "\n",
    "\n",
    "def combine_tasks(a):\n",
    "    b = a.copy()\n",
    "    t_in = task_data.train_tensors[0][0]\n",
    "    try:\n",
    "        #t_in = task_data.test_tensors[0][0]\n",
    "        #b = repeat_2(b,t_in, task_data)\n",
    "        #b = superp_2(b,t_in, task_data,*[0,1,2])\n",
    "        #b = superp_ob(b,t_in, task_data,*[0,1])\n",
    "        #b = superp_reg_2(b,t_in, task_data,*[0,8])\n",
    "        #b = draw_reg_1(b,t_in, task_data,*[])\n",
    "        #b = color_ob_1(b,t_in, task_data,*[3])\n",
    "        b = crop_1(b,t_in, task_data,*[2])\n",
    "        print(is_border_monocolor(b))\n",
    "        b = crop_3(b,t_in, task_data,*[1])\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return b\n",
    "    \n",
    "    return b\n",
    "\n",
    "tasks_indices = [task_n]\n",
    "for task in tasks_indices:\n",
    "    check_p(train_task_data[task], combine_tasks)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeit flip_2(tt,task_data.train_tensors[0][0], task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_colors': [5, 7], 'n_unique_colors': 2, 'n_unique_non_backg_colors': 1, 'grid_colors_perc': OrderedDict([(7, 0.6666666666666666), (5, 0.3333333333333333), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (6, 0.0), (8, 0.0), (9, 0.0)]), 'max_color_perc': 0.6666666666666666, 'most_common_color': 7, 'second_most_common_color': 5, 'least_common_color': 5, 'grid_shape': (1, 3), 'v_shape': 1, 'h_shape': 3, 'v_shape_half': None, 'h_shape_half': None, 'v_shape_third': None, 'h_shape_third': None, 'h_symm': True, 'v_symm': True, 'ld_symm': False, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': None, 'left_mid_point': None, 'lines': {'h_lines': [], 'v_lines': [0, 1, 2], 'rd_lines': [], 'ld_lines': []}, 'has_hole': False, 'holes_coords_obj': None, 'holes_coords_parent': None}\n",
      "[[7 5 7]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 6 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 5 0 7 5 7 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0]\n",
      " [0 0 2 2 0 0 3 3 3 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0]]\n",
      "[[3 4]\n",
      " [3 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "dd = task_data.train_tensors[1][0].objects[1]\n",
    "print(dd.attributes)\n",
    "print(dd.grid)\n",
    "print(dd.parent_grid)\n",
    "print(dd.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_colors': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'n_unique_colors': 10, 'n_unique_non_backg_colors': 9, 'grid_colors_perc': OrderedDict([(0, 0.5933333333333334), (9, 0.13666666666666666), (7, 0.09111111111111111), (1, 0.04888888888888889), (5, 0.044444444444444446), (4, 0.04), (2, 0.016666666666666666), (6, 0.013333333333333334), (8, 0.012222222222222223), (3, 0.0033333333333333335)]), 'max_color_perc': 0.5933333333333334, 'most_common_color': 0, 'second_most_common_color': 9, 'least_common_color': 3, 'grid_shape': (30, 30), 'v_shape': 30, 'h_shape': 30, 'v_shape_half': 15, 'h_shape_half': 15, 'v_shape_third': 10, 'h_shape_third': 10, 'h_symm': False, 'v_symm': False, 'ld_symm': False, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': (0, 15), 'left_mid_point': (15, 0), 'lines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}}\n",
      "[[0 0 0 0 0 0 0 0 6 6 5 5 0 1 0 0 0 0 1 0 5 5 6 6 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 6 6 5 0 1 0 0 7 7 0 0 1 0 5 6 6 0 0 5 0 0 0]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 7 0 8 0 0 9 9 9 9 9 9 9 0 0 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 4 0 0 5 9 9 9 9 9 9 9 0 5 0 9 9 9 9 9 9 9 9]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 9 9 9 9 9 9 9 0 0 5 9 9 9 9 9 9 4 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 9 9 9 9 9 9 9 1 0 0 9 9 9 9 9 9 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 9 9 9 9 9 9 9 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 9 9 9 9 9 9 9 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 0 1 1 0 0 1 1 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 4 0 7 0 0]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 0 0 7 0 0 7 0 0 0 5 0 0 2 0 7 0 4 0]\n",
      " [5 5 4 0 0 0 0 0 4 0 0 5 0 0 0 7 7 0 0 0 5 0 0 4 0 0 0 0 0 4]\n",
      " [6 6 5 0 1 0 0 7 0 8 0 0 0 0 0 0 0 0 0 0 0 0 8 0 7 0 0 1 0 5]\n",
      " [6 6 5 5 0 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 1 0 5 5]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 7 0 0 0 0 0 0 7]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 0 0 0 3 0 0 7 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]]\n",
      "[[0 0 0 0 0 0 0 0 6 6 5 5 0 1 0 0 0 0 1 0 5 5 6 6 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 6 6 5 0 1 0 0 7 7 0 0 1 0 5 6 6 0 0 5 0 0 0]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 9 9 9 9 9 9 9 9]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 7 0 8 0 0 9 9 9 9 9 9 9 0 0 0 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 0 4 0 0 5 9 9 9 9 9 9 9 0 5 0 9 9 9 9 9 9 9 9]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 9 9 9 9 9 9 9 0 0 5 9 9 9 9 9 9 4 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 9 9 9 9 9 9 9 1 0 0 9 9 9 9 9 9 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 9 9 9 9 9 9 9 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 9 9 9 9 9 9 9 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 7 0 2 0 0 0 0 0 0 7 0 1 1 0 1 1 0 1 1 0 7 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 4 0 8 0 0 0 0 7 0 1 1 0 0 1 1 0 7 0 0 0 0 8 0 4 0 0]\n",
      " [1 0 0 7 0 7 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 7 0 7 0]\n",
      " [0 1 0 0 7 0 4 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 4 0 7 0 0]\n",
      " [5 0 0 4 0 7 0 2 0 0 5 0 0 0 7 0 0 7 0 0 0 5 0 0 2 0 7 0 4 0]\n",
      " [5 5 4 0 0 0 0 0 4 0 0 5 0 0 0 7 7 0 0 0 5 0 0 4 0 0 0 0 0 4]\n",
      " [6 6 5 0 1 0 0 7 0 8 0 0 0 0 0 0 0 0 0 0 0 0 8 0 7 0 0 1 0 5]\n",
      " [6 6 5 5 0 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 1 0 5 5]\n",
      " [0 0 7 0 0 0 0 0 0 7 0 2 0 0 0 0 0 0 0 0 2 0 7 0 0 0 0 0 0 7]\n",
      " [0 0 0 7 0 0 3 0 0 0 0 0 4 0 8 0 0 8 0 4 0 0 0 0 0 3 0 0 7 0]\n",
      " [0 5 0 0 0 0 0 0 1 0 0 7 0 7 0 0 0 0 7 0 7 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 7 0 4 0 0 4 0 7 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 7 7 0 0 7 0 5 0 0 4 0 7 0 2 2 0 7 0 4 0 0 5 0 7 0 0 7 7]\n",
      " [0 0 7 7 0 0 0 7 5 5 4 0 0 0 0 0 0 0 0 0 0 4 5 5 7 0 0 0 7 7]]\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [0, 14], [0, 15], [0, 16], [0, 17], [0, 18], [0, 19], [0, 20], [0, 21], [0, 22], [0, 23], [0, 24], [0, 25], [0, 26], [0, 27], [0, 28], [0, 29], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [1, 15], [1, 16], [1, 17], [1, 18], [1, 19], [1, 20], [1, 21], [1, 22], [1, 23], [1, 24], [1, 25], [1, 26], [1, 27], [1, 28], [1, 29], [2, 0], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [2, 15], [2, 16], [2, 17], [2, 18], [2, 19], [2, 20], [2, 21], [2, 22], [2, 23], [2, 24], [2, 25], [2, 26], [2, 27], [2, 28], [2, 29], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [3, 14], [3, 15], [3, 16], [3, 17], [3, 18], [3, 19], [3, 20], [3, 21], [3, 22], [3, 23], [3, 24], [3, 25], [3, 26], [3, 27], [3, 28], [3, 29], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [4, 15], [4, 16], [4, 17], [4, 18], [4, 19], [4, 20], [4, 21], [4, 22], [4, 23], [4, 24], [4, 25], [4, 26], [4, 27], [4, 28], [4, 29], [5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [5, 15], [5, 16], [5, 17], [5, 18], [5, 19], [5, 20], [5, 21], [5, 22], [5, 23], [5, 24], [5, 25], [5, 26], [5, 27], [5, 28], [5, 29], [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [6, 15], [6, 16], [6, 17], [6, 18], [6, 19], [6, 20], [6, 21], [6, 22], [6, 23], [6, 24], [6, 25], [6, 26], [6, 27], [6, 28], [6, 29], [7, 0], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 17], [7, 18], [7, 19], [7, 20], [7, 21], [7, 22], [7, 23], [7, 24], [7, 25], [7, 26], [7, 27], [7, 28], [7, 29], [8, 0], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [8, 14], [8, 15], [8, 16], [8, 17], [8, 18], [8, 19], [8, 20], [8, 21], [8, 22], [8, 23], [8, 24], [8, 25], [8, 26], [8, 27], [8, 28], [8, 29], [9, 0], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [9, 14], [9, 15], [9, 16], [9, 17], [9, 18], [9, 19], [9, 20], [9, 21], [9, 22], [9, 23], [9, 24], [9, 25], [9, 26], [9, 27], [9, 28], [9, 29], [10, 0], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [10, 14], [10, 15], [10, 16], [10, 17], [10, 18], [10, 19], [10, 20], [10, 21], [10, 22], [10, 23], [10, 24], [10, 25], [10, 26], [10, 27], [10, 28], [10, 29], [11, 0], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [11, 14], [11, 15], [11, 16], [11, 17], [11, 18], [11, 19], [11, 20], [11, 21], [11, 22], [11, 23], [11, 24], [11, 25], [11, 26], [11, 27], [11, 28], [11, 29], [12, 0], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [12, 14], [12, 15], [12, 16], [12, 17], [12, 18], [12, 19], [12, 20], [12, 21], [12, 22], [12, 23], [12, 24], [12, 25], [12, 26], [12, 27], [12, 28], [12, 29], [13, 0], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13], [13, 14], [13, 15], [13, 16], [13, 17], [13, 18], [13, 19], [13, 20], [13, 21], [13, 22], [13, 23], [13, 24], [13, 25], [13, 26], [13, 27], [13, 28], [13, 29], [14, 0], [14, 1], [14, 2], [14, 3], [14, 4], [14, 5], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 11], [14, 12], [14, 13], [14, 14], [14, 15], [14, 16], [14, 17], [14, 18], [14, 19], [14, 20], [14, 21], [14, 22], [14, 23], [14, 24], [14, 25], [14, 26], [14, 27], [14, 28], [14, 29], [15, 0], [15, 1], [15, 2], [15, 3], [15, 4], [15, 5], [15, 6], [15, 7], [15, 8], [15, 9], [15, 10], [15, 11], [15, 12], [15, 13], [15, 14], [15, 15], [15, 16], [15, 17], [15, 18], [15, 19], [15, 20], [15, 21], [15, 22], [15, 23], [15, 24], [15, 25], [15, 26], [15, 27], [15, 28], [15, 29], [16, 0], [16, 1], [16, 2], [16, 3], [16, 4], [16, 5], [16, 6], [16, 7], [16, 8], [16, 9], [16, 10], [16, 11], [16, 12], [16, 13], [16, 14], [16, 15], [16, 16], [16, 17], [16, 18], [16, 19], [16, 20], [16, 21], [16, 22], [16, 23], [16, 24], [16, 25], [16, 26], [16, 27], [16, 28], [16, 29], [17, 0], [17, 1], [17, 2], [17, 3], [17, 4], [17, 5], [17, 6], [17, 7], [17, 8], [17, 9], [17, 10], [17, 11], [17, 12], [17, 13], [17, 14], [17, 15], [17, 16], [17, 17], [17, 18], [17, 19], [17, 20], [17, 21], [17, 22], [17, 23], [17, 24], [17, 25], [17, 26], [17, 27], [17, 28], [17, 29], [18, 0], [18, 1], [18, 2], [18, 3], [18, 4], [18, 5], [18, 6], [18, 7], [18, 8], [18, 9], [18, 10], [18, 11], [18, 12], [18, 13], [18, 14], [18, 15], [18, 16], [18, 17], [18, 18], [18, 19], [18, 20], [18, 21], [18, 22], [18, 23], [18, 24], [18, 25], [18, 26], [18, 27], [18, 28], [18, 29], [19, 0], [19, 1], [19, 2], [19, 3], [19, 4], [19, 5], [19, 6], [19, 7], [19, 8], [19, 9], [19, 10], [19, 11], [19, 12], [19, 13], [19, 14], [19, 15], [19, 16], [19, 17], [19, 18], [19, 19], [19, 20], [19, 21], [19, 22], [19, 23], [19, 24], [19, 25], [19, 26], [19, 27], [19, 28], [19, 29], [20, 0], [20, 1], [20, 2], [20, 3], [20, 4], [20, 5], [20, 6], [20, 7], [20, 8], [20, 9], [20, 10], [20, 11], [20, 12], [20, 13], [20, 14], [20, 15], [20, 16], [20, 17], [20, 18], [20, 19], [20, 20], [20, 21], [20, 22], [20, 23], [20, 24], [20, 25], [20, 26], [20, 27], [20, 28], [20, 29], [21, 0], [21, 1], [21, 2], [21, 3], [21, 4], [21, 5], [21, 6], [21, 7], [21, 8], [21, 9], [21, 10], [21, 11], [21, 12], [21, 13], [21, 14], [21, 15], [21, 16], [21, 17], [21, 18], [21, 19], [21, 20], [21, 21], [21, 22], [21, 23], [21, 24], [21, 25], [21, 26], [21, 27], [21, 28], [21, 29], [22, 0], [22, 1], [22, 2], [22, 3], [22, 4], [22, 5], [22, 6], [22, 7], [22, 8], [22, 9], [22, 10], [22, 11], [22, 12], [22, 13], [22, 14], [22, 15], [22, 16], [22, 17], [22, 18], [22, 19], [22, 20], [22, 21], [22, 22], [22, 23], [22, 24], [22, 25], [22, 26], [22, 27], [22, 28], [22, 29], [23, 0], [23, 1], [23, 2], [23, 3], [23, 4], [23, 5], [23, 6], [23, 7], [23, 8], [23, 9], [23, 10], [23, 11], [23, 12], [23, 13], [23, 14], [23, 15], [23, 16], [23, 17], [23, 18], [23, 19], [23, 20], [23, 21], [23, 22], [23, 23], [23, 24], [23, 25], [23, 26], [23, 27], [23, 28], [23, 29], [24, 0], [24, 1], [24, 2], [24, 3], [24, 4], [24, 5], [24, 6], [24, 7], [24, 8], [24, 9], [24, 10], [24, 11], [24, 12], [24, 13], [24, 14], [24, 15], [24, 16], [24, 17], [24, 18], [24, 19], [24, 20], [24, 21], [24, 22], [24, 23], [24, 24], [24, 25], [24, 26], [24, 27], [24, 28], [24, 29], [25, 0], [25, 1], [25, 2], [25, 3], [25, 4], [25, 5], [25, 6], [25, 7], [25, 8], [25, 9], [25, 10], [25, 11], [25, 12], [25, 13], [25, 14], [25, 15], [25, 16], [25, 17], [25, 18], [25, 19], [25, 20], [25, 21], [25, 22], [25, 23], [25, 24], [25, 25], [25, 26], [25, 27], [25, 28], [25, 29], [26, 0], [26, 1], [26, 2], [26, 3], [26, 4], [26, 5], [26, 6], [26, 7], [26, 8], [26, 9], [26, 10], [26, 11], [26, 12], [26, 13], [26, 14], [26, 15], [26, 16], [26, 17], [26, 18], [26, 19], [26, 20], [26, 21], [26, 22], [26, 23], [26, 24], [26, 25], [26, 26], [26, 27], [26, 28], [26, 29], [27, 0], [27, 1], [27, 2], [27, 3], [27, 4], [27, 5], [27, 6], [27, 7], [27, 8], [27, 9], [27, 10], [27, 11], [27, 12], [27, 13], [27, 14], [27, 15], [27, 16], [27, 17], [27, 18], [27, 19], [27, 20], [27, 21], [27, 22], [27, 23], [27, 24], [27, 25], [27, 26], [27, 27], [27, 28], [27, 29], [28, 0], [28, 1], [28, 2], [28, 3], [28, 4], [28, 5], [28, 6], [28, 7], [28, 8], [28, 9], [28, 10], [28, 11], [28, 12], [28, 13], [28, 14], [28, 15], [28, 16], [28, 17], [28, 18], [28, 19], [28, 20], [28, 21], [28, 22], [28, 23], [28, 24], [28, 25], [28, 26], [28, 27], [28, 28], [28, 29], [29, 0], [29, 1], [29, 2], [29, 3], [29, 4], [29, 5], [29, 6], [29, 7], [29, 8], [29, 9], [29, 10], [29, 11], [29, 12], [29, 13], [29, 14], [29, 15], [29, 16], [29, 17], [29, 18], [29, 19], [29, 20], [29, 21], [29, 22], [29, 23], [29, 24], [29, 25], [29, 26], [29, 27], [29, 28], [29, 29]]\n"
     ]
    }
   ],
   "source": [
    "#rr = Region(task_data.train_tensors[0][0].grid,regions[0])\n",
    "#rr.compute_attributes()\n",
    "rr = task_data.train_tensors[0][0].regions[0]\n",
    "print(rr.attributes)\n",
    "print(rr.grid)\n",
    "print(rr.parent_grid)\n",
    "print(rr.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newly solved tasks:  [1, 48, 186, 250, 337]\n",
      "old broken tasks:  [371]\n"
     ]
    }
   ],
   "source": [
    "score_old =   [2, 5, 13, 25, 30, 35, 38, 47, 55, 56, 71, 82, 86, 99, 102, 112, 115, 128, 134, 139, 141, 143, 145, 149, 151, 152, 154, 163, 171, 176, 178, 187, 195, 206, 209, 210, 222, 226, 230, 235, 240, 243, 248, 258, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 317, 318, 325, 346, 371, 379, 383, 384, 385, 388, 394]\n",
    "score_new = [1, 2, 5, 13, 25, 30, 35, 38, 47, 48, 55, 56, 71, 82, 86, 99, 102, 112, 115, 128, 134, 139, 141, 143, 145, 149, 151, 152, 154, 163, 171, 176, 178, 186, 187, 195, 206, 209, 210, 222, 226, 230, 235, 240, 243, 248, 250, 258, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 317, 318, 325, 337, 346, 379, 383, 384, 385, 388, 394]\n",
    "\n",
    "print(\"newly solved tasks: \", [item for item in score_new if item not in score_old]) #[1, 48, 186, 250, 337]\n",
    "print(\"old broken tasks: \", [item for item in score_old if item not in score_new])\n",
    "# TODO tasks solved with filter_programs: 66,..\n",
    "# TODO tasks solved at some point: 48, 52, 128, 258, 345, 371...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}\n",
      "[[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [2, 0], [2, 1], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 9], [3, 10], [3, 11], [3, 12], [3, 13], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 13], [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 5], [6, 6], [6, 7], [6, 8], [6, 9], [6, 10], [6, 11], [6, 12], [6, 13], [7, 0], [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 7], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [8, 0], [8, 1], [8, 2], [8, 3], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 9], [8, 10], [8, 11], [8, 12], [8, 13], [9, 0], [9, 1], [9, 2], [9, 3], [9, 4], [9, 5], [9, 6], [9, 7], [9, 8], [9, 9], [9, 10], [9, 11], [9, 12], [9, 13], [10, 0], [10, 1], [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9], [10, 10], [10, 11], [10, 12], [10, 13], [11, 0], [11, 1], [11, 2], [11, 3], [11, 4], [11, 5], [11, 6], [11, 7], [11, 8], [11, 9], [11, 10], [11, 11], [11, 12], [11, 13], [12, 0], [12, 1], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 7], [12, 8], [12, 9], [12, 10], [12, 11], [12, 12], [12, 13], [13, 0], [13, 1], [13, 2], [13, 3], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 9], [13, 10], [13, 11], [13, 12], [13, 13]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = detect_lines(task_data.train_tensors[0][0].grid)\n",
    "#lines = detect_lines(task_data.test_tensors[0][0].grid)\n",
    "print(lines)\n",
    "#print(count_lines_regions(lines))\n",
    "regions = detect_regions(task_data.train_tensors[0][0].grid, lines)\n",
    "print(regions)\n",
    "len(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_task(train_task_data[99]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superpose all the objects with an operation given by op\n",
    "def superp_ob(a, a_t, task_data,*args, key=None, op=\"AND\"):\n",
    "    \n",
    "    b = black_square\n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    for previous, current in zip(a_t.objects, a_t.objects[1:]):\n",
    "        if not (key is None):\n",
    "            pass\n",
    "        else:\n",
    "            if op==\"AND\":\n",
    "                b = np.where((previous.grid !=background_color) & (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"OR\":\n",
    "                b = np.where((previous.grid !=background_color) | (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"XOR\":\n",
    "                b = np.where((previous.grid !=background_color) ^ (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"ADD\":\n",
    "                b =  np.where((previous.grid + current.grid) < 10, previous.grid + current.grid, background_color)\n",
    "    return b\n",
    "\n",
    "\n",
    "def superp_ob_1(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"ADD\")\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "# need to detect fixed objects amomng all frames\n",
    "\n",
    "def detect_objs_movements(objects):\n",
    "    \n",
    "    ob_mvs = {}\n",
    "    for ob in objects:\n",
    "        \n",
    "def move_ob(a, a_t, task_data,*args):\n",
    "    \n",
    "    a_t.objects\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
