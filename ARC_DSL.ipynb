{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as colors_mat\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from itertools import product\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.signal import convolve2d\n",
    "from collections import Counter\n",
    "\n",
    "DEBUG = True # Active logging, printing, etc. False when committing to the LB.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Initial Data ...\n",
      "--- 0.026468992233276367 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Initial Data ...\")\n",
    "\n",
    "data_path = Path('')\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "testing_path = data_path / 'test'\n",
    "\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "evaluation_tasks = sorted(os.listdir(evaluation_path))\n",
    "testing_tasks = sorted(os.listdir(testing_path))\n",
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Functions ...\n",
      "--- 0.0010380744934082031 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Functions ...\")\n",
    "\n",
    "def flattener(pred):\n",
    "    \n",
    "    str_pred = str([row for row in pred.tolist()])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    \n",
    "    return str_pred\n",
    "\n",
    "def build_trainlist(task):\n",
    "    \n",
    "    task_data = []\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "        list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "    \n",
    "    return task_data\n",
    "\n",
    "def build_testlist(task):\n",
    "    \n",
    "    task_data = []\n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in = np.array(t[\"input\"]).astype('uint8')       \n",
    "        list.append(task_data, (t_in.copy()))\n",
    "    \n",
    "    return task_data\n",
    "\n",
    "def load_data(p, phase=None):\n",
    "    \n",
    "    if phase in {'training', 'test', 'evaluation'}:\n",
    "        p = data_path / phase / p\n",
    "    \n",
    "    task = json.loads(Path(p).read_text())\n",
    "    dict_vals_to_np = lambda x: { k : np.array(v) for k, v in x.items() }\n",
    "    assert set(task) == {'test', 'train'}\n",
    "    res = dict(test=[], train=[])\n",
    "    \n",
    "    for t in task['train']:\n",
    "        assert set(t) == {'input', 'output'}\n",
    "        res['train'].append(dict_vals_to_np(t))\n",
    "    for t in task['test']:\n",
    "        res['test'].append(dict_vals_to_np(t))\n",
    "        \n",
    "    return res\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Files ...\n",
      "--- 0.8137290477752686 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Files ...\")\n",
    "\n",
    "train_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(training_tasks[i], phase='training')\n",
    "    list.append(train_task_data, task)\n",
    "\n",
    "eval_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(evaluation_tasks[i], phase='evaluation')\n",
    "    list.append(eval_task_data, task)\n",
    "\n",
    "test_task_data = []\n",
    "for i in range(0, 100):\n",
    "    task = load_data(testing_tasks[i], phase='test')\n",
    "    list.append(test_task_data, task)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checking Functions\n",
      "--- 0.0016219615936279297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Checking Functions\")\n",
    "\n",
    "cmap = colors_mat.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors_mat.Normalize(vmin=0, vmax=9)\n",
    "num2color = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\n",
    "color2num = {c: n for n, c in enumerate(num2color)}\n",
    "\n",
    "def plot_one(task, ax, i,train_or_test,input_or_output):\n",
    "    \n",
    "    input_matrix = task[train_or_test][i][input_or_output]\n",
    "    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
    "    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
    "    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(train_or_test + ' '+ input_or_output)\n",
    "    \n",
    "def plot_task(task):\n",
    "\n",
    "    num_train = len(task['train'])\n",
    "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
    "    for i in range(num_train):     \n",
    "        plot_one(task, axs[0,i],i,'train','input')\n",
    "        plot_one(task, axs[1,i],i,'train','output')        \n",
    "    plt.tight_layout()\n",
    "    plt.show()        \n",
    "        \n",
    "    num_test = len(task['test'])\n",
    "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
    "    if num_test==1: \n",
    "        plot_one(task, axs[0],0,'test','input')\n",
    "        plot_one(task, axs[1],0,'test','output')     \n",
    "    else:\n",
    "        for i in range(num_test):      \n",
    "            plot_one(task, axs[0,i],i,'test','input')\n",
    "            plot_one(task, axs[1,i],i,'test','output')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def check_p(task, pred_func):\n",
    "    \n",
    "    fig_num = 0\n",
    "    n = len(task[\"train\"]) + len(task[\"test\"])\n",
    "    fig, axs = plt.subplots(3, n, figsize=(4*n,12), dpi=50)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    # All Data for Task\n",
    "    train_data = build_trainlist(task)\n",
    "    test_data = build_testlist(task)\n",
    "    task_data = Task(train_data, test_data)\n",
    "    \n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')   \n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Train-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Train-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Train-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "        \n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')\n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Test-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Test-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Test-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Main)\n",
      "--- 0.0009763240814208984 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Main)\")\n",
    "\n",
    "def get_neighbors(grid, i, j):\n",
    "    \n",
    "    nbh = lambda x, i, j: { \n",
    "        (ip, jp) : x[i+ip, j+jp] \n",
    "            for ip, jp in product([1, -1, 0], repeat=2) \n",
    "                if 0 <= i+ip < x.shape[0] and 0 <= j+jp < x.shape[1]\n",
    "    }\n",
    "        \n",
    "    nbh_data = nbh(grid, i, j)\n",
    "    nbh_values = [(1, 1), (1, -1), (1, 0), (-1, 1), (-1, -1), \n",
    "                  (-1, 0), (0, 1), (0, -1), (0, 0)]\n",
    "\n",
    "    for val in nbh_values:\n",
    "        if val not in nbh_data:\n",
    "            nbh_data[val] = 0\n",
    "    \n",
    "    return nbh_data\n",
    "\n",
    "def get_background_color(grid):\n",
    "    \n",
    "    try:    \n",
    "        background_color = 0\n",
    "        cnt = np.bincount(grid.flatten())[1:]\n",
    "        bg_color = [i + 1 for i, x in enumerate(cnt) if x == max(cnt)][0]\n",
    "        if np.nonzero(cnt)[0].shape[0] >= 2:\n",
    "            if max(cnt) >= (grid.shape[0] * grid.shape[1] * 0.25):\n",
    "                background_color = bg_color\n",
    "        return background_color    \n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "# return a list with all the colors available in grid\n",
    "def get_unique_colors(grid):\n",
    "        return np.unique(grid).tolist()\n",
    "    \n",
    "# Return a dictionary color:percentage, for instance: {0: 0.666,1: 0.333, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}\n",
    "def color_percentage(grid):\n",
    "    \n",
    "    n_elements = grid.shape[0] * grid.shape[1]\n",
    "    if ( n_elements <= 0):\n",
    "        raise ValueError(\"n_elements <= 0\")\n",
    "    unique, counts = np.unique(grid, return_counts=True)\n",
    "    if not (all(j < 10 for j in unique)):\n",
    "        raise ValueError(\"Uknown color! \", j)\n",
    "        \n",
    "    percentages =  dict(zip(unique, counts))\n",
    "    for color in range(0,10):\n",
    "        if color not in percentages.keys():\n",
    "            percentages[color] = 0.0\n",
    "    percentages.update((x, y*1.0/n_elements) for x, y in percentages.items())\n",
    "\n",
    "    return percentages\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Detection)\n",
      "--- 0.0027849674224853516 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Detection)\")\n",
    "       \n",
    "# Ensure No Duplicate Objects\n",
    "def search_array(arr, arr_data):\n",
    "    return next((True for elem in arr_data if np.array_equal(elem, arr)), False)\n",
    "\n",
    "# Separate Objects by Distance\n",
    "def object_detection_1(grid):\n",
    "    \n",
    "    # List of Objects\n",
    "    object_list = []\n",
    "    grid_copy = grid.copy()\n",
    "    struct = generate_binary_structure(2, 2)\n",
    "    labels, num_labels = label((grid_copy != 0), structure=struct)\n",
    "\n",
    "    # Find Objects\n",
    "    for i in range(0, num_labels):\n",
    "        idx = np.column_stack(np.where(labels == i + 1))\n",
    "        x_min = min([point[0] for point in idx])\n",
    "        y_min = min([point[1] for point in idx])\n",
    "        x_max = max([point[0] for point in idx])\n",
    "        y_max = max([point[1] for point in idx])\n",
    "\n",
    "        object_data = {}\n",
    "        object_data['coords'] = idx\n",
    "        object_data['obj'] = grid_copy[x_min: x_max + 1, y_min: y_max + 1]\n",
    "        list.append(object_list, object_data)\n",
    "\n",
    "    return object_list\n",
    "        \n",
    "# Separate Objects by Color/Distance\n",
    "def object_detection_2(grid):\n",
    "    \n",
    "    # List of Objects\n",
    "    object_list = []\n",
    "    grid_copy = grid.copy()\n",
    "    struct = generate_binary_structure(2, 2)\n",
    "    \n",
    "    # Ensure Colors != Background\n",
    "    grid_colors = np.unique(grid_copy)\n",
    "    bg_color = get_background_color(grid_copy)\n",
    "    grid_colors = [col for col in grid_colors if col not in [0, bg_color]]\n",
    "\n",
    "    # Find Objects\n",
    "    for color in grid_colors:\n",
    "        labels, num_labels = label((grid_copy == color), structure=struct)\n",
    "        for i in range(0, num_labels):\n",
    "            idx = np.column_stack(np.where(labels == i + 1))\n",
    "            x_min = min([point[0] for point in idx])\n",
    "            y_min = min([point[1] for point in idx])\n",
    "            x_max = max([point[0] for point in idx])\n",
    "            y_max = max([point[1] for point in idx])\n",
    "\n",
    "            object_data = {}\n",
    "            object_data['coords'] = idx\n",
    "            object_data['obj'] = grid_copy[x_min: x_max + 1, y_min: y_max + 1]\n",
    "            list.append(object_list, object_data)\n",
    "        \n",
    "    return object_list\n",
    "\n",
    "# Separate Layers in grid\n",
    "def layer_detection(grid):\n",
    "    \n",
    "    # List of Layers\n",
    "    layer_list = []\n",
    "    grid_copy = grid.copy()\n",
    "    grid_colors = np.unique(grid_copy)\n",
    "\n",
    "    # Find Layers by Color\n",
    "    for color in grid_colors:\n",
    "        layer_copy = grid_copy.copy()\n",
    "        layer_copy[layer_copy != color] = 0\n",
    "        \n",
    "        idx = []\n",
    "        for i in range(0, grid_copy.shape[0]):\n",
    "            for j in range(0, grid_copy.shape[1]):\n",
    "                list.append(idx, [i, j])\n",
    "\n",
    "        layer_data = {}\n",
    "        layer_data['coords'] = np.array(idx)\n",
    "        layer_data['obj'] = layer_copy\n",
    "        list.append(layer_list, layer_data)\n",
    "        \n",
    "    return layer_list\n",
    "      \n",
    "# Separate Regions in grid\n",
    "def region_detection(grid):\n",
    "    \n",
    "    # List of Regions\n",
    "    region_list = []\n",
    "    grid_copy = grid.copy()\n",
    "\n",
    "    # Ensure Colors != Background\n",
    "    grid_colors = np.unique(grid_copy)\n",
    "    bg_color = get_background_color(grid_copy)\n",
    "    grid_colors = [col for col in grid_colors if col not in [0, bg_color]]\n",
    "    \n",
    "    # Find Regions by Looking for Horizontal/Vertical Lines\n",
    "    # Typically, there won't be any overlap between region lines/object colors\n",
    "    for color in grid_colors:\n",
    "        \n",
    "        # Declare Splits\n",
    "        vertical_splits = None\n",
    "        horizontal_splits = None\n",
    "\n",
    "        # Vertical Regions\n",
    "        vertical_partition = np.zeros((grid_copy.shape[0], 1))       \n",
    "        vertical_partition[:, 0] = color\n",
    "        vertical_result = cv2.matchTemplate(\n",
    "            grid_copy.astype(np.uint8), vertical_partition.astype(np.uint8), cv2.TM_SQDIFF)\n",
    "        vertical_positions = np.argwhere(vertical_result < 0.001)\n",
    "\n",
    "        # Horizontal Regions\n",
    "        horizontal_partition = np.zeros((1, grid_copy.shape[1]))       \n",
    "        horizontal_partition[0, :] = color\n",
    "        horizontal_result = cv2.matchTemplate(\n",
    "            grid_copy.astype(np.uint8), horizontal_partition.astype(np.uint8), cv2.TM_SQDIFF)\n",
    "        horizontal_positions = np.argwhere(horizontal_result < 0.001)\n",
    "                \n",
    "        # Check if Horizontal/Vertical Partitions Exist\n",
    "        if (len(vertical_positions) >= 1) or (len(horizontal_positions) >= 1):\n",
    "            \n",
    "            # Combine Vertical/Horizontal Regions\n",
    "            vertical_splits = [-1] + [x[1] for x in vertical_positions]\n",
    "            horizontal_splits = [-1] + [x[0] for x in horizontal_positions]\n",
    "            \n",
    "            # Get Vertical Split Ranges\n",
    "            for i, v_split in enumerate(vertical_splits):\n",
    "                end_split_i = None\n",
    "                start_split_i = vertical_splits[i]\n",
    "                if i + 1 == len(vertical_splits):\n",
    "                    end_split_i = grid_copy.shape[1]\n",
    "                else:\n",
    "                    end_split_i = vertical_splits[i + 1]\n",
    "\n",
    "                # Get Horizontal Split Ranges\n",
    "                for j, h_split in enumerate(horizontal_splits): \n",
    "                    end_split_j = None\n",
    "                    start_split_j = horizontal_splits[j]\n",
    "                                        \n",
    "                    if j + 1 == len(horizontal_splits):\n",
    "                        end_split_j = grid_copy.shape[0]\n",
    "                    else:\n",
    "                        end_split_j = horizontal_splits[j + 1]\n",
    "                    \n",
    "                    idx = []\n",
    "                    for i in range(start_split_i + 1, end_split_i):\n",
    "                        for j in range(start_split_j + 1, end_split_j):\n",
    "                            list.append(idx, [i, j])\n",
    "\n",
    "                    region_data = {}\n",
    "                    region_data['coords'] = np.array(idx)\n",
    "                    region_data['obj'] = grid_copy[start_split_j + 1: end_split_j, start_split_i + 1: end_split_i]\n",
    "                    list.append(region_list, region_data)\n",
    "\n",
    "    return region_list\n",
    "         \n",
    "# Separate Object in grid\n",
    "def object_detection(grid):\n",
    "    \n",
    "    # List of Objects\n",
    "    combined_objects = []\n",
    "    \n",
    "    # Run Object Detection (1)\n",
    "    obj1 = object_detection_1(grid)    \n",
    "    for object_ in obj1:\n",
    "        current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "        if not search_array(object_[\"obj\"], current_objects):\n",
    "            combined_objects.append(object_)\n",
    "\n",
    "    # Run Object Detection (2)\n",
    "    obj2 = object_detection_2(grid)\n",
    "    for object_ in obj2:\n",
    "        current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "        if not search_array(object_[\"obj\"], current_objects):\n",
    "            combined_objects.append(object_)\n",
    "\n",
    "    # Calculate Layers/Regions\n",
    "    layers = layer_detection(grid)\n",
    "    regions = region_detection(grid)\n",
    "\n",
    "    # Check Layers for Unique Objects\n",
    "    for layer in layers:\n",
    "        \n",
    "        # Run Object Detection (3)\n",
    "        obj1 = object_detection_1(layer[\"obj\"])\n",
    "        for object_ in obj1:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "        # Run Object Detection (4)\n",
    "        obj2 = object_detection_2(layer[\"obj\"])\n",
    "        for object_ in obj2:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "    # Check Regions for Unique Objects\n",
    "    for region in regions:\n",
    "        \n",
    "        # Run Object Detection (3)\n",
    "        obj1 = object_detection_1(region[\"obj\"])                \n",
    "        for object_ in obj1:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "        # Run Object Detection (4)\n",
    "        obj2 = object_detection_2(region[\"obj\"])\n",
    "        for object_ in obj2:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "    return combined_objects\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Entity)\n",
      "--- 0.002089977264404297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Entity)\")\n",
    "\n",
    "# Fundamental Entity (Tensors, Objects, etc). \n",
    "# Contains all Basic Methods acting on Task Samples.\n",
    "class Entity():\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        self.grid = grid\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        self.attributes = {}\n",
    "        self.attributes[\"unique_colors\"] = get_unique_colors(self.grid)\n",
    "        self.attributes[\"grid_colors_perc\"] = color_percentage(self.grid)\n",
    "        self.attributes[\"grid_shape\"] = self.grid.shape\n",
    "        \n",
    "# Extends Entity Class\n",
    "# Contains Data for Sections of grid\n",
    "class Section(Entity):\n",
    "    \n",
    "    def __init__(self, section_data):\n",
    "        super().__init__(section_data[\"obj\"])\n",
    "        self.coords = section_data[\"coords\"]\n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "\n",
    "# Extends Entity Class\n",
    "# Contains Entire Data for Input/Output\n",
    "class Tensor(Entity):\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        super().__init__(grid)\n",
    "        self.objects = []\n",
    "        self.layers = []\n",
    "        self.regions = []\n",
    "        \n",
    "    def compute_features(self):\n",
    "        object_data = object_detection(self.grid)\n",
    "        layer_data = layer_detection(self.grid)\n",
    "        region_data = region_detection(self.grid)\n",
    "    \n",
    "        for object_ in object_data:\n",
    "            section = Section(object_)\n",
    "            section.compute_attributes()\n",
    "            list.append(self.objects, section)\n",
    "        for layer_ in layer_data:\n",
    "            section = Section(layer_)\n",
    "            section.compute_attributes()\n",
    "            list.append(self.layers, section)\n",
    "        for region_ in region_data:\n",
    "            section = Section(region_)\n",
    "            section.compute_attributes()\n",
    "            list.append(self.regions, section)\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()           \n",
    "\n",
    "# Fundamental Class for ALL Tasks\n",
    "# Contains all Basic Methods acting on Tasks.\n",
    "class Task():\n",
    "    \n",
    "    def __init__(self, train_data, test_data):\n",
    "        \n",
    "        # Lists of Train/Test Tensors\n",
    "        self.train_tensors = []\n",
    "        self.train_diff = []\n",
    "        self.common_diff = {}\n",
    "        self.test_tensors = []\n",
    "        \n",
    "        # Compute Train/Test Tensors\n",
    "        for t_in, t_out in train_data:\n",
    "            tensor_in = Tensor(t_in)\n",
    "            tensor_out = Tensor(t_out)\n",
    "            list.append(self.train_tensors, [tensor_in, tensor_out])\n",
    "        for t_in in test_data:\n",
    "            tensor_in = Tensor(t_in)\n",
    "            list.append(self.test_tensors, [tensor_in])\n",
    "        \n",
    "           \n",
    "    # Compute Task Train Attributes \n",
    "    def compute_train_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            for t in in_out_pair:\n",
    "                t.compute_attributes()\n",
    "    \n",
    "    # Compute Task Test Attributes \n",
    "    def compute_test_attributes(self):\n",
    "        for t in self.test_tensors:\n",
    "            t[0].compute_attributes()\n",
    "    \n",
    "    # Compute Attribute Differences for every in-out pair\n",
    "    def compute_diff_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            diff = {}\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            #print(t_in.attributes)\n",
    "            #print(t_in.attributes[\"grid_colors_perc\"])\n",
    "            #print(t_out.attributes[\"grid_colors_perc\"])\n",
    "            \n",
    "            diff[\"color_changed\"] = set(t_in.attributes[\"unique_colors\"]) != set(t_out.attributes[\"unique_colors\"])\n",
    "            \n",
    "            keylist = t_in.attributes[\"grid_colors_perc\"].keys()\n",
    "            color_perc_in = np.array([t_in.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            color_perc_out = np.array([t_out.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            diff[\"color_perc_changed\"] = not np.allclose(color_perc_in, color_perc_out)\n",
    "            \n",
    "            diff[\"shape_changed\"] = t_in.attributes[\"grid_shape\"] != t_out.attributes[\"grid_shape\"]\n",
    "    \n",
    "            list.append(self.train_diff,diff)\n",
    "        \n",
    "    # Find Common Differences in Input/Output Pairs. Return a dict \"diff\":int, such as {'color_changed': -1, 'color_perc_changed': 1, 'shape_changed': 1}.\n",
    "    def find_common_diff(self):\n",
    "        \n",
    "        \n",
    "        diffs = self.train_diff[0].keys()\n",
    "        print(\"diffs\", diffs)\n",
    "        \n",
    "        for k in diffs:\n",
    "            val = self.train_diff[0][k] # use first value as reference\n",
    "            for i, diff in enumerate(self.train_diff): \n",
    "                val = val and diff[k]\n",
    "        \n",
    "            if (val and (self.train_diff[0][k])): \n",
    "                self.common_diff[k] = 1 # this difference k is common in all the in-out pairs and is is True.\n",
    "            elif val:\n",
    "                self.common_diff[k] = 0 # the difference is not common to all the in-out pairs.\n",
    "            else:\n",
    "                self.common_diff[k] = -1 # this difference k is common in all the in-out pairs and is is False.\n",
    "                \n",
    "        \n",
    "    # Find Sequences in Common Differences\n",
    "    def find_sequence(self, train_attr):\n",
    "        pass\n",
    "                               \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Rotates) ...\n",
      "--- 0.001428842544555664 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Rotates) ...\")\n",
    "\n",
    "# Rotate Image 90 Degrees\n",
    "def rotate_1(a):\n",
    "    return np.rot90(a, 1, axes=(0,1))\n",
    "\n",
    "# Rotate Image 180 Degrees\n",
    "def rotate_2(a):\n",
    "    return np.rot90(a, 2, axes=(0,1))\n",
    "\n",
    "# Rotate Image 270 Degrees\n",
    "def rotate_3(a):\n",
    "    return np.rot90(a, 3, axes=(0,1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Flips) ...\n",
      "--- 0.0005278587341308594 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Flips) ...\")\n",
    "\n",
    "# Flip Image Along X-Axis\n",
    "def flip_1(a):\n",
    "    return np.flip(a, 0)\n",
    "\n",
    "# Flip Image Along Y-Axis\n",
    "def flip_2(a):\n",
    "    return np.flip(a, 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine DSL Functions ...\n",
      "DSL_fs_names  ['rotate_1', 'rotate_2', 'rotate_3', 'flip_1', 'flip_2']\n",
      "--- 0.0008330345153808594 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Combine DSL Functions ...\")\n",
    "\n",
    "rotate = [rotate_1, rotate_2, rotate_3\n",
    "         ]\n",
    "flip = [flip_1, flip_2\n",
    "       ]\n",
    "#color = [color_1]\n",
    "\n",
    "DSL_functions = rotate + flip\n",
    "DSL_fs_names = [f.__name__ for f in DSL_functions]\n",
    "print(\"DSL_fs_names \", DSL_fs_names)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Actions ...\n",
      "--- 0.0005600452423095703 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Actions ...\")\n",
    "\n",
    "# [\"color_changed\":bool, \"color_perc_changed\":bool, \"shape_changed\":bool, ...]\n",
    "# Return the action is defined by the dict above.\n",
    "def get_functions_actions(entity):\n",
    "    \n",
    "    shape = entity.attributes[\"grid_shape\"]\n",
    "    is_a_square =  shape[0] == shape[1]\n",
    "    \n",
    "    functions_actions = {\n",
    "    \"rotate_1\":[False,False,not is_a_square], \n",
    "    \"rotate_2\":[False,False,not is_a_square],\n",
    "    \"rotate_3\":[False,False,not is_a_square], \n",
    "    \"flip_1\":[False,False,False],\n",
    "    \"flip_2\":[False,False,False]\n",
    "                    }\n",
    "    return functions_actions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Filtering ...\n",
      "--- 0.0008738040924072266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Filtering ...\")\n",
    "\n",
    "# Filter the functions which will enter the generate loops. Run over all the test_in and take only the functions that are compatible with all the test_in.\n",
    "def function_filter(task, fs_names):\n",
    "\n",
    "    test_t_ins = task.test_tensors\n",
    "    functions_to_select = fs_names\n",
    "    \n",
    "    for t_in in test_t_ins:\n",
    "        \n",
    "        functions_actions = get_functions_actions(t_in[0])\n",
    "\n",
    "        diff = task.common_diff\n",
    "        print(diff)\n",
    "        \n",
    "\n",
    "        # remove the functions (from the list of all function) which make undesired changes. \n",
    "        for f,v in functions_actions.items():\n",
    "\n",
    "            if not diff[\"color_changed\"]==1: # if the task is preserving the color, remove function which modify colors.\n",
    "                if v[0]: # check if the function modifies colors\n",
    "                    if f in functions_to_select:\n",
    "                        functions_to_select.remove(f)\n",
    "\n",
    "            if not diff[\"shape_changed\"]==1:\n",
    "                if v[2]:\n",
    "                    if f in functions_to_select:\n",
    "                        functions_to_select.remove(f)\n",
    "                \n",
    "    return functions_to_select\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program():\n",
    "    \n",
    "    def __init__(self, functions = [], sim_score = 0, acting_on=\"Tensor\"):\n",
    "        self.functions = functions # list of functions. The program is the composition of those.\n",
    "        self.sim_score = sim_score # How well the program scores on the expected output.\n",
    "        self.acting_on = acting_on # Is this acting on a Tensor, an Object, a Layer?\n",
    "        self.task_accuracy = 0  # +1 for every time program maps t_in in t_out\n",
    "        self.magic_numbers = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Programs...\n",
      "--- 0.0010192394256591797 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Programs...\")\n",
    "\n",
    "def pred_wrapper(grid,func):\n",
    "    grid_copy = grid.copy()\n",
    "    if DEBUG:\n",
    "        return func(grid_copy)\n",
    "    else:\n",
    "        try:\n",
    "            return func(grid_copy)\n",
    "        except:\n",
    "            return grid\n",
    "        \n",
    "def get_sim_score(pred, reference):\n",
    "    return 1\n",
    "\n",
    "# generate a candidate program\n",
    "def generate_programs(task_data):\n",
    "    \n",
    "    n_train_pairs = len(task_data.train_tensors)\n",
    "    max_solution_length = 2\n",
    "    \n",
    "    # compute attributes\n",
    "    task_data.compute_train_attributes()\n",
    "    task_data.compute_test_attributes()\n",
    "    task_data.compute_diff_attributes()\n",
    "    task_data.find_common_diff()\n",
    "    \n",
    "    # candidate functions which when combined could deliver the correct solution program.\n",
    "    pred_functions = function_filter(task_data, DSL_functions)  \n",
    "    \n",
    "    for in_out_pair in task_data.train_tensors:\n",
    "        t_in = in_out_pair[0]\n",
    "        t_out = in_out_pair[1]\n",
    "        \n",
    "        pred_similarities = []\n",
    "        for pred_func in pred_functions:\n",
    "            \n",
    "            # evaluate all the pred_functions on the t_in Tensor and keep track of their score\n",
    "            pred_generate = pred_wrapper(t_in.grid, pred_func)\n",
    "            sim_score = get_sim_score(pred_generate, t_out)\n",
    "            list.append(pred_similarities,Program([pred_func],sim_score,\"Tensor\"))\n",
    "            \n",
    "            # TODO, do the same on Sections\n",
    "        \n",
    "        # keep the first n best scoring programs \n",
    "        n = len(pred_similarities)  \n",
    "        pred_similarities = sorted(pred_similarities, key=lambda x: x.sim_score, reverse=True)[:n]\n",
    "        trained_similarities = []\n",
    "        \n",
    "        \n",
    "        prediction_flags = [True] * len(pred_similarities) # flag if keep searching to update the function. \n",
    "        \n",
    "        # print(\"Seek Better Solution...\")\n",
    "        for j, program in enumerate(pred_similarities):\n",
    "            \n",
    "            current_prog = [program]\n",
    "            # If False, No Better program, store the program as it is now.\n",
    "            while prediction_flags[j] == True:\n",
    "                        \n",
    "                current_pred_func = None\n",
    "                new_current_prog = []\n",
    "                updated_flag = [False] * len(current_prog) # flag if the functions are being updated\n",
    "                \n",
    "                for k, prog in enumerate(current_prog):\n",
    "                    \n",
    "                                           \n",
    "                    # if the chains of functions is longer than allowed, add it to the functions to select\n",
    "                    if (len(prog.functions) >= max_solution_length):\n",
    "                        list.append(trained_similarities, prog)\n",
    "                        continue \n",
    "                        \n",
    "                    pred_generate = t_in.grid \n",
    "                    for pred_func in prog.functions:  \n",
    "                        pred_generate = pred_wrapper(pred_generate.copy(), pred_func) # function composition\n",
    "                    task_sim_score = get_sim_score(pred_generate.copy(), t_out.grid)\n",
    "                    current_pred_func = prog.functions\n",
    "                    \n",
    "                                    \n",
    "                    look_for_updates = True  # Just put False if debugging\n",
    "                    if look_for_updates:\n",
    "                        updated_similarities = []\n",
    "\n",
    "                        # Iterate over all the functions to generate a new composite function\n",
    "                        for pred_func in pred_functions:\n",
    "                            pred_func_generate = pred_wrapper(pred_generate.copy(), pred_func)\n",
    "                            task_sim_score = get_sim_score(pred_func_generate, t_out)\n",
    "                            list.append(updated_similarities,Program([pred_func],task_sim_score,\"Tensor\"))\n",
    "\n",
    "                        \n",
    "                        # check if the new composite function scores better than the current_pred_func\n",
    "                        for p in updated_similarities:\n",
    "                            improvement_threshold = -0.1 # DEBUG Normally this should be positive! (assuming max(score)= 1)\n",
    "                            if (p.sim_score > prog.sim_score + improvement_threshold): \n",
    "                                # the function have been improved! Now it will over the whole process again, to see if it can be improved further.\n",
    "                                \n",
    "                                new_current_prog.append(Program(current_pred_func + p.functions ,p.sim_score,\"Tensor\")) \n",
    "                                if not updated_flag[k]:\n",
    "                                    updated_flag[k] = True     # at least one new function has been generated\n",
    "                            else:\n",
    "                                pass\n",
    "                  \n",
    "                    # the functions cannot be improved further (at least not with 1 step), add it to the functions to select\n",
    "                    if not updated_flag[k]: # no updates\n",
    "                        list.append(trained_similarities, prog)\n",
    "                \n",
    "                \n",
    "                #print(\"current_prog loop end\")\n",
    "                #print(\"...\")\n",
    "                current_prog = new_current_prog\n",
    "                \n",
    "                if len(current_prog)==0:\n",
    "                    prediction_flags[j] = False \n",
    "            #print(\"End prediction_flags[j] == True while loop\")\n",
    "            #print(\"-----------\")\n",
    "          \n",
    "        #print(\"End pred_similarities for loop\")\n",
    "        #print(\"-----------\")       \n",
    "        #print(\"trained_similarities\",[x.functions for x in trained_similarities])\n",
    "            \n",
    "        return trained_similarities\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Program ...\n",
      "--- 0.0006909370422363281 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Select Program ...\")\n",
    "\n",
    "def select_programs(task_data, generated_programs):\n",
    "    \n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(generated_programs):\n",
    "        program.task_accuracy = 0\n",
    "    \n",
    "        # Iterate Through Train Tasks\n",
    "        for in_out_pair in task_data.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "        \n",
    "            pred_generate = t_in.grid\n",
    "            for pred_func in program.functions:\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), pred_func)\n",
    "                   \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid):\n",
    "                program.task_accuracy += 1\n",
    "            \n",
    "\n",
    "    print(\"best_programs\", [(x.functions,x.task_accuracy) for x in generated_programs])\n",
    "    # Select Best 3 Solutions\n",
    "    best_programs = sorted(generated_programs, key=lambda x: x.task_accuracy, reverse=True)[:3]\n",
    "    print(\"best_programs filtered\", [(x.functions,x.task_accuracy) for x in best_programs]) \n",
    "    return best_programs\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Manual) ...\n",
      "--- 0.22283601760864258 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Manual) ...\")\n",
    "\n",
    "def combine_tasks(a):\n",
    "    b = a.copy()\n",
    "    #print(b)\n",
    "    b = rotate_1(b)\n",
    "    b = flip_1(b)\n",
    "    return b\n",
    "\n",
    "tasks_indices = [178]\n",
    "for task in tasks_indices:\n",
    "    check_p(train_task_data[task], combine_tasks)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_n = 178\n",
    "train_data = build_trainlist(train_task_data[task_n])\n",
    "test_data = build_testlist(train_task_data[task_n])\n",
    "task_data = Task(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffs dict_keys(['color_changed', 'color_perc_changed', 'shape_changed'])\n",
      "{'color_changed': -1, 'color_perc_changed': -1, 'shape_changed': -1}\n"
     ]
    }
   ],
   "source": [
    "gen = generate_programs(task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_programs [([<function rotate_1 at 0x11f4ddf80>, <function rotate_1 at 0x11f4ddf80>], 0), ([<function rotate_1 at 0x11f4ddf80>, <function rotate_2 at 0x11f5250e0>], 0), ([<function rotate_1 at 0x11f4ddf80>, <function rotate_3 at 0x11f525200>], 0), ([<function rotate_1 at 0x11f4ddf80>, <function flip_1 at 0x11f525170>], 4), ([<function rotate_1 at 0x11f4ddf80>, <function flip_2 at 0x11f525440>], 0), ([<function rotate_2 at 0x11f5250e0>, <function rotate_1 at 0x11f4ddf80>], 0), ([<function rotate_2 at 0x11f5250e0>, <function rotate_2 at 0x11f5250e0>], 0), ([<function rotate_2 at 0x11f5250e0>, <function rotate_3 at 0x11f525200>], 0), ([<function rotate_2 at 0x11f5250e0>, <function flip_1 at 0x11f525170>], 0), ([<function rotate_2 at 0x11f5250e0>, <function flip_2 at 0x11f525440>], 0), ([<function rotate_3 at 0x11f525200>, <function rotate_1 at 0x11f4ddf80>], 0), ([<function rotate_3 at 0x11f525200>, <function rotate_2 at 0x11f5250e0>], 0), ([<function rotate_3 at 0x11f525200>, <function rotate_3 at 0x11f525200>], 0), ([<function rotate_3 at 0x11f525200>, <function flip_1 at 0x11f525170>], 0), ([<function rotate_3 at 0x11f525200>, <function flip_2 at 0x11f525440>], 4), ([<function flip_1 at 0x11f525170>, <function rotate_1 at 0x11f4ddf80>], 0), ([<function flip_1 at 0x11f525170>, <function rotate_2 at 0x11f5250e0>], 0), ([<function flip_1 at 0x11f525170>, <function rotate_3 at 0x11f525200>], 4), ([<function flip_1 at 0x11f525170>, <function flip_1 at 0x11f525170>], 0), ([<function flip_1 at 0x11f525170>, <function flip_2 at 0x11f525440>], 0), ([<function flip_2 at 0x11f525440>, <function rotate_1 at 0x11f4ddf80>], 4), ([<function flip_2 at 0x11f525440>, <function rotate_2 at 0x11f5250e0>], 0), ([<function flip_2 at 0x11f525440>, <function rotate_3 at 0x11f525200>], 0), ([<function flip_2 at 0x11f525440>, <function flip_1 at 0x11f525170>], 0), ([<function flip_2 at 0x11f525440>, <function flip_2 at 0x11f525440>], 0)]\n",
      "best_programs filtered [([<function rotate_1 at 0x11f4ddf80>, <function flip_1 at 0x11f525170>], 4), ([<function rotate_3 at 0x11f525200>, <function flip_2 at 0x11f525440>], 4), ([<function flip_1 at 0x11f525170>, <function rotate_3 at 0x11f525200>], 4)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.Program at 0x11fc27c50>,\n",
       " <__main__.Program at 0x11fc6a150>,\n",
       " <__main__.Program at 0x11fc6a210>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_programs(task_data, gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
