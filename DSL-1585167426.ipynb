{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport sys\nimport time\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nimport itertools\nimport scipy\nimport gc\nimport copy\n\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors as colors_mat\nfrom scipy.ndimage import label, generate_binary_structure\nfrom numpy.lib.stride_tricks import as_strided\nfrom itertools import product\nfrom skimage import measure\nfrom scipy.spatial.distance import cdist\nfrom scipy.signal import convolve2d\nfrom collections import Counter\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input\n/kaggle/input/abstraction-and-reasoning-challenge\n/kaggle/input/abstraction-and-reasoning-challenge/evaluation\n/kaggle/input/abstraction-and-reasoning-challenge/test\n/kaggle/input/abstraction-and-reasoning-challenge/training\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load Initial Data ...\")\n\ndata_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\ntraining_path = data_path / 'training'\nevaluation_path = data_path / 'evaluation'\ntesting_path = data_path / 'test'\n\ntraining_tasks = sorted(os.listdir(training_path))\nevaluation_tasks = sorted(os.listdir(evaluation_path))\ntesting_tasks = sorted(os.listdir(testing_path))\nsubmission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":2,"outputs":[{"output_type":"stream","text":"Load Initial Data ...\n--- 0.0291292667388916 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load Data Functions ...\")\n\ndef flattener(pred):\n    \n    str_pred = str([row for row in pred.tolist()])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    \n    return str_pred\n\ndef build_trainlist(task):\n    \n    task_data = []\n    for i, t in enumerate(task[\"train\"]):\n        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n        list.append(task_data, (t_in.copy(), t_out.copy()))\n    \n    return task_data\n\ndef build_testlist(task):\n    \n    task_data = []\n    for i, t in enumerate(task[\"test\"]):\n        t_in = np.array(t[\"input\"]).astype('uint8')       \n        list.append(task_data, (t_in.copy()))\n    \n    return task_data\n\ndef load_data(p, phase=None):\n    \n    if phase in {'training', 'test', 'evaluation'}:\n        p = data_path / phase / p\n    \n    task = json.loads(Path(p).read_text())\n    dict_vals_to_np = lambda x: { k : np.array(v) for k, v in x.items() }\n    assert set(task) == {'test', 'train'}\n    res = dict(test=[], train=[])\n    \n    for t in task['train']:\n        assert set(t) == {'input', 'output'}\n        res['train'].append(dict_vals_to_np(t))\n    for t in task['test']:\n        res['test'].append(dict_vals_to_np(t))\n        \n    return res\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":3,"outputs":[{"output_type":"stream","text":"Load Data Functions ...\n--- 0.00074005126953125 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load Data Files ...\")\n\ntrain_task_data = []\nfor i in range(0, 400):\n    task = load_data(training_tasks[i], phase='training')\n    list.append(train_task_data, task)\n\neval_task_data = []\nfor i in range(0, 400):\n    task = load_data(evaluation_tasks[i], phase='evaluation')\n    list.append(eval_task_data, task)\n\ntest_task_data = []\nfor i in range(0, 100):\n    task = load_data(testing_tasks[i], phase='test')\n    list.append(test_task_data, task)\n    \nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":4,"outputs":[{"output_type":"stream","text":"Load Data Files ...\n--- 1.4455881118774414 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load Checking Functions\")\n\ncmap = colors_mat.ListedColormap(\n    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors_mat.Normalize(vmin=0, vmax=9)\nnum2color = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\ncolor2num = {c: n for n, c in enumerate(num2color)}\n\ndef check_p(task, pred_func):\n    \n    fig_num = 0\n    n = len(task[\"train\"]) + len(task[\"test\"])\n    fig, axs = plt.subplots(3, n, figsize=(4*n,12), dpi=50)\n    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n\n    # All Data for Task\n    train_data = build_trainlist(task)\n    test_data = build_testlist(task)\n    task_data = Task(train_data, test_data)\n    \n    for i, t in enumerate(task[\"train\"]):\n        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')   \n        t_pred = pred_func(t_in)\n        \n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Train-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Train-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n        axs[2][fig_num].set_title(f'Train-{i} pred')\n        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n        fig_num += 1\n        \n    for i, t in enumerate(task[\"test\"]):\n        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')\n        t_pred = pred_func(t_in)\n        \n        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n        axs[0][fig_num].set_title(f'Test-{i} in')\n        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n        axs[1][fig_num].set_title(f'Test-{i} out')\n        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n        axs[2][fig_num].set_title(f'Test-{i} pred')\n        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n        fig_num += 1\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":5,"outputs":[{"output_type":"stream","text":"Load Checking Functions\n--- 0.0015671253204345703 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load DSL Helper Functions (Colors)\")\n\n# Ensure No Coordinate Match\ndef coord_match(grid1, grid2):\n    return all(np.array_equal(i, j) for i, j in zip(grid1['coords'], grid2['coords']))\n\n# Ensure No Duplicate Objects by Coordinates\ndef search_array(arr, arr_data):\n    return next((True for elem in arr_data if coord_match(elem, arr)), False)\n    \n# Return Grid Color (%) Dictionary \n# Example: {0: 0.666, 1: 0.333}\ndef get_colors_percentages(grid):\n    n_elements = grid.shape[0] * grid.shape[1]    \n    unique, counts = np.unique(grid, return_counts=True)\n    percentages =  dict(zip(unique, counts))\n    percentages.update((x, y * 1.0 / n_elements) for x, y in percentages.items())\n    return percentages\n\n# Return Background Color in Grid\ndef get_background_color(grid):\n    \n    try:    \n        background_color = 0\n        cnt = np.bincount(grid.flatten())\n        if cnt[0] >= 1:\n            bg_color = [i + 1 for i, x in enumerate(cnt) if x == max(cnt)][0]\n            if np.nonzero(cnt)[0].shape[0] >= 2:\n                if max(cnt) >= (grid.shape[0] * grid.shape[1] * 0.25):\n                    background_color = bg_color\n        return background_color    \n    \n    except:\n        return 0\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":6,"outputs":[{"output_type":"stream","text":"Load DSL Helper Functions (Colors)\n--- 0.0006289482116699219 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load DSL Helper Functions (Objects)\")\n  \n# Separate Objects by Distance\ndef object_distance(grid):\n    \n    # List of Objects\n    object_list = []\n    grid_copy = grid.copy()\n    struct = generate_binary_structure(2, 2)\n    labels, num_labels = label((grid_copy != 0), structure=struct)\n\n    # Find Objects\n    for i in range(0, num_labels):\n        idx = np.column_stack(np.where(labels == i + 1))\n        x_min = min([point[0] for point in idx])\n        y_min = min([point[1] for point in idx])\n        x_max = max([point[0] for point in idx])\n        y_max = max([point[1] for point in idx])\n                \n        idx = []\n        for i in range(x_min, x_max + 1):\n            for j in range(y_min, y_max + 1):\n                list.append(idx, [i, j])\n              \n        object_data = {}\n        object_data['coords'] = idx\n        object_data['obj'] = grid_copy[x_min: x_max + 1, y_min: y_max + 1]\n        list.append(object_list, object_data)\n\n    return object_list\n        \n# Separate Objects by Color/Distance\ndef object_color_distance(grid):\n    \n    # List of Objects\n    object_list = []\n    grid_copy = grid.copy()\n    struct = generate_binary_structure(2, 2)\n    num_objects = 0\n\n    grid_colors = np.unique(grid_copy)\n    bg_color = get_background_color(grid_copy)\n    grid_colors = [color for color in grid_colors if color not in [0, bg_color]]\n    \n    # Find Objects\n    for color in grid_colors:\n        labels, num_labels = label((grid_copy == color), structure=struct)\n        num_objects += num_labels\n        \n        for i in range(0, num_labels):\n            idx = np.column_stack(np.where(labels == i + 1))\n            x_min = min([point[0] for point in idx])\n            y_min = min([point[1] for point in idx])\n            x_max = max([point[0] for point in idx])\n            y_max = max([point[1] for point in idx])\n            \n            idx = []\n            for i in range(x_min, x_max + 1):\n                for j in range(y_min, y_max + 1):\n                    list.append(idx, [i, j])\n\n            object_data = {}\n            object_data['coords'] = idx\n            object_data['obj'] = grid_copy[x_min: x_max + 1, y_min: y_max + 1]\n            list.append(object_list, object_data)\n        \n    if num_objects <= 50:\n        return object_list\n    \n    return []\n\n# Separate Objects in Grid\ndef object_detection(grid):\n    \n    # List of Objects\n    combined_objects = []\n    \n    # Run Object Detection (1)\n    obj1 = object_distance(grid)    \n    for object_ in obj1:\n        if not search_array(object_, combined_objects):\n            combined_objects.append(object_)\n\n    # Run Object Detection (2)\n    obj2 = object_color_distance(grid)\n    for object_ in obj2:\n        if not search_array(object_, combined_objects):\n            combined_objects.append(object_)\n\n    return combined_objects\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":53,"outputs":[{"output_type":"stream","text":"Load DSL Helper Functions (Objects)\n--- 0.0012440681457519531 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load DSL Helper Functions (Attributes)\")\n\ndef get_similar_attributes(attribute_list):\n    \n    attribute_flag = True\n    for attribute_data in attribute_list[1:]:\n        if attribute_list[0] != attribute_data:\n            attribute_flag = False\n    \n    return attribute_flag\n\ndef get_different_attributes(attribute_list):\n    \n    attribute_flag = True\n    for attribute_data in attribute_list[1:]:\n        if attribute_list[0] == attribute_data:\n            attribute_flag = False\n    \n    return attribute_flag\n\n# Return Similarity Scores    \ndef get_similarities(grid1, grid2):\n    \n    similarities = 0\n    grid1_copy = grid1.copy()\n    grid2_copy = grid2.copy()    \n        \n    try:\n        for i in range(0, grid1_copy.shape[0]):\n            for j in range(0, grid1_copy.shape[1]):\n                if grid1_copy[i][j] == grid2_copy[i][j]:\n                    if grid2_copy[i][j] != 0:\n                        similarities += 1\n    except:\n        pass\n                \n    return similarities\n\n# Return Closest Object Mapping\ndef get_object_mapping(grid, grid_list):\n    \n    mappings = []\n    \n    # Find Input/Output Mappings\n    for object_ in grid_list:\n        grid_copy = copy.copy(grid)\n        object_copy = copy.copy(object_)\n\n        # Calculate/Modify Similarities\n        similarities = get_similarities(grid_copy.grid, object_copy.grid)\n        array_flag = np.array_equal(grid_copy.grid, object_copy.grid)\n        shape_flag = grid_copy.grid.shape == object_copy.grid.shape\n        coord_flag = all(np.array_equal(i, j) for i, j in zip(grid_copy.coords, object_copy.coords))\n\n        if shape_flag:\n            similarities += 1\n        if coord_flag:\n            similarities += 1\n        if array_flag:\n            similarities += 1\n            \n        # Add Mapping to List\n        if similarities >= 1:\n            list.append(mappings, [object_copy, similarities])                    \n    \n    # Sort Mappings By Similarities\n    if len(mappings) >= 1:\n        mappings = sorted(mappings, key=lambda x: x[1], reverse=True)\n        \n    return mappings\n                 \n# Return Attribute Ranking of Object\ndef get_relative_ranking(attribute, grid, grid_list):\n        \n    # Find Attribute Values\n    relative_values = []\n    for object_ in grid_list:\n        attr_value = object_.attributes[attribute]\n        list.append(relative_values, attr_value)\n        \n    # Sort Attributes by Values\n    relative_values = sorted(relative_values, reverse=True)\n    grid_value = grid.attributes[attribute]\n    return relative_values.index(grid_value)\n        \nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":110,"outputs":[{"output_type":"stream","text":"Load DSL Helper Functions (Attributes)\n--- 0.0009763240814208984 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load DSL Helper Functions (Entity)\")\n\n# Fundamental Entity (Tensors, Objects, etc). \n# Contains all Basic Methods acting on Task Samples.\nclass Entity():\n    \n    def __init__(self, object_, object_data=None):\n                \n        if type(object_) is dict:\n            self.grid = object_[\"obj\"]\n            self.coords = object_[\"coords\"]\n            self.percentages = get_colors_percentages(self.grid)\n\n        else:\n            self.grid = object_\n        \n        self.object_data = []\n        if object_data != None:\n            for object_ in object_data:\n                section = Section(object_)\n                section.compute_attributes()\n                list.append(self.object_data, section)\n            \n    def compute_attributes(self):\n        \n        self.attributes = {}\n        self.attributes[\"grid_length\"] = self.grid.shape[0]\n        self.attributes[\"grid_width\"] = self.grid.shape[1]\n        self.attributes[\"grid_surface\"] = self.grid.shape[0] * self.grid.shape[1]\n                                 \n        if len(self.object_data) >= 1:\n            self.attributes[\"relative_length\"] = get_relative_ranking(\"grid_length\", self, self.object_data)\n            self.attributes[\"relative_width\"] = get_relative_ranking(\"grid_width\", self, self.object_data)\n            self.attributes[\"relative_surface\"] = get_relative_ranking(\"grid_surface\", self, self.object_data)\n        \nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":111,"outputs":[{"output_type":"stream","text":"Load DSL Helper Functions (Entity)\n--- 0.0006208419799804688 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load DSL Helper Functions (Tensor)\")\n\n# Extends Entity Class\n# Contains Data for Sections of Grid\nclass Section(Entity):\n    \n    def __init__(self, section_data, object_data=None):\n        super().__init__(section_data, object_data=object_data)\n        self.compute_attributes()\n            \n    def compute_attributes(self):\n        super().compute_attributes()\n\n# Extends Entity Class\n# Contains Entire Data for Input/Output\nclass Tensor(Entity):\n    \n    def __init__(self, grid):\n        super().__init__(grid)\n        self.objects = []\n        self.compute_features()\n        self.compute_attributes()\n\n    def compute_features(self):\n        object_data = object_detection(self.grid)\n        for object_ in object_data:\n            section = Section(object_, object_data)\n            section.compute_attributes()\n            list.append(self.objects, section)\n                \n    def compute_attributes(self):\n        super().compute_attributes()           \n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":112,"outputs":[{"output_type":"stream","text":"Load DSL Helper Functions (Tensor)\n--- 0.0007569789886474609 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Load DSL Helper Functions (Task)\")\n\n# Fundamental Class for ALL Tasks\n# Contains all Basic Methods acting on Tasks.\nclass Task():\n    \n    # Initialize Task Data\n    def __init__(self, train_data, test_data, task_idx=0):\n        \n        # Identifying Information\n        self.task_idx = task_idx\n        \n        # Lists of Train/Test Tensors\n        self.train_tensors = []\n        self.test_tensors = []\n        \n        # Dictionaries/Attributes for Object Mappings\n        self.color_mappings = {}\n        self.agent_mappings = {}\n        self.color_attributes = {}\n        self.agent_attributes = {}\n        \n        # Unique Rules that Determine Output\n        self.color_rule = None\n        self.agent_rule = None\n        \n        # Compute Train/Output Tensors\n        for t_in, t_out in train_data:\n            tensor_in = Tensor(t_in)\n            tensor_out = Tensor(t_out)\n            tensor_in.compute_attributes()\n            tensor_out.compute_attributes()\n            list.append(self.train_tensors, [tensor_in, tensor_out])\n         \n        # Compute Test Tensors\n        for t_in in test_data:\n            tensor_in = Tensor(t_in)\n            tensor_in.compute_attributes()\n            list.append(self.test_tensors, [tensor_in])\n            \n    def similar_attributes(self):\n        \n        similar_attributes = []\n        for color, object_data in self.color_attributes.items():\n            attributes_to_check = list(object_data[0].attributes.keys())\n            for attribute in attributes_to_check:\n                attribute_data = [object_.attributes[attribute] for object_ in object_data]\n                attribute_flag = get_similar_attributes(attribute_data)\n                if attribute_flag == True:\n                    list.append(similar_attributes, attribute)\n        \n        return similar_attributes\n          \n    def different_attributes(self, similar_attributes):\n                \n        attribute_data = list(set(self.color_attributes))\n        for attribute in similar_attributes:\n            attribute_values = []\n            for color, object_data in self.color_attributes.items():\n                object_attributes = [object_.attributes[attribute] for object_ in object_data]\n                list.append(attribute_values, object_attributes[0])\n            attribute_flag = get_different_attributes(attribute_values)\n            if attribute_flag == True:\n                self.color_rule = attribute\n                \n    def object_mapping(self, t_in, t_out):\n\n        # Determine Object Mappings\n        for object_in in t_in.objects:\n            object_mappings = get_object_mapping(object_in, t_out.objects)\n            \n            if len(object_mappings) >= 1:\n                object_out = object_mappings[0][0]\n\n                # Determine Type of Mapping\n                array_flag = np.array_equal(object_in.grid, object_out.grid)\n                length_flag = len(object_in.coords) == len(object_out.coords)\n                coord_flag = all(np.array_equal(i, j) for i, j in zip(object_in.coords, object_out.coords))\n                \n                # Similar = Same Grid, Same Coords\n                if array_flag and coord_flag:\n                    self.color_mappings[object_in] = object_out\n                    self.agent_mappings[object_in] = object_out\n                # Color = Different Grid, Same Coords\n                elif not array_flag and coord_flag:\n                    self.color_mappings[object_in] = object_out\n                # Agent = Same Grid, Different Coords\n                elif array_flag and not coord_flag:    \n                    self.agent_mappings[object_in] = object_out\n                        \n    def color_groupings(self):\n                           \n        for object_in, object_out in self.color_mappings.items():\n            color_key = list(object_out.percentages.keys())[0]\n            if color_key in self.color_attributes:\n                list.append(self.color_attributes[color_key], object_in)\n            else:\n                self.color_attributes[color_key] = [object_in]\n\n        attribute_data = self.similar_attributes()\n        self.different_attributes(attribute_data)\n        print(self.color_rule)\n        \n    # Compute Attribute Differences\n    def compute_differences(self):\n        \n        # Calculate Object Mappings\n        for t_in, t_out in self.train_tensors:\n            if t_in.grid.shape == t_out.grid.shape:\n                self.object_mapping(t_in, t_out)\n        \n        self.color_groupings()\n                \n# Fundamental Class for Generated Programs\n# Contains all Basic Methods acting on Programs\nclass Program():\n    \n    # Initialize Program Data\n    def __init__(self, train_data, test_data, task_idx=0):\n        \n        # Identifying Information\n        self.task_idx = task_idx\n\n        # Lists of Train/Test Tensors\n        self.train_data = train_data\n        self.test_data = test_data\n\n        # Program Data/Accuracy\n        self.functions = []\n        self.similarity = 0\n        self.accuracy = 0\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":120,"outputs":[{"output_type":"stream","text":"Load DSL Helper Functions (Task)\n--- 0.0011816024780273438 seconds ---\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"task_n = 9\n\n#for task_n, task in enumerate(train_task_data):\nprint(\"Current Task: {}\".format(task_n))\n\n# Generate Task for Given Input\ntrain_data = build_trainlist(train_task_data[task_n])\ntest_data = build_testlist(train_task_data[task_n])\ntask_data = Task(train_data, test_data, task_idx=task_n)\ntask_data.compute_differences()\n\n# Generate Program to Solve Given Task\ntask_program = Program(train_data, test_data, task_idx=task_n)\nprint(\"\")","execution_count":121,"outputs":[{"output_type":"stream","text":"Current Task: 9\nrelative_surface\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}