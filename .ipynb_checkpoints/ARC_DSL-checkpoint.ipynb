{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 version:  4.1.1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy\n",
    "import gc\n",
    "import cv2\n",
    "import requests\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as colors_mat\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "from skimage import measure\n",
    "from skimage.segmentation import flood, flood_fill\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from itertools import product\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.signal import convolve2d\n",
    "from collections import Counter\n",
    "from cv2 import matchTemplate as cv2m\n",
    "from math import sqrt; from itertools import count, islice\n",
    "print(\"cv2 version: \",cv2.__version__)\n",
    "\n",
    "DEBUG = True # Active logging, printing, etc. False when committing to the LB. \n",
    "url_slack = \"https://hooks.slack.com/services/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\"  # This is secret, do not share.\n",
    "headers = {'Content-type': 'application/json'}\n",
    "MAX_DIM_MATRIX = 30\n",
    "MAX_magic_args_number = 1000\n",
    "I_AM_IN_KAGGLE = os.path.isdir(\"/kaggle/input/abstraction-and-reasoning-challenge/\")\n",
    "black_square = np.full((2,2),0)\n",
    "DUMMY_COLOR = 17\n",
    "MAX_N_OBJECTS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Initial Data ...\n",
      "--- 0.017928123474121094 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Initial Data ...\")\n",
    "\n",
    "if I_AM_IN_KAGGLE:\n",
    "    data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "else:\n",
    "    data_path = Path('')\n",
    "training_path = data_path / 'training'\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "testing_path = data_path / 'test'\n",
    "\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "evaluation_tasks = sorted(os.listdir(evaluation_path))\n",
    "testing_tasks = sorted(os.listdir(testing_path))\n",
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Functions ...\n",
      "--- 0.003201007843017578 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Functions ...\")\n",
    "\n",
    "def flattener(pred):\n",
    "    \n",
    "    str_pred = str([row for row in pred.tolist()])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    \n",
    "    return str_pred\n",
    "\n",
    "def build_trainlist(task):\n",
    "    \n",
    "    task_data = []\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "        list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "    \n",
    "    return task_data\n",
    "\n",
    "def build_testlist(task, LB_submission=False, pair_id=0):\n",
    "    \n",
    "    task_data = []\n",
    "    \n",
    "    if LB_submission:\n",
    "        t_in = np.array(task[\"test\"][pair_id][\"input\"]).astype('uint8')       \n",
    "        list.append(task_data, (t_in.copy()))\n",
    "    else:\n",
    "        for i, t in enumerate(task[\"test\"]):\n",
    "            t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "            list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "          \n",
    "    return task_data\n",
    "\n",
    "def load_data(p, phase=None):\n",
    "    \n",
    "    if phase in {'training', 'test', 'evaluation'}:\n",
    "        p = data_path / phase / p\n",
    "    \n",
    "    task = json.loads(Path(p).read_text())\n",
    "    dict_vals_to_np = lambda x: { k : np.array(v) for k, v in x.items() }\n",
    "    assert set(task) == {'test', 'train'}\n",
    "    res = dict(test=[], train=[])\n",
    "    \n",
    "    for t in task['train']:\n",
    "        assert set(t) == {'input', 'output'}\n",
    "        res['train'].append(dict_vals_to_np(t))\n",
    "    for t in task['test']:\n",
    "        res['test'].append(dict_vals_to_np(t))\n",
    "        \n",
    "    return res\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Files ...\n",
      "--- 0.8726489543914795 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Files ...\")\n",
    "\n",
    "train_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(training_tasks[i], phase='training')\n",
    "    list.append(train_task_data, task)\n",
    "\n",
    "eval_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(evaluation_tasks[i], phase='evaluation')\n",
    "    list.append(eval_task_data, task)\n",
    "\n",
    "test_task_data = []\n",
    "for i in range(0, 100):\n",
    "    task = load_data(testing_tasks[i], phase='test')\n",
    "    list.append(test_task_data, task)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checking Functions\n",
      "--- 0.0016560554504394531 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Checking Functions\")\n",
    "\n",
    "cmap = colors_mat.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors_mat.Normalize(vmin=0, vmax=9)\n",
    "num2color = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\n",
    "color2num = {c: n for n, c in enumerate(num2color)}\n",
    "\n",
    "def plot_one(task, ax, i,train_or_test,input_or_output):\n",
    "    \n",
    "    input_matrix = task[train_or_test][i][input_or_output]\n",
    "    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
    "    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
    "    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(train_or_test + ' '+ input_or_output)\n",
    "    \n",
    "def plot_task(task):\n",
    "\n",
    "    num_train = len(task['train'])\n",
    "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
    "    for i in range(num_train):     \n",
    "        plot_one(task, axs[0,i],i,'train','input')\n",
    "        plot_one(task, axs[1,i],i,'train','output')        \n",
    "    plt.tight_layout()\n",
    "    plt.show()        \n",
    "        \n",
    "    num_test = len(task['test'])\n",
    "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
    "    if num_test==1: \n",
    "        plot_one(task, axs[0],0,'test','input')\n",
    "        plot_one(task, axs[1],0,'test','output')     \n",
    "    else:\n",
    "        for i in range(num_test):      \n",
    "            plot_one(task, axs[0,i],i,'test','input')\n",
    "            plot_one(task, axs[1,i],i,'test','output')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def check_p(task, pred_func):\n",
    "    \n",
    "    fig_num = 0\n",
    "    n = len(task[\"train\"]) + len(task[\"test\"])\n",
    "    fig, axs = plt.subplots(3, n, figsize=(4*n,12), dpi=50)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # All Data for Task\n",
    "    train_data = build_trainlist(task)\n",
    "    test_data = build_testlist(task)\n",
    "    task_data = Task(train_data, test_data)\n",
    "    \n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')   \n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Train-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Train-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Train-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "        \n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')\n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Test-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Test-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Test-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Main)\n",
      "--- 0.005369901657104492 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Main)\")\n",
    "\n",
    "# color the given coordinates points, passed as list of 2d list. Example: [[0,1],[2,3],[2,4]]\n",
    "def color_points(t,points_coord,color):\n",
    "    \n",
    "    t_copy = np.copy(t)\n",
    "    for point in points_coord:\n",
    "        t_copy[point[0],point[1]] = color\n",
    "    return t_copy\n",
    "\n",
    "# https://stackoverflow.com/questions/10823877/what-is-the-fastest-way-to-flatten-arbitrarily-nested-lists-in-python\n",
    "# flatten a list of nested lists\n",
    "def flatten_rec(container):\n",
    "    for i in container:\n",
    "        if isinstance(i, (list,tuple)):\n",
    "            for j in flatten_rec(i):\n",
    "                yield j\n",
    "        else:\n",
    "            yield i\n",
    "            \n",
    "#https://stackoverflow.com/questions/32531377/how-can-i-check-if-one-two-dimensional-numpy-array-contains-a-specific-pattern-o\n",
    "# return the coords of all the instances of template in grid (upper left corner)\n",
    "def match_template(grid, template):\n",
    "    \n",
    "    # check that the shapes are consinstent\n",
    "    if grid.shape == (1,):\n",
    "        return []\n",
    "    if template.shape == (1,):\n",
    "        pass \n",
    "    else:\n",
    "        if (grid.shape[0] < template.shape[0]) or (grid.shape[1] < template.shape[1]):\n",
    "            return []\n",
    "        \n",
    "    M = cv2m(grid.astype('uint8'),template.astype('uint8'),cv2.TM_SQDIFF)\n",
    "    x,y = np.where(M<0.01) # =0 can fail with floats\n",
    "    coords = list(zip(x, y))\n",
    "    return coords\n",
    "\n",
    "# https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical\n",
    "def checkEqual1(iterator):\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all(first == rest for rest in iterator)\n",
    "\n",
    "# expect a list of lists, check that all of them have more than N elements\n",
    "def checkAllMoreN(iterator, N):\n",
    "    if iterator == []:\n",
    "        return False\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "        if not (len(first) > N):\n",
    "            return False\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all( (len(rest) > N) for rest in iterator)\n",
    "\n",
    "def is_prime(n):\n",
    "    return n > 1 and all(n%i for i in islice(count(2), int(sqrt(n)-1)))\n",
    "\n",
    "# return max and min lenght objects in llist\n",
    "def checkMaxMinLen(llist):\n",
    "    max_len = 0\n",
    "    min_len = 100\n",
    "    for el in llist:\n",
    "        if len(el) > max_len:\n",
    "            max_len = len(el)\n",
    "        if len(el) < min_len:   \n",
    "            min_len = len(el)\n",
    "    return {\"min_len\":min_len, \"max_len\":max_len}\n",
    "        \n",
    "# return max and min attributes in llist, as selected by the key\n",
    "def checkMaxMinAttribute(llist,key):\n",
    "    max_attr = -100\n",
    "    min_attr = 1000\n",
    "    for el in llist:\n",
    "        attr = el.attributes[key]\n",
    "        if attr > max_attr:\n",
    "            max_attr = attr\n",
    "        if attr < min_attr:   \n",
    "            min_attr = attr\n",
    "    return {\"max_attr\":max_attr, \"min_attr\":min_attr}\n",
    "        \n",
    "\n",
    "def send_slack_report(message):\n",
    "    data = {'auth_token': 'auth1', 'widget': 'id1', 'text': message}\n",
    "    r = requests.post(url_slack, data=json.dumps(data), headers=headers)\n",
    "\n",
    "def get_neighbors(grid, i, j):\n",
    "    \n",
    "    nbh = lambda x, i, j: { \n",
    "        (ip, jp) : x[i+ip, j+jp] \n",
    "            for ip, jp in product([1, -1, 0], repeat=2) \n",
    "                if 0 <= i+ip < x.shape[0] and 0 <= j+jp < x.shape[1]\n",
    "    }\n",
    "        \n",
    "    nbh_data = nbh(grid, i, j)\n",
    "    nbh_values = [(1, 1), (1, -1), (1, 0), (-1, 1), (-1, -1), \n",
    "                  (-1, 0), (0, 1), (0, -1), (0, 0)]\n",
    "\n",
    "    for val in nbh_values:\n",
    "        if val not in nbh_data:\n",
    "            nbh_data[val] = 0\n",
    "    \n",
    "    return nbh_data\n",
    "\n",
    "def get_background_color(grid):\n",
    "    \n",
    "    try:    \n",
    "        background_color = 0\n",
    "        cnt = np.bincount(grid.flatten())[1:]\n",
    "        bg_color = [i + 1 for i, x in enumerate(cnt) if x == max(cnt)][0]\n",
    "        if np.nonzero(cnt)[0].shape[0] >= 2:\n",
    "            if max(cnt) >= (grid.shape[0] * grid.shape[1] * 0.25):\n",
    "                background_color = bg_color\n",
    "        return background_color    \n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "# return a list with all the colors available in grid\n",
    "def get_unique_colors(grid):\n",
    "        return np.unique(grid).tolist()\n",
    "    \n",
    "# Return a dictionary color:percentage, for instance: {0: 0.666,1: 0.333, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}\n",
    "def color_percentage(grid, sorted_dict=True):\n",
    "    \n",
    "    n_elements = grid.shape[0] * grid.shape[1]\n",
    "    if ( n_elements <= 0):\n",
    "        raise ValueError(\"n_elements <= 0\")\n",
    "    unique, counts = np.unique(grid, return_counts=True)\n",
    "    if not (all(j < 10 for j in unique)):\n",
    "        raise ValueError(\"Uknown color! unique:\", unique)\n",
    "        \n",
    "    percentages =  dict(zip(unique, counts))\n",
    "    for color in range(0,10):\n",
    "        if color not in percentages.keys():\n",
    "            percentages[color] = 0.0\n",
    "    percentages.update((x, y*1.0/n_elements) for x, y in percentages.items())\n",
    "    \n",
    "    if sorted_dict:\n",
    "        percentages = collections.OrderedDict(sorted(percentages.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return percentages\n",
    "\n",
    "# Return True if symmetric\n",
    "def horizontal_symmetric(grid):\n",
    "    return np.array_equal(grid, np.flipud(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def vertical_symmetric(grid):\n",
    "    return np.array_equal(grid, np.fliplr(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def left_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid.T)\n",
    "\n",
    "# Return True if symmetric\n",
    "def right_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid[::-1,::-1].T) # or np.rot90(grid,2).T\n",
    "\n",
    "# If yes, return the color, else None\n",
    "def is_border_monocolor(a):\n",
    "    \n",
    "    color = a[0,0]\n",
    "    for x in range(0,a.shape[1]-1):\n",
    "        if (a[0,x] != color) or (a[a.shape[0]-1,x] != color):\n",
    "            return None\n",
    "    for x in range(0,a.shape[0]-1):\n",
    "        if (a[x,0] != color) or (a[x,a.shape[1]-1] != color):\n",
    "            return None\n",
    "    return color\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Detection)\n",
      "--- 0.0046651363372802734 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Detection)\")\n",
    "       \n",
    "## OBJECTS ######################\n",
    "\n",
    "# detect all the objects (a cluster of pixels colored differently from the background, without making distinction of colors)\n",
    "# Return a list of arrays, containing the coordinates of the objects in the parent grid.\n",
    "def detect_objects(grid, include_diag=True):\n",
    "    \n",
    "    structure = [[1,1,1],[1,1,1],[1,1,1]]\n",
    "    if not include_diag:\n",
    "        structure = [[0,1,0],[1,1,1],[0,1,0]]\n",
    "        \n",
    "    t_copy = np.copy(grid)\n",
    "    background_color = get_background_color(grid)\n",
    "    u_colors = np.unique(grid)\n",
    "    colors = np.delete(u_colors, np.where(u_colors == background_color))\n",
    "    t_copy[t_copy != background_color] = DUMMY_COLOR\n",
    "    \n",
    "    indices = []\n",
    "    labels, num_labels = label(t_copy == DUMMY_COLOR, structure=structure)\n",
    "    \n",
    "    for i in range(0, num_labels):\n",
    "        idx = np.column_stack(np.where(labels == i + 1))\n",
    "        list.append(indices, idx)\n",
    "    \n",
    "    if len(indices) > MAX_N_OBJECTS:\n",
    "        return []\n",
    "    return indices\n",
    "\n",
    "# Take an array with the object coordinates in the parent grid, and return useful stats.\n",
    "def matrix_rect(obj, add_border=0):\n",
    "    \n",
    "    x_max, x_min, y_max, y_min = 0, 99, 0, 99\n",
    "    \n",
    "    for point in obj:\n",
    "        if point[0] < x_min:\n",
    "            x_min = point[0]\n",
    "        if point[1] < y_min:\n",
    "            y_min = point[1]\n",
    "        if point[0] > x_max:\n",
    "            x_max = point[0]\n",
    "        if point[1] > y_max:\n",
    "            y_max = point[1]\n",
    "            \n",
    "    x_min = x_min - add_border\n",
    "    y_min = y_min - add_border\n",
    "    x_max = x_max + add_border\n",
    "    y_max = y_max + add_border\n",
    "\n",
    "    for i in range(x_min,x_max + 1):\n",
    "        for j in range(y_min,y_max + 1):\n",
    "            new_point = [i,j]\n",
    "            if not (new_point in obj):\n",
    "                obj.append(new_point)\n",
    "                \n",
    "    x_dim = x_max + 1 - x_min\n",
    "    y_dim = y_max + 1 - y_min\n",
    "    \n",
    "    return {\"obj\":obj, \n",
    "            \"x_dim\": x_dim, \n",
    "            \"y_dim\": y_dim, \n",
    "            \"x_max\": x_max, \n",
    "            \"y_max\": y_max, \n",
    "            \"x_min\": x_min, \n",
    "            \"y_min\": y_min}\n",
    "    \n",
    "    \n",
    "# fill a contiguous space with fill_color, percolating from starting_point\n",
    "def fill_holes(t,fill_color,starting_point=(0,0)):\n",
    "    t_copy = np.copy(t)\n",
    "    filled = flood_fill(t_copy, starting_point,fill_color,connectivity=0) #  TODO, should fill holes also diagonally\n",
    "    return filled\n",
    "    \n",
    "# is this value(color) on the border of the grid?\n",
    "def is_value_on_border(t,value):\n",
    "    for i in range(0,t.shape[0]):\n",
    "        if (t[i,0]==value): \n",
    "                return True\n",
    "        if (t[i,t.shape[1]-1]==value): \n",
    "                return True\n",
    "    for j in range(0,t.shape[1]):\n",
    "        if (t[0,j]==value): \n",
    "                return True\n",
    "        if (t[t.shape[0]-1,j]==value): \n",
    "                return True         \n",
    "    return False\n",
    "\n",
    "# return the coordinates of all the holes in t. An hole is defined as a region which does not percolate to the border.\n",
    "def flood_scan(t, count_only_background_holes = True):\n",
    "    holes_coordinates = []\n",
    "    t_copy = np.copy(t)\n",
    "    for i in range(0,t.shape[0]):\n",
    "        for j in range(0,t.shape[1]):\n",
    "            filled = fill_holes(t_copy,DUMMY_COLOR,starting_point=(i,j))\n",
    "            if not is_value_on_border(filled,DUMMY_COLOR):\n",
    "                holes_coordinates.append([i,j])\n",
    "    \n",
    "    # remove \"border regions\" inside the grid from the holes coordinates\n",
    "    if count_only_background_holes:\n",
    "        new_holes_coordinates = []\n",
    "        background_color = get_background_color(t)\n",
    "        for point in holes_coordinates:\n",
    "            if (t[point[0],point[1]] == background_color):\n",
    "                new_holes_coordinates.append(point)\n",
    "        return new_holes_coordinates\n",
    "        \n",
    "    return holes_coordinates\n",
    "\n",
    "## REGIONS ######################\n",
    "\n",
    "# detect lines which span the whole grid. Return the associated index. Detect only lines where the line-color is not repeated elsewhere in the grid\n",
    "def detect_region_lines(a): \n",
    "    \n",
    "    lines = {\"h_lines\":[],\"v_lines\":[],\"rd_lines\":[],\"ld_lines\":[]} # left is the \"traditional\" diagonal\n",
    "    try:\n",
    "        for i in range(a.shape[1]):\n",
    "            if np.all(a[:,i]==([a[0,i]]*a.shape[0])):\n",
    "                lines[\"v_lines\"].append(i)\n",
    "\n",
    "        for j in range(a.shape[0]):\n",
    "            if np.all(a[j,:]==([a[j,0]]*a.shape[1])):\n",
    "                lines[\"h_lines\"].append(j) \n",
    "    except:\n",
    "        pass\n",
    "     \n",
    "    b = np.copy(a)\n",
    "    \n",
    "    for key, value in lines.items():      \n",
    "        if key==\"h_lines\":\n",
    "            b = np.delete(b, value, axis=0)\n",
    "        if key==\"v_lines\":\n",
    "            b = np.delete(b, value, axis=1)\n",
    "        \n",
    "    # eliminate lines which are not real separators\n",
    "    h_lines = []\n",
    "    v_lines = []\n",
    "    \n",
    "    for key, value in lines.items():\n",
    "        for line_index in value:\n",
    "            line_color = 0\n",
    "            if key==\"h_lines\":\n",
    "                line_color = a[line_index,0]\n",
    "                if line_color not in b:\n",
    "                    h_lines.append(line_index)\n",
    "            if key==\"v_lines\":\n",
    "                line_color = a[0,line_index]\n",
    "                if line_color not in b:\n",
    "                    v_lines.append(line_index)\n",
    "        \n",
    "    lines[\"h_lines\"] = h_lines\n",
    "    lines[\"v_lines\"] = v_lines\n",
    "    \n",
    "    return lines\n",
    "\n",
    "# detect lines which span the whole grid. Return the associated index. \n",
    "def detect_simple_lines(a): \n",
    "    \n",
    "    lines = {\"h_lines\":[],\"v_lines\":[],\"rd_lines\":[],\"ld_lines\":[]}\n",
    "    try:\n",
    "        for i in range(a.shape[1]):\n",
    "            if np.all(a[:,i]==([a[0,i]]*a.shape[0])):\n",
    "                lines[\"v_lines\"].append(i)\n",
    "\n",
    "        for j in range(a.shape[0]):\n",
    "            if np.all(a[j,:]==([a[j,0]]*a.shape[1])):\n",
    "                lines[\"h_lines\"].append(j) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return lines\n",
    "\n",
    "# detect lines which span the whole grid, but can be interrupted in some points. Return the associated index, color, and orientation. \n",
    "# Also the line-color can be repeated elsewhere in the grid\n",
    "def detect_pseudolines(a, backg_color): \n",
    "    threshold = 0.6\n",
    "    plines = {\"h_lines\":[],\"v_lines\":[],\"rd_lines\":[],\"ld_lines\":[]}\n",
    "    b = a.copy()\n",
    "    try:        \n",
    "        for x in range(a.shape[0]):\n",
    "            counts = np.bincount(a[x,:])\n",
    "            color = np.argmax(counts)\n",
    "            if color != backg_color:\n",
    "                perc_color = counts[color]/sum(counts)\n",
    "                if perc_color > threshold:\n",
    "                    plines[\"h_lines\"].append({\"ind\":x,\"color\":color,\"perc\":perc_color})\n",
    "\n",
    "        for y in range(a.shape[1]):\n",
    "            counts = np.bincount(a[:,y])\n",
    "            color = np.argmax(counts)\n",
    "            if color != backg_color:\n",
    "                perc_color = counts[color]/sum(counts)\n",
    "                if perc_color > threshold:\n",
    "                    plines[\"v_lines\"].append({\"ind\":y,\"color\":color,\"perc\":perc_color})\n",
    "                    \n",
    "        for offset in range(-(a.shape[0] - 1), (a.shape[0])):\n",
    "            counts =  np.bincount(a.diagonal(offset=offset))\n",
    "            color = np.argmax(counts)\n",
    "            if color != backg_color:\n",
    "                perc_color = counts[color]/sum(counts)\n",
    "                if perc_color > threshold:\n",
    "                    plines[\"ld_lines\"].append({\"ind\":offset,\"color\":color,\"perc\":perc_color})       \n",
    "                    \n",
    "        b = np.flip(b, axis=1)\n",
    "        for offset in range(-(a.shape[1] - 1), (a.shape[1])):\n",
    "            counts =  np.bincount(b.diagonal(offset=offset))\n",
    "            color = np.argmax(counts)\n",
    "            if color != backg_color:\n",
    "                perc_color = counts[color]/sum(counts)\n",
    "                if perc_color > threshold:\n",
    "                    plines[\"rd_lines\"].append({\"ind\":offset,\"color\":color,\"perc\":perc_color})\n",
    "                           \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return plines\n",
    "\n",
    "# get the number of regions separated by lines (thee lines span the whole grid)\n",
    "# need to pass lines = detect_region_lines(a)\n",
    "def count_lines_regions(lines): \n",
    "    n_regions = (1+len(lines[\"h_lines\"])) * (1+len(lines[\"v_lines\"]))\n",
    "    return n_regions\n",
    "\n",
    "# return the coordinates of all the regions separated by lines\n",
    "# need to pass lines = detect_region_lines(a)\n",
    "def detect_regions(a, lines,random_lines=False):\n",
    "    \n",
    "    b = np.full(a.shape,0)\n",
    "    regions = []\n",
    "    \n",
    "    if random_lines: # arbitrary (but all connected) lines, see task 144\n",
    "        #coords = get_random_lines_coords(a)\n",
    "        #b = fill_holes(b,DUMMY_COLOR,starting_point=(coords[0][0],coords[0][1]))\n",
    "        pass\n",
    "    else: # scenario with only h and v straight lines\n",
    "        for row in lines[\"h_lines\"]:\n",
    "            b[row,:] = DUMMY_COLOR\n",
    "        for col in lines[\"v_lines\"]:\n",
    "            b[:,col] = DUMMY_COLOR\n",
    "     \n",
    "    # fill the regions with dummy colors, then find their coordinates\n",
    "    k = 1\n",
    "    used_dummy_colors = []\n",
    "    for x in range(0,b.shape[0]):\n",
    "        for y in range(0,b.shape[1]):\n",
    "            if (b[x,y]!= DUMMY_COLOR) and (not b[x,y] in used_dummy_colors):\n",
    "                b = fill_holes(b,DUMMY_COLOR + k,starting_point=(x,y))\n",
    "                used_dummy_colors.append(DUMMY_COLOR + k)\n",
    "                k += 1\n",
    "       \n",
    "    for colo in used_dummy_colors:        \n",
    "        regions.append(np.argwhere(b == colo).tolist())\n",
    "    \n",
    "    return regions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 6 4 2 0 1]\n",
      "1\n",
      "0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,1,2,1,1,5,1,3,2,2,1])\n",
    "counts = np.bincount(a)\n",
    "print(counts)\n",
    "print(np.argmax(counts))\n",
    "print(counts[np.argmax(counts)]/sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg = np.array([[0, 1, 3],\n",
    "       [2, 3, 4]])\n",
    "gg.diagonal(offset=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Entity)\n",
      "--- 0.004676103591918945 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Entity)\")\n",
    "\n",
    "# Fundamental Entity (Tensors, Objects, etc). \n",
    "# Contains all Basic Methods acting on Task Samples.\n",
    "class Entity():\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        self.grid = grid\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        self.attributes = {}\n",
    "        \n",
    "        # Color Related\n",
    "        self.attributes[\"unique_colors\"] = get_unique_colors(self.grid)\n",
    "        self.attributes[\"n_unique_colors\"] = len(self.attributes[\"unique_colors\"])\n",
    "        self.attributes[\"n_unique_non_backg_colors\"] = self.attributes[\"n_unique_colors\"] - 1\n",
    "        self.attributes[\"grid_colors_perc\"] = color_percentage(self.grid)\n",
    "        sorted_percs = sorted(self.attributes[\"grid_colors_perc\"].values())\n",
    "        self.attributes[\"max_color_perc\"] = sorted_percs[-1] \n",
    "        try:\n",
    "            self.attributes[\"next_to_max_color_perc\"] = sorted_percs[-2] \n",
    "        except:\n",
    "            self.attributes[\"next_to_max_color_perc\"] = None\n",
    "    \n",
    "        existing_colors = {k: v for k, v in self.attributes[\"grid_colors_perc\"].items() if v > 0}\n",
    "        existing_colors = list(existing_colors.keys())\n",
    "\n",
    "        self.attributes[\"most_common_color\"] = existing_colors[0]\n",
    "        try:\n",
    "            self.attributes[\"second_most_common_color\"] = existing_colors[1]\n",
    "        except:\n",
    "            self.attributes[\"second_most_common_color\"] = None\n",
    "        self.attributes[\"least_common_color\"] = existing_colors[-1]\n",
    "        self.attributes[\"border_color\"] = is_border_monocolor(self.grid)\n",
    "        \n",
    "        # Shape Related\n",
    "        self.attributes[\"grid_shape\"] = self.grid.shape\n",
    "        self.attributes[\"v_shape\"] = self.attributes[\"grid_shape\"][0]\n",
    "        self.attributes[\"h_shape\"] = self.attributes[\"grid_shape\"][1]\n",
    "        if (self.attributes[\"v_shape\"]%2)==0:\n",
    "            self.attributes[\"v_shape_half\"] = self.attributes[\"v_shape\"] // 2\n",
    "        else:\n",
    "            self.attributes[\"v_shape_half\"] = None\n",
    "        if (self.attributes[\"h_shape\"]%2)==0:\n",
    "            self.attributes[\"h_shape_half\"] = self.attributes[\"h_shape\"] // 2\n",
    "        else:\n",
    "            self.attributes[\"h_shape_half\"] = None\n",
    "        if (self.attributes[\"v_shape\"]%2)==0:\n",
    "            self.attributes[\"v_shape_third\"] = self.attributes[\"v_shape\"] // 3\n",
    "        else:\n",
    "            self.attributes[\"v_shape_third\"] = None\n",
    "        if (self.attributes[\"h_shape\"]%2)==0:\n",
    "            self.attributes[\"h_shape_third\"] = self.attributes[\"h_shape\"] // 3 \n",
    "        else:\n",
    "            self.attributes[\"h_shape_third\"] = None\n",
    "        \n",
    "        # Symmetry Related\n",
    "        self.attributes[\"h_symm\"] = horizontal_symmetric(self.grid)\n",
    "        self.attributes[\"v_symm\"] = vertical_symmetric(self.grid)\n",
    "        self.attributes[\"ld_symm\"] = left_diagonal_symmetric(self.grid)\n",
    "        self.attributes[\"rd_symm\"] = right_diagonal_symmetric(self.grid)\n",
    "        \n",
    "        # Object Related\n",
    "        self.attributes[\"top_left_corner\"] = (0,0)\n",
    "        if not self.attributes[\"h_shape_half\"] is None:\n",
    "            self.attributes[\"top_mid_point\"] = (0,self.attributes[\"h_shape_half\"])\n",
    "        else:\n",
    "            self.attributes[\"top_mid_point\"] = None\n",
    "        if not self.attributes[\"v_shape_half\"] is None:\n",
    "            self.attributes[\"left_mid_point\"] = (self.attributes[\"v_shape_half\"],0)\n",
    "        else:\n",
    "            self.attributes[\"left_mid_point\"] = None\n",
    "            \n",
    "        # Lines Related    \n",
    "        self.attributes[\"lines\"] = detect_region_lines(self.grid)\n",
    "        self.attributes[\"slines\"] = detect_simple_lines(self.grid)\n",
    "        self.attributes[\"plines\"] = detect_pseudolines(self.grid,self.attributes[\"most_common_color\"])\n",
    "        \n",
    "        self.attributes[\"n_h_lines\"] = len(self.attributes[\"lines\"][\"h_lines\"])\n",
    "        self.attributes[\"n_v_lines\"] = len(self.attributes[\"lines\"][\"v_lines\"])\n",
    "        self.attributes[\"n_h_slines\"] = len(self.attributes[\"slines\"][\"h_lines\"])\n",
    "        self.attributes[\"n_v_slines\"] = len(self.attributes[\"slines\"][\"v_lines\"])\n",
    "        self.attributes[\"n_h_plines\"] = len(self.attributes[\"plines\"][\"h_lines\"])\n",
    "        self.attributes[\"n_v_plines\"] = len(self.attributes[\"plines\"][\"v_lines\"])\n",
    "        self.attributes[\"n_rd_plines\"] = len(self.attributes[\"plines\"][\"rd_lines\"])\n",
    "        self.attributes[\"n_ld_plines\"] = len(self.attributes[\"plines\"][\"ld_lines\"])\n",
    "        \n",
    "        \n",
    "    \n",
    "class Obj(Entity):\n",
    "    \n",
    "    def __init__(self, parent_grid, obj_coords_in_parent_grid):            \n",
    "        obj_data = matrix_rect(obj_coords_in_parent_grid)  \n",
    "        self.obj_data = obj_data\n",
    "        new_obj = np.full((obj_data[\"x_dim\"], obj_data[\"y_dim\"]), 0) # TODO here 0 should be background color\n",
    "        # the object is always embedded in a rectangolar grid for simplicity\n",
    "        for i in range(obj_data[\"x_dim\"]):\n",
    "            for j in range(obj_data[\"y_dim\"]):\n",
    "                new_obj[i,j] = (parent_grid[obj_data[\"x_min\"] + i, obj_data[\"y_min\"] + j])\n",
    "                \n",
    "        super().__init__(new_obj) # define the entity with the object grid\n",
    "        self.parent_grid = parent_grid\n",
    "        self.coords = obj_coords_in_parent_grid  # these coordinates are exact, so in general it is not a rectangle\n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "        \n",
    "        self.attributes[\"has_hole\"] = False\n",
    "        self.attributes[\"holes_coords_obj\"] = None # coords with respect to the object\n",
    "        self.attributes[\"holes_coords_parent\"] = None # coords with respect to the parent\n",
    "        if len(self.coords) != self.grid.size: \n",
    "            holes_coords = flood_scan(self.grid)\n",
    "            self.attributes[\"has_hole\"] = len(holes_coords) > 0\n",
    "            if self.attributes[\"has_hole\"]:\n",
    "                self.attributes[\"holes_coords_obj\"] = holes_coords\n",
    "                self.attributes[\"holes_coords_parent\"] = [[x + self.obj_data[\"x_min\"],y + self.obj_data[\"y_min\"]] for x,y in holes_coords]\n",
    "                \n",
    "class Region(Entity):\n",
    "    \n",
    "    def __init__(self, parent_grid, reg_coords_in_parent_grid):            \n",
    "        reg_data = matrix_rect(reg_coords_in_parent_grid)   \n",
    "        new_region = np.full((reg_data[\"x_dim\"], reg_data[\"y_dim\"]), 0) \n",
    "        for i in range(reg_data[\"x_dim\"]):\n",
    "            for j in range(reg_data[\"y_dim\"]):\n",
    "                new_region[i,j] = (parent_grid[reg_data[\"x_min\"] + i, reg_data[\"y_min\"] + j])\n",
    "    \n",
    "        super().__init__(new_region) \n",
    "        self.parent_grid = parent_grid\n",
    "        self.coords = reg_coords_in_parent_grid  \n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "        \n",
    "        \n",
    "# Contains Entire Data for Input/Output\n",
    "class Tensor(Entity):\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        super().__init__(grid)\n",
    "        self.objects = []\n",
    "        self.regions = [] \n",
    "        self.layers = [] # TODO\n",
    "        \n",
    "        \n",
    "    # detect objects, layer and regions\n",
    "    def detect_entities(self):\n",
    "        objects_coords = detect_objects(self.grid)\n",
    "        for obj_coords in objects_coords:\n",
    "            self.objects.append(Obj(self.grid,obj_coords))\n",
    "        \n",
    "        regions_coords = detect_regions(self.grid, self.attributes[\"lines\"])\n",
    "        for region_coords in regions_coords:\n",
    "            self.regions.append(Region(self.grid,region_coords))\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        # compute the attributes of the whole grid\n",
    "        super().compute_attributes()  \n",
    "        # find the entities (objects, layer and regions)\n",
    "        self.detect_entities()\n",
    "        \n",
    "        # compute the attributes of the objects in the grid\n",
    "        for obj in self.objects:\n",
    "            obj.compute_attributes()\n",
    "        # compute the attributes of the whole grid referred to entities\n",
    "        self.attributes[\"n_objects\"] = len(self.objects)\n",
    "        \n",
    "        for region in self.regions:\n",
    "            region.compute_attributes()\n",
    "        self.attributes[\"n_regions\"] = len(self.regions)\n",
    "        \n",
    "        self.attributes[\"regions_max_color_perc_in\"] = checkMaxMinAttribute(self.regions,\"max_color_perc\")[\"max_attr\"]\n",
    "        self.attributes[\"regions_max_next_to_max_color_perc_in\"] = checkMaxMinAttribute(self.regions,\"next_to_max_color_perc\")[\"max_attr\"]\n",
    "        \n",
    "            \n",
    "\n",
    "# Fundamental Class for ALL Tasks\n",
    "# Contains all Basic Methods acting on Tasks.\n",
    "class Task():\n",
    "    \n",
    "    def __init__(self, train_data, test_data, LB_submission=False):\n",
    "        \n",
    "        # Lists of Train/Test Tensors\n",
    "        self.train_tensors = [] # Explicitly:  [[t_in_1,t_out_1],[t_in_2,t_out_2],...\n",
    "        self.train_diff = []  # For every in-out pair, difference between in and out attributes\n",
    "        self.common_diff = {} # For all the in-out pairs, common differences (Example: All of the in-out pairs change color)\n",
    "        self.sequences = {} # Sequences or patterns among all the in-out pairs \n",
    "        self.test_tensors = []\n",
    "        self.LB_submission = LB_submission\n",
    "        \n",
    "        # Compute Train Tensors\n",
    "        for t_in, t_out in train_data:\n",
    "            tensor_in = Tensor(t_in)\n",
    "            tensor_out = Tensor(t_out)\n",
    "            list.append(self.train_tensors, [tensor_in, tensor_out])\n",
    "            \n",
    "        # Compute Test Tensors\n",
    "        if self.LB_submission:\n",
    "            for t_in in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                list.append(self.test_tensors, [tensor_in])\n",
    "        else:\n",
    "            for t_in, t_out in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                tensor_out = Tensor(t_out)\n",
    "                list.append(self.test_tensors, [tensor_in, tensor_out])\n",
    "        \n",
    "           \n",
    "    # Compute Task Train Attributes \n",
    "    def compute_train_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            for t in in_out_pair:\n",
    "                t.compute_attributes()\n",
    "    \n",
    "    # Compute Task Test Attributes \n",
    "    def compute_test_attributes(self):\n",
    "        if self.LB_submission:\n",
    "            for t in self.test_tensors:\n",
    "                t[0].compute_attributes()\n",
    "        else:\n",
    "            for in_out_pair in self.test_tensors:\n",
    "                for t in in_out_pair:\n",
    "                    t.compute_attributes()\n",
    "    \n",
    "    # Compute Attribute Differences for every in-out pair\n",
    "    def compute_diff_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            diff = {}\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            \n",
    "            # Color Related\n",
    "            diff[\"color_changed\"] = set(t_in.attributes[\"unique_colors\"]) != set(t_out.attributes[\"unique_colors\"])\n",
    "            diff[\"new_colors\"] = list(set(t_out.attributes[\"unique_colors\"]) - set(t_in.attributes[\"unique_colors\"]))\n",
    "            \n",
    "            keylist = t_in.attributes[\"grid_colors_perc\"].keys()\n",
    "            color_perc_in = np.array([t_in.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            color_perc_out = np.array([t_out.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            diff[\"color_perc_changed\"] = not np.allclose(color_perc_in, color_perc_out)\n",
    "            \n",
    "            diff[\"most_common_color_changed\"] = t_in.attributes[\"most_common_color\"] != t_out.attributes[\"most_common_color\"]\n",
    "            try:\n",
    "                diff[\"second_most_common_color_changed\"] = t_in.attributes[\"second_most_common_color\"] != t_out.attributes[\"second_most_common_color\"]\n",
    "            except:\n",
    "                pass\n",
    "            diff[\"least_common_color_changed\"] = t_in.attributes[\"least_common_color\"] != t_out.attributes[\"least_common_color\"]\n",
    "            \n",
    "            # Shape Related\n",
    "            diff[\"shape_changed\"] = t_in.attributes[\"grid_shape\"] != t_out.attributes[\"grid_shape\"]\n",
    "            diff[\"h_shape_changed\"] = t_in.attributes[\"grid_shape\"][1] != t_out.attributes[\"grid_shape\"][1]\n",
    "            diff[\"v_shape_changed\"] = t_in.attributes[\"grid_shape\"][0] != t_out.attributes[\"grid_shape\"][0]\n",
    "           \n",
    "            \n",
    "            # Symmetry Related\n",
    "            diff[\"h_symm_changed\"] = t_in.attributes[\"h_symm\"] != t_out.attributes[\"h_symm\"]\n",
    "            diff[\"v_symm_changed\"] = t_in.attributes[\"v_symm\"] != t_out.attributes[\"v_symm\"]\n",
    "            diff[\"ld_symm_changed\"] = t_in.attributes[\"ld_symm\"] != t_out.attributes[\"ld_symm\"]\n",
    "            diff[\"rd_symm_changed\"] = t_in.attributes[\"rd_symm\"] != t_out.attributes[\"rd_symm\"]\n",
    "            \n",
    "            # Objects Related\n",
    "            diff[\"n_objects_changed\"] = t_in.attributes[\"n_objects\"] != t_out.attributes[\"n_objects\"]\n",
    "            \n",
    "            # Regions Related\n",
    "            diff[\"n_regions_changed\"] = t_in.attributes[\"n_regions\"] != t_out.attributes[\"n_regions\"]\n",
    "            \n",
    "            # Lines Related\n",
    "            diff[\"n_h_lines_changed\"] = t_in.attributes[\"n_h_lines\"] != t_out.attributes[\"n_h_lines\"]\n",
    "            diff[\"n_v_lines_changed\"] = t_in.attributes[\"n_v_lines\"] != t_out.attributes[\"n_v_lines\"]\n",
    "            diff[\"n_h_slines_changed\"] = t_in.attributes[\"n_h_slines\"] != t_out.attributes[\"n_h_slines\"]\n",
    "            diff[\"n_v_slines_changed\"] = t_in.attributes[\"n_v_slines\"] != t_out.attributes[\"n_v_slines\"]\n",
    "            diff[\"n_h_plines_changed\"] = t_in.attributes[\"n_h_plines\"] != t_out.attributes[\"n_h_plines\"]\n",
    "            diff[\"n_v_plines_changed\"] = t_in.attributes[\"n_v_plines\"] != t_out.attributes[\"n_v_plines\"]\n",
    "            \n",
    "            # Other\n",
    "            diff[\"is_in_in_out\"] = match_template(t_out.grid, t_in.grid)\n",
    "            diff[\"is_out_in_in\"] = match_template(t_in.grid, t_out.grid)\n",
    "            \n",
    "            \n",
    "            list.append(self.train_diff,diff)\n",
    "        \n",
    "    # Find Common Differences in Input/Output Pairs. Return a dict \"diff\":int, such as {'color_changed': -1, 'color_perc_changed': 1, 'shape_changed': 1}.\n",
    "    def find_common_diff(self):\n",
    "        \n",
    "        diffs = self.train_diff[0].keys()\n",
    "        \n",
    "        for k in diffs:\n",
    "            try:\n",
    "                truth_values = []\n",
    "                for i, diff in enumerate(self.train_diff): \n",
    "                    truth_values.append(diff[k])\n",
    "\n",
    "                if all(truth_values): \n",
    "                    self.common_diff[k] = 1 # this difference k is common in all the in-out pairs and it is True.\n",
    "                elif (not all(truth_values)) and (not any(truth_values)):\n",
    "                    self.common_diff[k] = -1 # this difference k is common in all the in-out pairs and it is False.\n",
    "                else:\n",
    "                    self.common_diff[k] = 0 # the difference is not common to all the in-out pairs.\n",
    "            except KeyError as error:\n",
    "                self.common_diff[k] = 0\n",
    "                \n",
    "        \n",
    "    # Find Sequences or patterns in Common Differences or in the outputs. \n",
    "    # For instance a color/shape common to all the outputs.\n",
    "    def find_sequence(self):\n",
    "        \n",
    "        # find which colors do not appear in train input, but appear in all the outputs\n",
    "        common_new_colors = [0,1,2,3,4,5,6,7,8,9]\n",
    "        for in_out_pair in self.train_diff:\n",
    "            common_new_colors = list(set(common_new_colors).intersection(in_out_pair[\"new_colors\"]))\n",
    "        self.sequences[\"common_new_colors\"] = common_new_colors\n",
    "        for i, cnc in enumerate(self.sequences[\"common_new_colors\"]):\n",
    "            self.sequences[\"common_new_colors\" + \"_\" + str(i)] = cnc\n",
    "            \n",
    "        # memorize the shape, if all the output shapes are the same\n",
    "        out_shapes_0 = []\n",
    "        out_shapes_1 = []\n",
    "        in_shapes_0 = []\n",
    "        in_shapes_1 = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            out_shapes_0.append(t_out.grid.shape[0])\n",
    "            out_shapes_1.append(t_out.grid.shape[1])\n",
    "            in_shapes_0.append(t_in.grid.shape[0])\n",
    "            in_shapes_1.append(t_in.grid.shape[1])\n",
    "        self.sequences[\"out_shape_0\"] = -1\n",
    "        self.sequences[\"out_shape_1\"] = -1\n",
    "        if checkEqual1(out_shapes_0):\n",
    "            self.sequences[\"out_shape_0\"] = out_shapes_0[0]\n",
    "        if checkEqual1(out_shapes_1):\n",
    "            self.sequences[\"out_shape_1\"] = out_shapes_1[0]\n",
    "        self.sequences[\"max_in_shape\"] = max(in_shapes_0 + in_shapes_1)\n",
    "        self.sequences[\"min_in_shape\"] = min(in_shapes_0 + in_shapes_1)\n",
    "        self.sequences[\"max_out_shape\"] = max(out_shapes_0 + out_shapes_1)\n",
    "        self.sequences[\"min_out_shape\"] = min(out_shapes_0 + out_shapes_1)\n",
    "        self.sequences[\"prime_in_shape_0\"] = any(is_prime(ele) for ele in in_shapes_0)\n",
    "        self.sequences[\"prime_in_shape_1\"] = any(is_prime(ele) for ele in in_shapes_1)\n",
    "            \n",
    "            \n",
    "         \n",
    "        # check if all the outputs have the same number of colors\n",
    "        n_colors = []\n",
    "        for in_out_pair in task_data.train_tensors:\n",
    "            t_out = in_out_pair[1]\n",
    "            n_colors.append(t_out.attributes[\"n_unique_colors\"])\n",
    "        self.sequences[\"n_colors\"] = 0\n",
    "        if checkEqual1(n_colors):\n",
    "            self.sequences[\"n_colors\"] = n_colors[0]\n",
    "            \n",
    "        # check in and out objects\n",
    "        in_objs = []\n",
    "        out_objs = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_objs.append(t_in.objects)\n",
    "            out_objs.append(t_out.objects)\n",
    "        self.sequences[\"max_n_objects_in\"] = checkMaxMinLen(in_objs)[\"max_len\"]\n",
    "        self.sequences[\"min_n_objects_in\"] = checkMaxMinLen(in_objs)[\"min_len\"]\n",
    "        self.sequences[\"max_n_objects_out\"] = checkMaxMinLen(out_objs)[\"max_len\"]\n",
    "        self.sequences[\"min_n_objects_out\"] = checkMaxMinLen(out_objs)[\"min_len\"]\n",
    "              \n",
    "\n",
    "        \n",
    "        # check in and out regions\n",
    "        in_regions = []\n",
    "        out_regions = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_regions.append(t_in.regions)\n",
    "            out_regions.append(t_out.regions)\n",
    "        self.sequences[\"max_n_regions_in\"] = checkMaxMinLen(in_regions)[\"max_len\"]\n",
    "        self.sequences[\"min_n_regions_in\"] = checkMaxMinLen(in_regions)[\"min_len\"]\n",
    "        self.sequences[\"max_n_regions_out\"] = checkMaxMinLen(out_regions)[\"max_len\"]\n",
    "        self.sequences[\"min_n_regions_out\"] = checkMaxMinLen(out_regions)[\"min_len\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # check in and out color_perc\n",
    "        in_cp = []\n",
    "        out_cp = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_cp.append(t_in.attributes[\"max_color_perc\"])\n",
    "            out_cp.append(t_out.attributes[\"max_color_perc\"])\n",
    "        self.sequences[\"max_max_color_perc_in\"] = max(in_cp)\n",
    "        self.sequences[\"min_max_color_perc_in\"] = min(in_cp)\n",
    "        self.sequences[\"max_max_color_perc_out\"] = max(out_cp)\n",
    "        self.sequences[\"min_max_color_perc_out\"] = min(out_cp)\n",
    "        \n",
    "        # compute order of plines coloring\n",
    "        in_plines = []\n",
    "        out_plines = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            in_cp.append(t_in.attributes[\"plines\"])\n",
    "            out_plines.append(t_out.attributes[\"plines\"])\n",
    "        self.sequences[\"plines_order\"] = compute_fill_order(out_plines)\n",
    "        \n",
    "        # in and out n of s and p lines\n",
    "        n_in_plines = []\n",
    "        n_out_plines = []\n",
    "        n_in_slines = []\n",
    "        n_out_slines = []\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            n_in_plines.append(t_in.attributes[\"n_h_plines\"] + t_in.attributes[\"n_v_plines\"] + t_in.attributes[\"n_rd_plines\"] + t_in.attributes[\"n_ld_plines\"])\n",
    "            n_out_plines.append(t_out.attributes[\"n_h_plines\"] + t_out.attributes[\"n_v_plines\"]+ t_out.attributes[\"n_rd_plines\"] + t_out.attributes[\"n_ld_plines\"])\n",
    "            n_in_slines.append(t_in.attributes[\"n_h_slines\"] + t_in.attributes[\"n_v_slines\"])\n",
    "            n_out_slines.append(t_out.attributes[\"n_h_slines\"] + t_out.attributes[\"n_v_slines\"])\n",
    "        self.sequences[\"max_n_plines_in\"] = max(n_in_plines)\n",
    "        self.sequences[\"min_n_plines_in\"] = min(n_in_plines)\n",
    "        self.sequences[\"max_n_plines_out\"] = max(n_out_plines)\n",
    "        self.sequences[\"min_n_plines_out\"] = min(n_out_plines)\n",
    "        self.sequences[\"max_n_slines_in\"] = max(n_in_slines)\n",
    "        self.sequences[\"min_n_slines_in\"] = min(n_in_slines)\n",
    "        self.sequences[\"max_n_slines_out\"] = max(n_out_slines)\n",
    "        self.sequences[\"min_n_slines_out\"] = min(n_out_slines)\n",
    "        \n",
    "            \n",
    "        \n",
    "                               \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Rotates) ...\n",
      "--- 0.0013320446014404297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Rotates) ...\")\n",
    "\n",
    "# Rotate Image 90 Degrees\n",
    "def rotate_1(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 1, axes=(0,1))\n",
    "\n",
    "# Rotate Image 180 Degrees\n",
    "def rotate_2(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 2, axes=(0,1))\n",
    "\n",
    "# Rotate Image 270 Degrees\n",
    "def rotate_3(a, a_t, task_data, *args):\n",
    "    return np.rot90(a, 3, axes=(0,1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Flips) ...\n",
      "--- 0.0004718303680419922 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Flips) ...\")\n",
    "\n",
    "# Flip Image Along X-Axis\n",
    "def flip_1(a, a_t, task_data, *args):\n",
    "    return np.flip(a, 0)\n",
    "\n",
    "# Flip Image Along Y-Axis\n",
    "def flip_2(a, a_t, task_data, *args):\n",
    "    return np.flip(a, 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Mirrors) ...\n",
      "--- 0.002362966537475586 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Mirrors) ...\")\n",
    "\n",
    "# Mirror Image Along Top Side of Frame\n",
    "def mirror_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=0), a), axis=0)\n",
    "\n",
    "# Mirror Image Along Right Side of Frame\n",
    "def mirror_2(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=1)), axis=1)\n",
    "\n",
    "# Mirror Image Along Bottom Side of Frame\n",
    "def mirror_3(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=0)), axis=0)\n",
    "\n",
    "# Mirror Image Along Left Side of Frame\n",
    "def mirror_4(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=1), a), axis=1)  \n",
    "\n",
    "# Get Transpose of Image\n",
    "def mirror_5(a, a_t, task_data, *args):\n",
    "    return a.T\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.0017108917236328125 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Duplicate Original grid args[0] times vertically and args[1] horizontally\n",
    "def repeat_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.tile(a,(args[0],args[1]))\n",
    "\n",
    "# Repeat the grid, only in correspondents of positions where there are non background colors\n",
    "def repeat_2(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * a.shape[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * a.shape[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    c = np.tile(a, a.shape)\n",
    "    c_mask = a.repeat(a.shape[0], axis=0).repeat(a.shape[1], axis=1)\n",
    "    return c & c_mask\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.00179290771484375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Elastically rescales up grid args[0] times vertically and args[1] horizontally\n",
    "def rescale_1(a, a_t, task_data, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.kron(a, np.ones((args[0],args[1]), dtype=np.uint8)) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Crop) ...\n",
      "--- 0.0014531612396240234 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Crop) ...\")\n",
    "\n",
    "# Crop using the coordinates of a color as a reference.\n",
    "def crop_1(a, a_t, task_data, *args):\n",
    "    color = args[0]\n",
    "    coords = np.argwhere(a==color)\n",
    "    x_min, y_min = coords.min(axis=0)\n",
    "    x_max, y_max = coords.max(axis=0)\n",
    "    return a[x_min:x_max+1, y_min:y_max+1]\n",
    "    \n",
    "# Crop using the top left corner and two dimensions\n",
    "def crop_2(a, a_t, task_data, *args):\n",
    "    shape_v = args[0]\n",
    "    shape_h = args[1]\n",
    "    top_left_coords = args[2]\n",
    "    if ((top_left_coords[0]  + shape_v) > a.shape[0]) or ((top_left_coords[1]  + shape_h) > a.shape[1]):\n",
    "        #print(\"Out of bounds B\", shape_v ,shape_h ,top_left_coords, a.shape[0], a.shape[1])\n",
    "        raise ValueError(\"Out of bounds\")  \n",
    "    return a[top_left_coords[0]:top_left_coords[0]+shape_v, top_left_coords[1]:top_left_coords[1]+shape_h]\n",
    "\n",
    "# Crop the border\n",
    "def crop_3(a, a_t, task_data, *args):\n",
    "    thickness = args[0]\n",
    "    if (thickness==0) or (thickness>a.shape[0]//2) or (thickness>a.shape[1]//2):\n",
    "        raise ValueError(\"Bad thickness\") \n",
    "    return a[thickness:a.shape[0]-thickness, thickness:a.shape[1]-thickness]\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Symmetric) ...\n",
      "--- 0.0011467933654785156 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Symmetric) ...\")\n",
    "\n",
    "# Make Image Symmetric Along X-Axis\n",
    "def symmetric_1(a, a_t, task_data, *args):\n",
    "    b1 = flip_1(a, a_t, task_data, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "# Make Image Symmetric Along Y-Axis\n",
    "def symmetric_2(a, a_t, task_data, *args):\n",
    "    b1 = flip_2(a, a_t, task_data, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Color) ...\n",
      "--- 0.002577066421508789 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Color) ...\")\n",
    "\n",
    "# Substitute Color1 with Color2 (NOT viceversa) \n",
    "def color_1(a, a_t, task_data, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    a[b_first] = color2\n",
    "    return a \n",
    "\n",
    "# Swap Color1 with Color2 and Color2 with Color1\n",
    "def color_2(a, a_t, task_data, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    b_second = a == color2\n",
    "    a[b_first] = color2\n",
    "    a[b_second] = color1\n",
    "    return a\n",
    "\n",
    "# Substitute all colors different from Color1 with Color2 (NOT viceversa) \n",
    "def color_3(a, a_t, task_data, *args):\n",
    "    if (len(get_unique_colors(a)) < 3):\n",
    "        raise ValueError(\"Not enough colors in this grid\")\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a != color1\n",
    "    a[b_first] = color2\n",
    "    return a\n",
    "\n",
    "# Color objects with a given attribute\n",
    "def color_ob(a, a_t, task_data, key ,*args):\n",
    "    new_color = args[0]\n",
    "    objs_to_color = []\n",
    "    for obj in a_t.objects:\n",
    "        if obj.attributes[key]:\n",
    "            objs_to_color.append(obj)\n",
    "            \n",
    "    if (len(objs_to_color) == 0):\n",
    "        raise ValueError(\"No objects to color\")\n",
    "      \n",
    "    for obj in objs_to_color:\n",
    "        a = color_points(a,obj.coords,new_color)\n",
    "    return a\n",
    "\n",
    "# Color objects with holes in them\n",
    "def color_ob_1(a, a_t, task_data, *args):\n",
    "    return color_ob(a, a_t, task_data,\"has_hole\",*args)\n",
    "\n",
    "\n",
    "def color_reg(a, a_t, task_data,*args, key=\"most_common_color\"):\n",
    "    \n",
    "    background_color = args[0]\n",
    "    for region in a_t.regions:\n",
    "        for point in region.coords:\n",
    "            if key in region.attributes:\n",
    "                fill_color = region.attributes[key]\n",
    "            else:\n",
    "                fill_color = background_color\n",
    "            if a[point[0],point[1]] !=fill_color:\n",
    "                a = flood_fill(a, tuple(point),fill_color,connectivity=0)\n",
    "    return a\n",
    "\n",
    "def color_reg_from_condition(a, a_t, task_data,*args, keys=[\"most_common_color\",\"regions_max_next_to_max_color_perc_in\",\"next_to_max_color_perc\"]):\n",
    "    \n",
    "    background_color = args[0]\n",
    "    for region in a_t.regions:\n",
    "        #print(a_t.attributes[\"regions_max_next_to_max_color_perc_in\"],region.attributes[\"next_to_max_color_perc\"])\n",
    "        for point in region.coords:\n",
    "            if np.isclose(a_t.attributes[keys[1]],region.attributes[keys[2]]):\n",
    "                fill_color = region.attributes[keys[0]]\n",
    "            else:\n",
    "                fill_color = background_color\n",
    "            if a[point[0],point[1]] !=fill_color:\n",
    "                    a = flood_fill(a, tuple(point),fill_color,connectivity=0)\n",
    "    return a\n",
    "\n",
    "def color_reg_1(a, a_t, task_data,*args):\n",
    "    return color_reg(a, a_t, task_data,*args, key=\"most_common_color\")\n",
    "def color_reg_2(a, a_t, task_data,*args):\n",
    "    return color_reg(a, a_t, task_data,*args, key=\"second_most_common_color\")\n",
    "def color_reg_3(a, a_t, task_data,*args):\n",
    "    return color_reg(a, a_t, task_data,*args, key=\"least_common_color\")\n",
    "def color_reg_4(a, a_t, task_data,*args):\n",
    "    return color_reg_from_condition(a, a_t, task_data,*args, keys=[\"second_most_common_color\",\"regions_max_next_to_max_color_perc_in\",\"next_to_max_color_perc\"])\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Superpose) ...\n",
      "--- 0.004374027252197266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Superpose) ...\")\n",
    "\n",
    "\n",
    "\n",
    "# superpose all the regions with an operation given by op. Here the regions are just inferred from splicing the grid.\n",
    "def superp(a, a_t, task_data,*args,op=\"AND\",axis=0):\n",
    "    \n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    n_regions = args[2]\n",
    "    if (n_regions > 5):\n",
    "        raise ValueError(\"Too many regions\")\n",
    "    axis = axis #args[3] # 0 or 1\n",
    "    regions = np.split(a,n_regions,axis=axis)\n",
    "    for previous, current in zip(regions, regions[1:]):\n",
    "        if op==\"AND\":\n",
    "            b = np.where((previous !=background_color) & (current !=background_color), new_color, background_color)\n",
    "        if op==\"OR\":\n",
    "            b = np.where((previous !=background_color) | (current !=background_color), new_color, background_color)\n",
    "        if op==\"XOR\":\n",
    "            b = np.where((previous !=background_color) ^ (current !=background_color), new_color, background_color)\n",
    "        if op==\"ADD\":\n",
    "            b =  np.where((previous + current) < 10, previous + current, background_color)\n",
    "    return b\n",
    "\n",
    "def superp_1(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"AND\",axis=0)\n",
    "def superp_2(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"OR\",axis=0)\n",
    "def superp_3(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"XOR\",axis=0)\n",
    "def superp_4(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"ADD\",axis=0)\n",
    "def superp_5(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"AND\",axis=1)\n",
    "def superp_6(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"OR\",axis=1)\n",
    "def superp_7(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"XOR\",axis=1)\n",
    "def superp_8(a, a_t, task_data,*args):\n",
    "    return superp(a, a_t, task_data,*args,op=\"ADD\",axis=1)\n",
    "\n",
    "# superpose all the regions with an operation given by op\n",
    "def superp_reg(a, a_t, task_data,*args, key=None, op=\"AND\"):\n",
    "    \n",
    "    b = black_square\n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    for previous, current in zip(a_t.regions, a_t.regions[1:]):\n",
    "        if not (key is None):\n",
    "            pass\n",
    "        else:\n",
    "            if op==\"AND\":\n",
    "                b = np.where((previous.grid !=background_color) & (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"OR\":\n",
    "                b = np.where((previous.grid !=background_color) | (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"XOR\":\n",
    "                b = np.where((previous.grid !=background_color) ^ (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"ADD\":\n",
    "                b =  np.where((previous.grid + current.grid) < 10, previous.grid + current.grid, background_color)\n",
    "    return b\n",
    "\n",
    "\n",
    "def superp_reg_1(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"AND\")\n",
    "def superp_reg_2(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"OR\")\n",
    "def superp_reg_3(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"XOR\")\n",
    "def superp_reg_4(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"ADD\")\n",
    "        \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Draw) ...\n",
      "--- 0.00146484375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Draw) ...\")\n",
    "\n",
    "# draw a new grid, filling according to key conditions in the regions\n",
    "def draw_reg(a, a_t, task_data,*args, key=\"most_common_color\"):\n",
    "    \n",
    "    lines = a_t.attributes[\"lines\"]\n",
    "    n_h_lines = len(lines[\"h_lines\"])\n",
    "    n_v_lines = len(lines[\"v_lines\"])\n",
    "    \n",
    "    b = np.full((n_h_lines +1, n_v_lines +1),0)\n",
    "    i = 0\n",
    "    for x in range(0,n_h_lines +1):\n",
    "        for y in range(0,n_v_lines +1): \n",
    "            b[x,y] = a_t.regions[i].attributes[key]\n",
    "            i +=1\n",
    "    \n",
    "    return b\n",
    "\n",
    "def draw_reg_1(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"most_common_color\")\n",
    "def draw_reg_2(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"second_most_common_color\")\n",
    "def draw_reg_3(a, a_t, task_data,*args):\n",
    "    return draw_reg(a, a_t, task_data,*args, key=\"least_common_color\")\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Special) ...\n",
      "--- 0.0017011165618896484 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Special) ...\")\n",
    "\n",
    "# create a uniformely colored new grid from scratch\n",
    "def special_1(a, a_t, task_data, *args):\n",
    "    color = args[0]\n",
    "    shape_v = args[1]\n",
    "    shape_h = args[2]\n",
    "    if (color > 9):\n",
    "        raise ValueError(\"Bad color!\")\n",
    "    return np.full((shape_v,shape_h), color, dtype=np.uint8)\n",
    "\n",
    "\n",
    "# fill holes in the objects\n",
    "def special_2(a, a_t, task_data, *args):\n",
    "    \n",
    "    fill_color = args[0]\n",
    "    objs = a_t.objects\n",
    "    if len(objs) == 0:\n",
    "        raise ValueError(\"No Objects!\")\n",
    "    for ob in objs:\n",
    "        if ob.attributes[\"has_hole\"]:\n",
    "            for hole_coord in ob.attributes[\"holes_coords_parent\"]:\n",
    "                if (a[hole_coord[0],hole_coord[1]] != fill_color):\n",
    "                    a = fill_holes(a,fill_color,starting_point=tuple(hole_coord))\n",
    "            \n",
    "    return a       \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine DSL Functions ...\n",
      "DSL_fs_names  ['color_1', 'color_2', 'lines_1', 'lines_2', 'lines_3', 'lines_4', 'lines_5', 'lines_6', 'lines_7', 'lines_8']\n",
      "Total number of functions:  10\n",
      "--- 0.004302263259887695 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Combine DSL Functions ...\")\n",
    "\n",
    "rotate = [rotate_1, rotate_2, rotate_3\n",
    "         ]\n",
    "flip = [flip_1, flip_2\n",
    "       ]\n",
    "mirror = [mirror_1,mirror_2,mirror_3,mirror_4,mirror_5]\n",
    "repeat = [repeat_1, repeat_2]\n",
    "rescale = [rescale_1]\n",
    "crop = [\n",
    "    crop_1, \n",
    "    crop_2, \n",
    "    #crop_3\n",
    "]\n",
    "symmetric = [symmetric_1, symmetric_2]\n",
    "color = [color_1, color_2#, color_3, color_ob_1, color_reg_1, color_reg_2, color_reg_3, color_reg_4\n",
    "        ]\n",
    "\n",
    "superpose = [superp_1, superp_2, superp_3, superp_4,superp_5, superp_6, superp_7, superp_8, superp_reg_1,superp_reg_2,superp_reg_3,superp_reg_4]\n",
    "draw = [draw_reg_1,draw_reg_2,draw_reg_3]\n",
    "lines = [lines_1,lines_2,lines_3,lines_4,lines_5,lines_6,lines_7,lines_8]\n",
    "special = [special_1, special_2]\n",
    "\n",
    "DSL_functions = color + lines#rotate + flip + mirror + repeat + rescale + crop + symmetric + color + superpose + draw + lines + special \n",
    "DSL_fs_names = [f.__name__ for f in DSL_functions]\n",
    "print(\"DSL_fs_names \", DSL_fs_names)\n",
    "print(\"Total number of functions: \", len(DSL_functions))\n",
    "\n",
    "# Return True if the new_function should not compose with the current_functions\n",
    "def forbidden_composition(new_function, current_functions):\n",
    "    \n",
    "    f_names = [f.__name__ for f in current_functions]\n",
    "    new_f_names = [f.__name__ for f in new_function]\n",
    "    forbidden_combos = [\"rescale\", \"repeat\",\"lines\"]\n",
    "    \n",
    "    for keyword in forbidden_combos:\n",
    "        if (keyword in '\\t'.join(new_f_names)) and (keyword in '\\t'.join(f_names)):\n",
    "            return True\n",
    "        \n",
    "    forbidden_duos = [[\"crop_1\",\"crop_2\"],[\"rotate_1\",\"rotate_3\"]]\n",
    "    for duo in forbidden_duos:\n",
    "        if ((duo[0] in '\\t'.join(new_f_names)) and (duo[1] in '\\t'.join(f_names))) or ((duo[1] in '\\t'.join(new_f_names)) and (duo[0] in '\\t'.join(f_names))):\n",
    "            return True\n",
    "        \n",
    "    forbidden_single = [\"flip_1\",\"flip_2\",\"rotate_2\",\"crop_1\",\"crop_2\",\"symmetric_1\",\"symmetric_2\"]\n",
    "    for single in forbidden_single:\n",
    "        if ((single in '\\t'.join(new_f_names)) and (single in '\\t'.join(f_names))):\n",
    "            return True\n",
    "        \n",
    "    functions_that_must_go_first = [\"lines_1\",\"lines_2\",\"lines_3\",\"lines_4\",\"lines_5\",\"lines_6\",\"lines_7\",\"lines_8\",\"color_reg_1\",\"color_reg_2\",\"color_reg_3\",\"color_reg_4\",\"repeat_2\",\"special_2\", \"crop_2\",\"color_ob_1\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\n",
    "                                   \"draw_reg_1\",\"draw_reg_2\",\"draw_reg_3\",\n",
    "                                   \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"]\n",
    "    for keyword in functions_that_must_go_first:\n",
    "        if (keyword in '\\t'.join(new_f_names)):\n",
    "            return True\n",
    "        \n",
    "    functions_that_cannot_go_first = [\"crop_3\"]\n",
    "    \n",
    "    for keyword in functions_that_cannot_go_first:\n",
    "        if (keyword in '\\t'.join(f_names)):\n",
    "            return True\n",
    "      \n",
    "    functions_that_must_go_alone = [\"special_1\",\"color_3\"]\n",
    "    for keyword in functions_that_must_go_alone:\n",
    "        if ((keyword in '\\t'.join(new_f_names)) or (keyword in '\\t'.join(f_names)) ):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Actions ...\n",
      "--- 0.004047870635986328 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Actions ...\")\n",
    "\n",
    "# Return the action is defined by the dict above. Put \"UNDEF\" is the function may or may not change the attribute.\n",
    "# Notice that some \"UNDEF\" actions can actually be defined if we add more info.\n",
    "def get_functions_actions(entity):\n",
    "    \n",
    "    shape = entity.attributes[\"grid_shape\"]\n",
    "    is_a_square =  shape[0] == shape[1]\n",
    "    is_h_symm = entity.attributes[\"h_symm\"]\n",
    "    is_v_symm = entity.attributes[\"v_symm\"]\n",
    "    \n",
    "    go_from_h_symm_to_v_or_viceversa = ((is_h_symm) and (not is_v_symm)) or ((is_v_symm) and (not is_h_symm))\n",
    "    \n",
    "    functions_actions = {\n",
    "    \"rotate_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\": not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":False,\"n_regions_changed\":False,\"n_h_lines_changed\":False,\"n_v_lines_changed\":False,\"n_h_slines_changed\":False,\"n_v_slines_changed\":False,\"n_h_plines_changed\":False,\"n_v_plines_changed\":False}, \n",
    "    \"rotate_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False,\"n_objects_changed\":False,\"n_regions_changed\":False,\"n_h_lines_changed\":False,\"n_v_lines_changed\":False,\"n_h_slines_changed\":False,\"n_v_slines_changed\":False,\"n_h_plines_changed\":False,\"n_v_plines_changed\":False},\n",
    "    \"rotate_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":False,\"n_regions_changed\":False,\"n_h_lines_changed\":False,\"n_v_lines_changed\":False,\"n_h_slines_changed\":False,\"n_v_slines_changed\":False,\"n_h_plines_changed\":False,\"n_v_plines_changed\":False}, \n",
    "    \"flip_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":False,\"n_regions_changed\":False,\"n_h_lines_changed\":False,\"n_v_lines_changed\":False,\"n_h_slines_changed\":False,\"n_v_slines_changed\":False,\"n_h_plines_changed\":False,\"n_v_plines_changed\":False},\n",
    "    \"flip_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":False,\"n_regions_changed\":False,\"n_h_lines_changed\":False,\"n_v_lines_changed\":False,\"n_h_slines_changed\":False,\"n_v_slines_changed\":False,\"n_h_plines_changed\":False,\"n_v_plines_changed\":False},\n",
    "    \"mirror_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"mirror_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"mirror_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"mirror_4\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"mirror_5\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False,\"n_objects_changed\":False,\"n_regions_changed\":False,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"repeat_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"repeat_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"rescale_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":False,\"n_regions_changed\":False,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"crop_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"crop_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"crop_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False,\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"symmetric_1\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":not is_h_symm,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"symmetric_2\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":not is_v_symm,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False,\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_ob_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_reg_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":False,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_reg_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":False,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_reg_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":False,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"color_reg_4\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":False,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_4\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_5\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_6\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_7\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_8\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":True,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":True,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":True,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"superp_reg_4\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":True,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":True,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":True,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":True,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"draw_reg_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":True,\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_1\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_2\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":True,\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_3\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":True,\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_4\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_5\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_6\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_7\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":True,\"n_v_slines_changed\":True,\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"lines_8\":{\"color_changed\":\"UNDEF\",\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"special_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":\"UNDEF\",\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"},\n",
    "    \"special_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\",\"n_objects_changed\":\"UNDEF\",\"n_regions_changed\":\"UNDEF\",\"n_h_lines_changed\":\"UNDEF\",\"n_v_lines_changed\":\"UNDEF\",\"n_h_slines_changed\":\"UNDEF\",\"n_v_slines_changed\":\"UNDEF\",\"n_h_plines_changed\":\"UNDEF\",\"n_v_plines_changed\":\"UNDEF\"}\n",
    "                   }\n",
    "    return functions_actions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Filtering ...\n",
      "--- 0.0021979808807373047 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Filtering ...\")\n",
    "\n",
    "# Filter the functions which will enter the generate loops. Run over all the test_in and take only the functions that are compatible with all the test_in.\n",
    "def function_filter(task_data, fs_names):\n",
    "\n",
    "    test_t_ins = task_data.test_tensors\n",
    "    functions_to_select = fs_names\n",
    "    functions_removed = []\n",
    "    \n",
    "    for t_in in test_t_ins:\n",
    "        \n",
    "        functions_actions = get_functions_actions(t_in[0])\n",
    "        diff = task_data.common_diff\n",
    "        \n",
    "        d1 = [\"color_changed\",\"color_perc_changed\",\"most_common_color_changed\",\"second_most_common_color_changed\",\"least_common_color_changed\",\"shape_changed\",\"h_shape_changed\",\"v_shape_changed\",\"n_objects_changed\",\"n_regions_changed\",\"n_h_lines_changed\",\"n_v_lines_changed\",\"n_h_slines_changed\",\"n_v_slines_changed\",\"n_h_plines_changed\",\"n_v_plines_changed\"]\n",
    "        d2 = [\"new_colors\", \"h_symm_changed\",\"v_symm_changed\",\"ld_symm_changed\",\"rd_symm_changed\",\"is_in_in_out\", \"is_out_in_in\"] \n",
    "        print(\"diff\",diff)\n",
    "        d_final =  [x for x in list(diff.keys()) if x not in d2]\n",
    "\n",
    "        # remove the functions (from the list of all function) which make undesired changes. \n",
    "        for f,v in functions_actions.items():\n",
    "            \n",
    "            for diff_name in d_final:\n",
    "                if diff[diff_name]==-1: # Example: if the task is preserving the color. \n",
    "                    if v[diff_name]==True: # Example: check if the function modifies colors. Explicit ==True check is important here.\n",
    "                        if f in functions_to_select: \n",
    "                            functions_removed.append(f) # Example: If so, remove function which modify colors.\n",
    "         \n",
    "    # if the shape has changed at least once:\n",
    "    if (diff[\"shape_changed\"]!=-1):\n",
    "        functions_removed.extend([\"lines_1\", \"lines_2\",\"lines_3\", \"lines_4\",\"lines_5\", \"lines_6\",\"lines_7\", \"lines_8\",\"color_reg_1\",\"color_reg_2\",\"color_reg_3\",\"color_reg_4\"])\n",
    "   \n",
    "    # if the outputs are not mono-color\n",
    "    if task_data.sequences[\"n_colors\"] ==1:\n",
    "        functions_removed.extend([\"special_2\", \"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "    else:\n",
    "        functions_removed.append(\"special_1\")\n",
    "      \n",
    "    # if out is always in in, the solution is likely crop or similar\n",
    "    if diff[\"is_out_in_in\"]==1:\n",
    "        functions_removed.extend(set(fs_names) - set([\"crop_1\",\"crop_2\",\"crop_3\",\"special_1\"]))\n",
    "        \n",
    "    # if in is very small\n",
    "    if (task_data.sequences[\"max_in_shape\"]<6):\n",
    "        functions_removed.extend([\"lines_2\",\"lines_3\", \"lines_4\",\"lines_5\", \"lines_6\",\"lines_7\", \"lines_8\",\"special_2\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "        \n",
    "    # if out is very small\n",
    "    if (task_data.sequences[\"out_shape_0\"]!=-1) and (task_data.sequences[\"out_shape_0\"]<3) and (task_data.sequences[\"out_shape_1\"]!=-1) and (task_data.sequences[\"out_shape_1\"]<3) :\n",
    "        functions_removed.extend([\"lines_1\",\"lines_2\",\"lines_3\", \"lines_4\",\"lines_5\", \"lines_6\",\"lines_7\", \"lines_8\",\"rescale_1\",\"repeat_1\",\"mirror_1\",\"mirror_2\",\"mirror_3\",\"mirror_4\"])\n",
    "     \n",
    "    # if out is only 1 dim\n",
    "    if (task_data.sequences[\"min_out_shape\"]==1):\n",
    "        functions_removed.extend([\"lines_1\",\"lines_2\",\"lines_3\", \"lines_4\",\"lines_5\", \"lines_6\",\"lines_7\", \"lines_8\",\"special_2\", \"repeat_1\",\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "    \n",
    "    # if out is very large\n",
    "    if (task_data.sequences[\"out_shape_0\"]>13) and (task_data.sequences[\"out_shape_1\"]>13):\n",
    "        functions_removed.extend([\"crop_1\",\"crop_2\",\"special_1\"])\n",
    "        \n",
    "    # if out is bigger than in\n",
    "    if (task_data.sequences[\"min_out_shape\"] > task_data.sequences[\"max_in_shape\"]):\n",
    "        functions_removed.extend([\"special_1\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "        \n",
    "    # if there aren't at least 2 objects in all the inputs\n",
    "    if task_data.sequences[\"min_n_objects_in\"] < 2:\n",
    "        functions_removed.extend([\"color_ob_1\"])\n",
    "        \n",
    "    # if there are many objects in input\n",
    "    if task_data.sequences[\"min_n_objects_in\"] > 3:\n",
    "        functions_removed.extend([\"special_1\", \"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\"])\n",
    "        \n",
    "    # if there aren't at least 2 regions in all the inputs\n",
    "    if task_data.sequences[\"min_n_regions_in\"] < 2:\n",
    "        functions_removed.extend([\"color_reg_1\",\"color_reg_2\",\"color_reg_3\",\"color_reg_4\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\",\"superp_reg_4\",\"draw_reg_1\",\"draw_reg_2\",\"draw_reg_3\"])\n",
    "    else:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "     \n",
    "    # if n_regions changes\n",
    "    if (task_data.sequences[\"min_n_regions_in\"] != task_data.sequences[\"min_n_regions_out\"]) or (task_data.sequences[\"max_n_regions_in\"] != task_data.sequences[\"max_n_regions_out\"]):\n",
    "        functions_removed.extend([\"color_reg_1\",\"color_reg_2\",\"color_reg_3\",\"color_reg_4\"])\n",
    "        \n",
    "    # if the input dimension is not divisible\n",
    "    if task_data.sequences[\"prime_in_shape_0\"]:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_4\"])\n",
    "    if task_data.sequences[\"prime_in_shape_1\"]:\n",
    "        functions_removed.extend([\"superp_5\",\"superp_6\",\"superp_7\",\"superp_8\"])\n",
    "        \n",
    "    # if the input is mainly background\n",
    "    if task_data.sequences[\"min_max_color_perc_in\"] > 0.7:\n",
    "        functions_removed.extend([\"superp_1\",\"superp_2\",\"superp_3\",\"superp_5\",\"superp_6\",\"superp_7\",\"superp_reg_1\",\"superp_reg_2\",\"superp_reg_3\"])\n",
    "    else: \n",
    "        functions_removed.extend([\"lines_2\",\"lines_3\", \"lines_4\",\"lines_5\", \"lines_6\",\"lines_7\", \"lines_8\"])\n",
    "        \n",
    "    # if the number of plines is equal or smaller in the output\n",
    "    if task_data.sequences[\"max_n_plines_out\"] <= task_data.sequences[\"max_n_plines_in\"]:\n",
    "        functions_removed.extend([\"lines_2\",\"lines_3\", \"lines_4\",\"lines_5\", \"lines_6\",\"lines_7\", \"lines_8\"])   # , \"lines_4\",\"lines_5\" , \"lines_8\" to add when including diag lines in the count  \n",
    "        \n",
    "        \n",
    "    print(\"functions removed\", set(functions_removed))\n",
    "    functions_to_select = [item for item in fs_names if item not in functions_removed]\n",
    "    functions_to_select = [func for func in DSL_functions if func.__name__ in functions_to_select] # convert from string to function\n",
    "    return functions_to_select\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic Numbers ...\n",
      "--- 0.004934072494506836 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Magic Numbers ...\")\n",
    "\n",
    "# How many additional arguments every functions is taking, for each kind of argument. The order is important here.\n",
    "fs_argument_structure = {\n",
    "\"rotate_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0}, \n",
    "    \"rotate_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"rotate_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"flip_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"flip_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_4\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"mirror_5\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"repeat_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"repeat_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"rescale_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_2\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":1,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"crop_3\":{\"color_related\":0, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"symmetric_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"symmetric_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_1\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_2\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_3\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_ob_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_reg_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_reg_2\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_reg_3\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"color_reg_4\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_1\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_2\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_3\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_4\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_5\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_6\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_7\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_8\":{\"color_related\":2, \"shape_related\":1,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_1\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_2\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_3\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"superp_reg_4\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"draw_reg_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_4\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_5\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_6\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_7\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"lines_8\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"special_1\":{\"color_related\":1, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0},\n",
    "    \"special_2\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0,\"axis_related\":0}\n",
    "                    }\n",
    "\n",
    "# how many magic arguments this function takes\n",
    "def number_of_magic_arguments(function):\n",
    "    args = fs_argument_structure[function.__name__]\n",
    "    return sum(args.values())\n",
    "\n",
    "# helper to get_magic_numbers from a single tensor. Only color related magic numbers.\n",
    "def get_magic_numbers_color_single(t, magic_numbers_colors):\n",
    "    #colors_perc = t.attributes[\"grid_colors_perc\"] \n",
    "    magic_numbers_colors.append(t.attributes[\"most_common_color\"])\n",
    "    try:\n",
    "        magic_numbers_colors.append(t.attributes[\"second_most_common_color\"])\n",
    "    except:\n",
    "        pass\n",
    "    magic_numbers_colors.append(t.attributes[\"least_common_color\"])\n",
    "    \n",
    "    return magic_numbers_colors \n",
    "\n",
    "# helper\n",
    "def compute_shape_variations(diff,direction, magic_numbers_shape, t_out_shape, t_in_shape): \n",
    "    # append ratios and differences. This is useful for functions like repeat, crop and resize.\n",
    "    if diff:\n",
    "        ratio_1 = t_out_shape[direction]//t_in_shape[direction]\n",
    "        ratio_2 = t_in_shape[direction]//t_out_shape[direction]\n",
    "        diff_1 = t_out_shape[direction]-t_in_shape[direction]\n",
    "        diff_2 = t_in_shape[direction]-t_out_shape[direction]\n",
    "        \n",
    "        if (ratio_1 > 1) and ((t_out_shape[direction]%t_in_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_1)\n",
    "        if (ratio_2 > 1) and ((t_in_shape[direction]%t_out_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_2)\n",
    "        if diff_1 > 0:\n",
    "            magic_numbers_shape.append(diff_1)\n",
    "        if diff_2 > 0:\n",
    "            magic_numbers_shape.append(diff_2)\n",
    "\n",
    "# helper to get_magic_numbers from a pair of tensors. Only shape related magic numbers.\n",
    "def get_magic_numbers_shape_pair(in_out_pair, magic_numbers_shape,task_data,pair_n):\n",
    "    \n",
    "    t_in = in_out_pair[0]\n",
    "    t_out = in_out_pair[1]\n",
    "    MAX_SHAPE_MAGIC_NUMBER = 10\n",
    "    \n",
    "    t_in_shape = t_in.attributes[\"grid_shape\"] \n",
    "    t_out_shape = t_out.attributes[\"grid_shape\"] \n",
    "    \n",
    "    # do not append t_in shapes, as they should not be predictive\n",
    "    magic_numbers_shape.extend([1,2,3,4]) # these are pretty basic shape numbers always worth trying \n",
    "    magic_numbers_shape.append(t_out_shape[0])\n",
    "    magic_numbers_shape.append(t_out_shape[1])\n",
    "    \n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"h_shape_changed\"],0, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"v_shape_changed\"],1, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    \n",
    "    magic_numbers_shape = [mn for mn in magic_numbers_shape if mn <= MAX_SHAPE_MAGIC_NUMBER]\n",
    "    \n",
    "    return magic_numbers_shape \n",
    "\n",
    "# helper to get_magic_numbers from a pair of tensors. Only object related magic numbers.\n",
    "def get_magic_numbers_object_pair(in_out_pair, magic_numbers_object,task_data,pair_n):\n",
    "    positions_of_out_in_in = task_data.train_diff[pair_n][\"is_out_in_in\"]\n",
    "    if (len(positions_of_out_in_in) < 5): # avoid edge cases in with output is just a pixel, repeated a lot of times in input.\n",
    "        magic_numbers_object.extend(positions_of_out_in_in) \n",
    "    return magic_numbers_object \n",
    "\n",
    "# prepare the magic numbers for all the categories. Example: {'color_related': [0, 2, 3, 4, 6, 8], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "def get_magic_numbers(task_data):\n",
    "    \n",
    "    magic_numbers = {\"color_related\":[], \"shape_related\":[],\"regions_related\":[],\"object_related\":[],\"layer_related\":[],\"axis_related\":[]}\n",
    "    \n",
    "    # get magic numbers from train in-out pairs\n",
    "    for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "        magic_numbers[\"shape_related\"] = get_magic_numbers_shape_pair(in_out_pair, magic_numbers[\"shape_related\"],task_data,pair_n)\n",
    "        magic_numbers[\"object_related\"] = get_magic_numbers_object_pair(in_out_pair, magic_numbers[\"object_related\"],task_data,pair_n)\n",
    "        \n",
    "        for color_n, new_color in enumerate(task_data.sequences[\"common_new_colors\"]): \n",
    "            magic_numbers[\"color_related\"].append(new_color)\n",
    "        for t in in_out_pair:         \n",
    "            magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t, magic_numbers[\"color_related\"])\n",
    "       \n",
    "    # get magic numbers from test in samples\n",
    "    for t in task_data.test_tensors:       \n",
    "        magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t[0], magic_numbers[\"color_related\"])    \n",
    "    \n",
    "    \n",
    "    magic_numbers[\"color_related\"] = list(set(magic_numbers[\"color_related\"]))\n",
    "    magic_numbers[\"shape_related\"] = list(set(magic_numbers[\"shape_related\"]))\n",
    "    magic_numbers[\"object_related\"] = list(set(magic_numbers[\"object_related\"]))\n",
    "    #magic_numbers[\"axis_related\"] = [0,1]\n",
    "    return magic_numbers\n",
    "\n",
    "\n",
    "# return all the possible combinations of lists of arguments. For instance, if the function take 2 color_related arguments\n",
    "# and 1 shape_related argument, the function will return a list like: [ [1,2,3], [1,2,4], ... ] with [c1,c2,s1] as ordering.\n",
    "def prepare_magic_arguments(func, magic_numbers):\n",
    "    \n",
    "    func_argument_structure = fs_argument_structure[func.__name__]\n",
    "    magic_args = {'color_related': [], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "    \n",
    "    for x_related,numbers in magic_numbers.items():\n",
    "        if func_argument_structure[x_related] > 0:\n",
    "            # compute all the possible combinations of arguments of the same kind\n",
    "            magic_args[x_related] = list(itertools.product(numbers, repeat=func_argument_structure[x_related]))\n",
    "    \n",
    "    # assemble the arguments of different categories together\n",
    "    magic_args_lists = []\n",
    "    for k,v in magic_args.items():\n",
    "        if len(v) > 0:\n",
    "            magic_args_lists.append(v)\n",
    "    magic_args_mixed = list(itertools.product(*magic_args_lists))\n",
    "    for i in range(len(magic_args_mixed)):\n",
    "        magic_args_mixed[i] = [y for x in magic_args_mixed[i] for y in (x if isinstance(x, tuple) else (x,))]\n",
    "        \n",
    "    if len(magic_args_mixed) > MAX_magic_args_number : # avoid very lengthy computations\n",
    "        return {'color_related': [], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': [], 'axis_related': []}\n",
    "    return magic_args_mixed \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program():\n",
    "    \n",
    "    def __init__(self, functions=[], sim_score=0, acting_on=\"Tensor\", mn=[]):\n",
    "        self.functions = functions # list of functions. The program is the composition of those.\n",
    "        self.sim_score = sim_score # How well the program scores on the expected output.\n",
    "        self.acting_on = acting_on # Is this acting on a Tensor, an Object, a Layer?\n",
    "        self.task_accuracy = 0  # +1 for every time program maps t_in in t_out\n",
    "        self.magic_numbers = mn # list of lists of magic numbers. Every sublist is associated to a function.\n",
    "        self.magic_logic_understood = False\n",
    "        self.logic_num = [] # array which contain strings explaining the logic of the magic numbers\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.functions==other.functions) and (self.magic_numbers==other.magic_numbers) and (self.magic_logic_understood==other.magic_logic_understood) and (self.logic_num==other.logic_num)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(('functions', ','.join(str(v) for v in self.functions),\n",
    "                     'magic_numbers', ','.join(str(v) for v in self.magic_numbers),\n",
    "                     'magic_logic_understood', str(self.magic_logic_understood),\n",
    "                     'logic_num',','.join(str(v) for v in self.logic_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how much the predicted_out coming from entity_in is in line with the expected \n",
    "# attribute differences of the train in-out pairs in task_data.\n",
    "def attributes_similarity(task_data,entity_in,predicted_out_grid, verbose=False):\n",
    "    \n",
    "    sim_score = 0 # sim_score = 1 if the grids are equal\n",
    "    t_in_grid = entity_in.grid\n",
    "    \n",
    "    # slight misuse of the Task object. I'm using it to easily compute \"common_diff\" and \"sequence\" for [entity_in,predicted_out]\n",
    "    train_data = build_trainlist({\"train\":[{\"input\":t_in_grid,\"output\":predicted_out_grid},],})\n",
    "    #print(\"t_in_grid\",t_in_grid)\n",
    "    #print(\"predicted_out_grid\",predicted_out_grid)\n",
    "    t = Task(train_data, train_data)\n",
    "    t.compute_train_attributes()\n",
    "    t.compute_diff_attributes()\n",
    "    t.find_common_diff()\n",
    "    t.find_sequence()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n task_data.common_diff\", task_data.common_diff)\n",
    "        print(\"\\n t.common_diff\", t.common_diff)\n",
    "    \n",
    "    keys_to_exclude = ['color_perc_changed', 'most_common_color_changed', 'second_most_common_color_changed', \n",
    "                       'least_common_color_changed','h_symm_changed', 'v_symm_changed', 'ld_symm_changed',\n",
    "                       'rd_symm_changed', \"is_in_in_out\", \"is_out_in_in\"\n",
    "                       #'color_changed',\n",
    "                       #'new_colors',\n",
    "                       #'shape_changed',\n",
    "                       #\"h_shape_changed\", \"v_shape_changed\"\n",
    "                      ] \n",
    "    \n",
    "    normalisation = 0 # normalise to 1\n",
    "    \n",
    "    for key_diff, value in task_data.common_diff.items():\n",
    "        if (key_diff not in keys_to_exclude) and (task_data.common_diff[key_diff] !=0 ):\n",
    "            normalisation += 1\n",
    "            if (task_data.common_diff[key_diff] == t.common_diff[key_diff]): \n",
    "                sim_score += 1\n",
    "    \n",
    "    return sim_score/normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the programs which do not predict the expected attributes when acting on the test t_in\n",
    "def filter_programs(programs, task_data):\n",
    "    \n",
    "    filtered_trained_similarities = []\n",
    "    # Iterate Through Test Tasks\n",
    "    for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "        t_in = in_out_pair[0]\n",
    "\n",
    "        for prog_ram in programs: \n",
    "            #print(\"prog_ram\",[(x.functions,x.magic_numbers, x.magic_logic_understood) for x in [prog_ram]]) \n",
    "            # make the prediction\n",
    "            pred_generate = t_in.grid\n",
    "            get_magic_numbers_from_logic(prog_ram, t_in, task_data) \n",
    "            \n",
    "            # eliminate all the programs which have undefined magic numbers (the logic is working on the train set, but not on test)\n",
    "            ok_magic_numbers = not None in flatten_rec(prog_ram.magic_numbers)\n",
    "            \n",
    "            for num, func in enumerate(prog_ram.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, func, *prog_ram.magic_numbers[num])\n",
    "\n",
    "            if (pred_generate.size == 0) or (np.array_equal(pred_generate,black_square)):\n",
    "                continue\n",
    "            #print(\"prog_ram\",prog_ram.functions)\n",
    "            #print(\"mns\", prog_ram.magic_numbers)\n",
    "            #print(\"pred_generate\", pred_generate)\n",
    "            #print(\"t_in\", t_in.grid)\n",
    "            at_s = 1.0\n",
    "            if I_AM_IN_KAGGLE and (not DEBUG):\n",
    "                # TODO speedup\n",
    "                pass\n",
    "                #at_s = attributes_similarity(task_data,t_in,pred_generate)#, verbose=True)\n",
    "            #print(\"at_s\",at_s)\n",
    "                 \n",
    "            if np.isclose(at_s, 1.0) and ok_magic_numbers:   # the program satisfies all the expected attributes     \n",
    "                filtered_trained_similarities.append(prog_ram)\n",
    "                \n",
    "    return filtered_trained_similarities \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Programs...\n",
      "--- 0.0014660358428955078 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Programs...\")\n",
    "        \n",
    "def pred_wrapper(grid, t, task_data, func, *magic_args):\n",
    "    grid_copy = grid.copy()\n",
    "    if DEBUG:\n",
    "        try:\n",
    "            return func(grid_copy, t, task_data, *magic_args)\n",
    "        except Exception as error:\n",
    "            return black_square\n",
    "    else:\n",
    "        try:\n",
    "            return func(grid_copy, t, task_data, *magic_args)\n",
    "        except:\n",
    "            return black_square\n",
    "        \n",
    "def get_sim_score(pred, reference):\n",
    "    if np.array_equal(pred, reference):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "# generate a candidate program\n",
    "def generate_programs(task_data):\n",
    "    \n",
    "    n_train_pairs = len(task_data.train_tensors)\n",
    "    max_solution_length = 2\n",
    "    \n",
    "    # compute attributes\n",
    "    task_data.compute_train_attributes()\n",
    "    task_data.compute_test_attributes()\n",
    "    task_data.compute_diff_attributes()\n",
    "    task_data.find_common_diff()\n",
    "    task_data.find_sequence()\n",
    "    \n",
    "    magic_numbers = get_magic_numbers(task_data)\n",
    "    \n",
    "    # candidate functions which when combined could deliver the correct solution program.\n",
    "    pred_functions = function_filter(task_data, DSL_fs_names)  \n",
    "    #print(\"pred_functions\", pred_functions)\n",
    "    \n",
    "    for in_out_pair in task_data.train_tensors:\n",
    "        t_in = in_out_pair[0]\n",
    "        t_out = in_out_pair[1]\n",
    "        \n",
    "        pred_similarities = []\n",
    "        for pred_func in pred_functions:\n",
    "            # run over all magic arguments\n",
    "            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "            for mn in magic_args:\n",
    "                # evaluate all the pred_functions on the t_in Tensor and keep track of their score\n",
    "                pred_generate = pred_wrapper(t_in.grid, t_in, task_data, pred_func, *mn)\n",
    "                sim_score = get_sim_score(pred_generate, t_out.grid)\n",
    "                list.append(pred_similarities,Program([pred_func],sim_score,\"Tensor\",[mn]))    \n",
    "            \n",
    "        \n",
    "        # keep the first n best scoring programs \n",
    "        n = len(pred_similarities)  \n",
    "        pred_similarities = sorted(pred_similarities, key=lambda x: x.sim_score, reverse=True)[:n]\n",
    "        trained_similarities = []\n",
    "        \n",
    "        \n",
    "        prediction_flags = [True] * len(pred_similarities) # flag if keep searching to update the function. \n",
    "        \n",
    "        # print(\"Seek Better Solution...\")\n",
    "        for j, program in enumerate(pred_similarities):\n",
    "            \n",
    "            current_prog = [program]\n",
    "            # If False, No Better program, store the program as it is now.\n",
    "            while prediction_flags[j] == True:\n",
    "                        \n",
    "                current_pred_func = None\n",
    "                current_pred_magic_numbers = None\n",
    "                new_current_prog = []\n",
    "                updated_flag = [False] * len(current_prog) # flag if the functions are being updated\n",
    "                \n",
    "                for k, prog in enumerate(current_prog):\n",
    "                    \n",
    "                                           \n",
    "                    # if the chains of functions is longer than allowed, add it to the functions to select\n",
    "                    if (len(prog.functions) >= max_solution_length):\n",
    "                        list.append(trained_similarities, prog)\n",
    "                        continue \n",
    "                        \n",
    "                    # compose the program\n",
    "                    pred_generate = t_in.grid \n",
    "                    for num, pred_func in enumerate(prog.functions):\n",
    "                        pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *prog.magic_numbers[num]) # function composition\n",
    "                    task_sim_score = get_sim_score(pred_generate.copy(), t_out.grid)\n",
    "                    current_pred_func = prog.functions\n",
    "                    current_pred_magic_numbers = prog.magic_numbers\n",
    "                    \n",
    "                                    \n",
    "                    look_for_updates = True  # Just put False if debugging\n",
    "                    if look_for_updates:\n",
    "                        updated_similarities = []\n",
    "\n",
    "                        # Iterate over all the functions to generate a new composite function\n",
    "                        for pred_func in pred_functions:\n",
    "                            if forbidden_composition([pred_func], current_pred_func): # skip this function, if composition is forbidden\n",
    "                                continue\n",
    "                            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "                            for mn in magic_args:\n",
    "                                pred_func_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *mn)\n",
    "                                task_sim_score = get_sim_score(pred_func_generate, t_out.grid)\n",
    "                                list.append(updated_similarities,Program([pred_func],task_sim_score,\"Tensor\",[mn]))\n",
    "\n",
    "                        \n",
    "                        # check if the new composite function scores better than the current_pred_func\n",
    "                        for p in updated_similarities:\n",
    "                            if forbidden_composition(p.functions, current_pred_func): # skip this function, if composition is forbidden\n",
    "                                continue\n",
    "                            if prog.sim_score == 1:\n",
    "                                improvement_threshold = 0 # DEBUG Normally this should be positive! \n",
    "                            else:\n",
    "                                improvement_threshold = -0.1 # DEBUG Normally this should be positive! (assuming max(score)= 1)\n",
    "                            if (p.sim_score > prog.sim_score + improvement_threshold): \n",
    "                                # the function have been improved! Now it will over the whole process again, to see if it can be improved further.\n",
    "                                \n",
    "                                new_current_prog.append(Program(current_pred_func + p.functions ,p.sim_score,\"Tensor\",current_pred_magic_numbers +p.magic_numbers)) \n",
    "                                if not updated_flag[k]:\n",
    "                                    updated_flag[k] = True     # at least one new function has been generated\n",
    "                            else:\n",
    "                                pass\n",
    "                  \n",
    "                    # the functions cannot be improved further (at least not with 1 step), add it to the functions to select\n",
    "                    if not updated_flag[k]: # no updates\n",
    "                        list.append(trained_similarities, prog)\n",
    "                \n",
    "                \n",
    "                #print(\"current_prog loop end\")\n",
    "                #print(\"...\")\n",
    "                current_prog = new_current_prog\n",
    "                \n",
    "                if len(current_prog)==0:\n",
    "                    prediction_flags[j] = False \n",
    "            #print(\"End prediction_flags[j] == True while loop\")\n",
    "            #print(\"-----------\")\n",
    "          \n",
    "        #print(\"End pred_similarities for loop\")\n",
    "        #print(\"-----------\")       \n",
    "        #print(\"trained_similarities\",[(x.functions,x.magic_numbers) for x in trained_similarities])\n",
    "        \n",
    "        return trained_similarities\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the programs which predict the same magic numbers on the test\n",
    "def filter_programs_with_same_magic_numbers(programs, task_data):\n",
    "    \n",
    "    ok_programs = []\n",
    "    ok_magic_numbers = []\n",
    "    n_programs = 3\n",
    "    \n",
    "    # Iterate Through Test Tasks\n",
    "    for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "        t_in = in_out_pair[0]\n",
    "\n",
    "        for prog_ram in programs: \n",
    "            \n",
    "            # stop if we find 3 different programs\n",
    "            if len(ok_programs) == n_programs:\n",
    "                return ok_programs\n",
    "            \n",
    "            get_magic_numbers_from_logic(prog_ram, t_in, task_data) \n",
    "            \n",
    "            mns_are_duplicate = False\n",
    "            for mns in ok_magic_numbers:\n",
    "                if (mns == prog_ram.magic_numbers):\n",
    "                    mns_are_duplicate = True\n",
    "                    break\n",
    "            if not mns_are_duplicate:\n",
    "                ok_magic_numbers.append(prog_ram.magic_numbers)\n",
    "                ok_programs.append(prog_ram)\n",
    "                \n",
    "    return ok_programs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Program ...\n",
      "--- 0.0018308162689208984 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Select Program ...\")\n",
    "\n",
    "def select_programs(task_data, generated_programs):\n",
    "    \n",
    "    programs_without_logic = [] # when a program has a logic, add also a copy program without logic\n",
    "    programs_with_alternative_logic = [] # if the program has multiple valid logic, generate different programs from all the logic combinations\n",
    "    \n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(generated_programs):\n",
    "        program.task_accuracy = 0\n",
    "        logic_understood = []  # list of bools\n",
    "        logic_nums = [] # list of list of strings, containing the logic associated to the respective magic numbers\n",
    "    \n",
    "        # Iterate Through Train Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "        \n",
    "            pred_generate = t_in.grid\n",
    "            # predict\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "                             \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid):\n",
    "                program.task_accuracy += 1\n",
    "                \n",
    "                # check if the magic numbers follow a logic\n",
    "                program.logic_num = [-1] * len(program.functions) # -1 is a flag for bad outcome\n",
    "                for num, pred_func in enumerate(program.functions):\n",
    "                    program.logic_num[num] = [[] for _ in program.magic_numbers[num]] # define a list [[],[],[],...] https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "                    \n",
    "                    for j, n in enumerate(program.magic_numbers[num]):\n",
    "                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"color_related\"] > 0:\n",
    "                            # logic coming from a single grid\n",
    "                            if t_in.attributes[\"most_common_color\"] == n:\n",
    "                                program.logic_num[num][j].append(\"most_common_color\")\n",
    "                            if (\"second_most_common_color\" in t_in.attributes) and (t_in.attributes[\"second_most_common_color\"] == n):\n",
    "                                program.logic_num[num][j].append(\"second_most_common_color\")\n",
    "                            if t_in.attributes[\"least_common_color\"] == n:\n",
    "                                program.logic_num[num][j].append(\"least_common_color\")\n",
    "                            #if t_in.attributes[\"border_color\"] == n:\n",
    "                            #    program.logic_num[num][j].append(\"border_color\")                \n",
    "                            # logic coming from all the in-out train pairs\n",
    "                            for i, cnc in enumerate(task_data.sequences[\"common_new_colors\"]):\n",
    "                                if cnc == n:\n",
    "                                    program.logic_num[num][j].append(\"common_new_colors\" + \"_\" + str(i))\n",
    "                                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"shape_related\"] > 0:\n",
    "                            if (\"out_shape_0\" in task_data.sequences) and (task_data.sequences[\"out_shape_0\"] == n):\n",
    "                                program.logic_num[num][j].append(\"out_shape_0\")\n",
    "                            if (\"out_shape_1\" in task_data.sequences) and (task_data.sequences[\"out_shape_1\"] == n):\n",
    "                                program.logic_num[num][j].append(\"out_shape_1\")\n",
    "                            if t_in.attributes[\"v_shape\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape\")\n",
    "                            if t_in.attributes[\"h_shape\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape\")\n",
    "                            if t_in.attributes[\"v_shape_half\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape_half\")\n",
    "                            if t_in.attributes[\"h_shape_half\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape_half\")\n",
    "                            if t_in.attributes[\"v_shape_third\"] == n:\n",
    "                                program.logic_num[num][j].append(\"v_shape_third\")\n",
    "                            if t_in.attributes[\"h_shape_third\"] == n:\n",
    "                                program.logic_num[num][j].append(\"h_shape_third\")\n",
    "                            if t_in.attributes[\"n_unique_colors\"] == n:\n",
    "                                program.logic_num[num][j].append(\"n_unique_colors\")\n",
    "                            if t_in.attributes[\"n_unique_non_backg_colors\"] == n:\n",
    "                                program.logic_num[num][j].append(\"n_unique_non_backg_colors\")\n",
    "                                \n",
    "                        if fs_argument_structure[pred_func.__name__][\"object_related\"] > 0:\n",
    "                            if t_in.attributes[\"top_left_corner\"] == n:\n",
    "                                program.logic_num[num][j].append(\"top_left_corner\")\n",
    "                            if t_in.attributes[\"top_mid_point\"] == n:\n",
    "                                program.logic_num[num][j].append(\"top_mid_point\")\n",
    "                            if t_in.attributes[\"left_mid_point\"] == n:\n",
    "                                program.logic_num[num][j].append(\"left_mid_point\")\n",
    "                        \n",
    "                        program.logic_num[num][j] = list(set(program.logic_num[num][j]))\n",
    "                        \n",
    "                # if all the numbers are recognized in some attribute, then we undestood the logic of the task (at least regarding magic numbers)\n",
    "                log_und = []\n",
    "                for k, logi in enumerate(program.logic_num):\n",
    "                    if (len(logi) == 0) and (number_of_magic_arguments(program.functions[k]) > 0):\n",
    "                        log_und.append(False)\n",
    "                    # handle the case in which the function takes no magic arguments\n",
    "                    elif (len(logi) == 0) and (number_of_magic_arguments(program.functions[k]) == 0):\n",
    "                        log_und.append(\"No Logic by default\")\n",
    "                \n",
    "                if not all(log_und):\n",
    "                    log_und = False\n",
    "                elif ((\"No Logic by default\" in log_und) and (all(log_und))):\n",
    "                    log_und = True\n",
    "                else:\n",
    "                    log_und = True\n",
    "                        \n",
    "                    \n",
    "                logic_understood.append(log_und)\n",
    "                logic_nums.append(program.logic_num)\n",
    "         \n",
    "        # END OF INPUT_OUTPUT PAIRS LOOP\n",
    "               \n",
    "        #print(\"program.functions\",program.functions) \n",
    "        #print(\"program.logic_num\",program.logic_num) \n",
    "        #print(\"program.logic_nums\",logic_nums) \n",
    "        \n",
    "        # generate programs with the combinations of all the logics\n",
    "        mns_fs = []*len(program.functions)\n",
    "        for lnms in program.logic_num: # iterate over the logic_num for each function\n",
    "            mns_fs.append([list(elem) for elem in list(itertools.product(*lnms))] ) \n",
    "        mns_fs = [list(elem) for elem in list(itertools.product(*mns_fs))]\n",
    "\n",
    "        for el in mns_fs:\n",
    "            prog_with_alternative_logic = copy.deepcopy(program)\n",
    "            prog_with_alternative_logic.logic_num = el  \n",
    "            prog_with_alternative_logic.magic_logic_understood = all(logic_understood) and (len(logic_understood)> 0)\n",
    "            #print(\"logic_understood\",logic_understood, el)\n",
    "            #print(\"prog_with_alternative_logic.magic_logic_understood\",prog_with_alternative_logic.magic_logic_understood, el)\n",
    "            for logi in el:\n",
    "                for ll in logi:\n",
    "                    # check that the logic appears in all the input-output pairs\n",
    "                    if not (all( ll in flatten_rec(sublist) for sublist in logic_nums)) : # this is not totally correct, as ll could be in the wrong nested list of sublist. So this check is too permissive.\n",
    "                        prog_with_alternative_logic.magic_logic_understood = False\n",
    "            if prog_with_alternative_logic.magic_logic_understood:\n",
    "                programs_with_alternative_logic.append(prog_with_alternative_logic)\n",
    "         \n",
    "        # append also a program without logic, it may actually solve the task!\n",
    "        prog_without_logic = program # this modifies the original program, as it is not deepcopied\n",
    "        prog_without_logic.logic_num = []\n",
    "        prog_without_logic.magic_logic_understood = False\n",
    "        programs_without_logic.append(prog_without_logic)\n",
    "        \n",
    "    \n",
    "    generated_programs.extend(programs_without_logic)\n",
    "    generated_programs.extend(programs_with_alternative_logic)\n",
    "    \n",
    "    # filter by requiring the prediction to have the expected attributes and that magic numbers are not None on test\n",
    "    generated_programs = filter_programs(generated_programs, task_data)\n",
    "    \n",
    "    # Select Best 3 Solutions\n",
    "    best_programs = list(set(generated_programs)) # remove duplicates\n",
    "    best_programs = sorted(best_programs, key=lambda x: x.magic_logic_understood, reverse=True) # give priority to programs which understood the logic\n",
    "    best_programs = sorted(best_programs, key=lambda x: len(x.functions), reverse=False) # give priority to short programs\n",
    "    best_programs = sorted(best_programs, key=lambda x: x.task_accuracy, reverse=True)\n",
    "    #print(\"best_programs sorted\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs])\n",
    "    best_programs = best_programs[:20]\n",
    "    #best_programs = filter_programs(best_programs, task_data)\n",
    "    best_programs = filter_programs_with_same_magic_numbers(best_programs, task_data)\n",
    "    print(\"best_programs filtered\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs]) \n",
    "    return best_programs\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the logic has been understood from the in-out pairs, use this logic to generate the magic numbers\n",
    "# which will solve the test prediction\n",
    "def get_magic_numbers_from_logic(program, t_in, task_data):\n",
    "    \n",
    "    if program.magic_logic_understood:\n",
    "        for num, logic_n in enumerate(program.logic_num):\n",
    "            for l,logic in enumerate(logic_n):\n",
    "                if logic in t_in.attributes: # logic coming from a single grid\n",
    "                    program.magic_numbers[num][l] = t_in.attributes[logic]\n",
    "                if logic in task_data.sequences: # logic coming from all the in-out train pairs\n",
    "                    program.magic_numbers[num][l] = task_data.sequences[logic] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Program Application Framework ...\n",
      "--- 0.0019350051879882812 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Program Application Framework ...\")\n",
    "\n",
    "# apply on the test tasks\n",
    "def compute_test_accuracy(task_n, task_data, best_programs):\n",
    "\n",
    "    # Initialize Local Variables\n",
    "    output_test = 0\n",
    "    good_programs = []\n",
    "    good_logics = []\n",
    "    num_test = len(task_data.test_tensors)\n",
    "\n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(best_programs):\n",
    "        program.task_accuracy = 0\n",
    "\n",
    "        # Iterate Through Test Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "\n",
    "            pred_generate = t_in.grid\n",
    "            \n",
    "            # build magic numbers from the logic\n",
    "            get_magic_numbers_from_logic(program, t_in, task_data)                       \n",
    "            \n",
    "            # make the prediction\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "            \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid): \n",
    "                program.task_accuracy += 1\n",
    "\n",
    "        if program.task_accuracy >= 1:\n",
    "            good_programs.append(program.functions)\n",
    "            good_logics.append(program.logic_num)\n",
    "            output_test += 1\n",
    "         \n",
    "        # Print Log of Task, Program, Accuracy, Percentage Accurate\n",
    "        percent_accuracy = np.round((program.task_accuracy / num_test * 100), 2)\n",
    "        print(\"(Test:{}.{:02d})-(Program:{}, MNs:{}, logic:{})- Acc:{}/{}\".format(\n",
    "            task_n, i, [f.__name__ for f in program.functions], [mn for mn in program.magic_numbers], program.logic_num, program.task_accuracy, num_test))\n",
    "\n",
    "    # Return Accuracy\n",
    "    output_test = int(output_test >= 1)\n",
    "    return {\"accuracy\":output_test,\"good_programs\":[[f.__name__ for f in fs] for fs in good_programs],\"logic\":good_logics}\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Program Submission Framework ...\n",
      "--- 0.0007619857788085938 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Program Submission Framework ...\")\n",
    "\n",
    "def submit_program_to_LB(task_data, selected_programs):\n",
    "\n",
    "    # Initialize Local Variables\n",
    "    output_data = \"\"    \n",
    "    \n",
    "    # Iterate Through Selected Programs\n",
    "    for i, program in enumerate(selected_programs):\n",
    "\n",
    "        # Iterate Through Test Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            \n",
    "            pred_generate = t_in.grid\n",
    "            \n",
    "            # build magic numbers from the logic\n",
    "            get_magic_numbers_from_logic(program, t_in, task_data)                       \n",
    "            \n",
    "            # make the prediction\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), t_in, task_data, pred_func, *program.magic_numbers[num])\n",
    "    \n",
    "            # Format Output Data as String\n",
    "            output_data += (flattener(pred_generate) + ' ')\n",
    "    \n",
    "    # Return Output\n",
    "    return output_data\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Training Set) ...\n",
      "Generating Program for Task 140\n",
      "diff {'color_changed': -1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': -1, 'second_most_common_color_changed': -1, 'least_common_color_changed': -1, 'shape_changed': -1, 'h_shape_changed': -1, 'v_shape_changed': -1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'n_objects_changed': -1, 'n_regions_changed': -1, 'n_h_lines_changed': 1, 'n_v_lines_changed': 1, 'n_h_slines_changed': 1, 'n_v_slines_changed': 1, 'n_h_plines_changed': -1, 'n_v_plines_changed': -1, 'is_in_in_out': -1, 'is_out_in_in': -1}\n",
      "functions removed {'draw_reg_3', 'superp_reg_2', 'superp_reg_4', 'superp_1', 'color_reg_3', 'color_1', 'superp_3', 'color_2', 'color_reg_2', 'superp_6', 'superp_5', 'draw_reg_1', 'superp_7', 'superp_2', 'superp_reg_1', 'superp_8', 'superp_4', 'superp_reg_3', 'color_reg_1', 'special_1', 'draw_reg_2', 'color_ob_1', 'color_reg_4'}\n",
      "best_programs filtered [([<function lines_8 at 0x129fc6950>], [[6]], 1, True, [['least_common_color']]), ([<function lines_8 at 0x129fc6950>], [[7]], 1, False, []), ([<function lines_8 at 0x129fc6950>], [[8]], 1, False, [])]\n",
      "(Test:140.00)-(Program:['lines_8'], MNs:[[6]], logic:[['least_common_color']])- Acc:1/1\n",
      "(Test:140.01)-(Program:['lines_8'], MNs:[[7]], logic:[])- Acc:0/1\n",
      "(Test:140.02)-(Program:['lines_8'], MNs:[[8]], logic:[])- Acc:0/1\n",
      "Generation Took 0.8820428848266602 Seconds\n",
      "Training Set - Final Accuracy: 1 / 1 \n",
      " Training Set - Accurate Tasks: [140] \n",
      " --------------------\n",
      "--- 0.8840479850769043 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Training Set) ...\")\n",
    "\n",
    "accuracy_full = 0\n",
    "accuracy_tasks = []\n",
    "detailed_accuracy_tasks = []\n",
    "slow_tasks = []\n",
    "training_flag = True \n",
    "start=140\n",
    "finish=start+1\n",
    "if (training_flag == True) and DEBUG:\n",
    "    for task_n in range(start,finish):\n",
    "        task_time = time.time()\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        accuracy = []\n",
    "        \n",
    "        train_data = build_trainlist(train_task_data[task_n])\n",
    "        test_data = build_testlist(train_task_data[task_n])\n",
    "        task_data = Task(train_data, test_data)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        res = compute_test_accuracy(task_n, task_data, best_programs)\n",
    "        \n",
    "        time_spent = time.time() - task_time\n",
    "        print(\"Generation Took %s Seconds\" % (time_spent))\n",
    "        accuracy_full += res[\"accuracy\"]\n",
    "\n",
    "        if res[\"accuracy\"] >= 1:\n",
    "            list.append(accuracy_tasks, task_n)\n",
    "            list.append(detailed_accuracy_tasks, [task_n,res[\"good_programs\"],res[\"logic\"]])\n",
    "    \n",
    "        if time_spent > 60:\n",
    "            slow_tasks.append([task_n,time_spent])\n",
    "            \n",
    "        report_0 = \"Training Set - Final Accuracy: {} / {}\".format(accuracy_full, finish-start)\n",
    "        report_1 = \"Training Set - Accurate Tasks: {}\".format(accuracy_tasks)\n",
    "        report_2 = \"Training Set - Detailed Accurate Tasks: {}\".format(detailed_accuracy_tasks)\n",
    "        report_slow = \"Training Set - Slow Tasks: {}\".format(slow_tasks)\n",
    "        print(report_0, \"\\n\", report_1, \"\\n\", \"--------------------\" )\n",
    "        final_report = report_0 + \" \\n \" + report_1 + \" \\n \" + report_2 + \" \\n \" + report_slow + \" \\n \" + str(time.time() - start_time) + \" seconds\"\n",
    "        if (((task_n%50==0) or (task_n==finish-start-1)) and (task_n!=0)) and DEBUG:\n",
    "            if DEBUG and I_AM_IN_KAGGLE:\n",
    "                send_slack_report(final_report)\n",
    "            \n",
    "if DEBUG and I_AM_IN_KAGGLE:\n",
    "    send_slack_report(final_report)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Evaluation Set) ...\n",
      "--- 0.0014269351959228516 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Evaluation Set) ...\")\n",
    "\n",
    "accuracy_full = 0\n",
    "accuracy_tasks = []\n",
    "detailted_accuracy_tasks = []\n",
    "evaluation_flag = False\n",
    "start=42#0\n",
    "finish=43 #400\n",
    "if evaluation_flag == True:\n",
    "    for task_n in range(start,finish):\n",
    "        task_time = time.time()\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        accuracy = []\n",
    "        \n",
    "        train_data = build_trainlist(eval_task_data[task_n])\n",
    "        test_data = build_testlist(eval_task_data[task_n])\n",
    "        task_data = Task(train_data, test_data)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        res = compute_test_accuracy(task_n, task_data, best_programs)\n",
    "        \n",
    "        print(\"Generation Took %s Seconds\" % (time.time() - task_time))\n",
    "        accuracy_full += res[\"accuracy\"]\n",
    "\n",
    "        if res[\"accuracy\"] >= 1:\n",
    "            list.append(accuracy_tasks, task_n)\n",
    "            list.append(detailted_accuracy_tasks, [task_n,res[\"good_programs\"],res[\"logic\"]])\n",
    "            \n",
    "        report_0 = \"Evaluation Set - Final Accuracy: {} / {}\".format(accuracy_full, finish-start)\n",
    "        report_1 = \"Evaluation Set - Accurate Tasks: {}\".format(accuracy_tasks)\n",
    "        report_2 = \"Evaluation Set - Detailed Accurate Tasks: {}\".format(detailted_accuracy_tasks)\n",
    "        print(report_0, \"\\n\", report_1, \"\\n\", \"--------------------\" )\n",
    "        final_report = report_0 + \" \\n \" + report_1 + \" \\n \" + report_2 + \" \\n \" + str(time.time() - start_time) + \" seconds\"\n",
    "        if (((task_n%50==0) or (task_n==finish-start-1)) and (task_n!=0)) and DEBUG:\n",
    "            #send_slack_report(final_report)\n",
    "            pass\n",
    "            \n",
    "if DEBUG:\n",
    "    #send_slack_report(final_report)\n",
    "    pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Submission to LB) ...\n",
      "\n",
      "\n",
      "--- 0.0010249614715576172 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Submission to LB) ...\\n\")\n",
    "\n",
    "task_n = 0\n",
    "submit_to_LB_flag = I_AM_IN_KAGGLE and (not DEBUG)\n",
    "if submit_to_LB_flag == True:\n",
    "    for output_id in submission.index:\n",
    "\n",
    "        task_id = output_id.split('_')[0]\n",
    "        pair_id = int(output_id.split('_')[1])\n",
    "        if pair_id == 1:\n",
    "            task_n -= 1 # there are 100 tasks, but 4 of them have a second version with pair_id = 1 instead of = 0.\n",
    "        f = str(testing_path / str(task_id + '.json'))\n",
    "        with open(f, 'r') as read_file:\n",
    "            task = json.load(read_file)\n",
    "\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        train_data = build_trainlist(test_task_data[task_n])\n",
    "        test_data = build_testlist(test_task_data[task_n], LB_submission=True, pair_id=pair_id)\n",
    "        task_data = Task(train_data, test_data, LB_submission=True)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        program_data = submit_program_to_LB(task_data, best_programs)\n",
    "        submission.loc[output_id, 'output'] = program_data \n",
    "        task_n += 1\n",
    "        print(\"-------\")\n",
    "    \n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Submission to CSV ...\n",
      "--- 0.011543989181518555 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Output Submission to CSV ...\")\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work Area. Feel free to clean if it gets too messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff {'color_changed': -1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': -1, 'second_most_common_color_changed': -1, 'least_common_color_changed': -1, 'shape_changed': -1, 'h_shape_changed': -1, 'v_shape_changed': -1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'n_objects_changed': -1, 'n_regions_changed': -1, 'n_h_lines_changed': 1, 'n_v_lines_changed': 1, 'n_h_slines_changed': 1, 'n_v_slines_changed': 1, 'n_h_plines_changed': -1, 'n_v_plines_changed': -1, 'is_in_in_out': -1, 'is_out_in_in': -1}\n",
      "functions removed {'draw_reg_3', 'lines_4', 'superp_reg_2', 'superp_reg_4', 'lines_5', 'lines_6', 'superp_1', 'color_reg_3', 'color_1', 'superp_3', 'color_2', 'lines_7', 'color_reg_2', 'lines_2', 'superp_6', 'superp_5', 'draw_reg_1', 'superp_7', 'lines_3', 'superp_2', 'superp_reg_1', 'superp_8', 'lines_8', 'superp_4', 'superp_reg_3', 'color_reg_1', 'special_1', 'draw_reg_2', 'color_ob_1', 'color_reg_4'}\n",
      "$$  {'color_related': [0, 2, 6, 7, 8], 'shape_related': [1, 2, 3, 4, 7], 'regions_related': [], 'object_related': [], 'layer_related': [], 'axis_related': []}\n",
      "len(prepare_magic_arguments(special_1, magic_numbers) 125\n",
      "{'color_changed': False, 'new_colors': [], 'color_perc_changed': True, 'most_common_color_changed': False, 'second_most_common_color_changed': False, 'least_common_color_changed': False, 'shape_changed': False, 'h_shape_changed': False, 'v_shape_changed': False, 'h_symm_changed': False, 'v_symm_changed': False, 'ld_symm_changed': False, 'rd_symm_changed': False, 'n_objects_changed': False, 'n_regions_changed': False, 'n_h_lines_changed': True, 'n_v_lines_changed': True, 'n_h_slines_changed': True, 'n_v_slines_changed': True, 'n_h_plines_changed': False, 'n_v_plines_changed': False, 'is_in_in_out': [], 'is_out_in_in': []}\n",
      "**  {'common_new_colors': [], 'out_shape_0': -1, 'out_shape_1': -1, 'max_in_shape': 15, 'min_in_shape': 7, 'max_out_shape': 15, 'min_out_shape': 7, 'prime_in_shape_0': True, 'prime_in_shape_1': True, 'n_colors': 2, 'max_n_objects_in': 1, 'min_n_objects_in': 1, 'max_n_objects_out': 1, 'min_n_objects_out': 1, 'max_n_regions_in': 1, 'min_n_regions_in': 1, 'max_n_regions_out': 1, 'min_n_regions_out': 1, 'max_max_color_perc_in': 0.9955555555555555, 'min_max_color_perc_in': 0.9795918367346939, 'max_max_color_perc_out': 0.9066666666666666, 'min_max_color_perc_out': 0.7755102040816326, 'plines_order': [], 'max_n_plines_in': 0, 'min_n_plines_in': 0, 'max_n_plines_out': 0, 'min_n_plines_out': 0, 'max_n_slines_in': 28, 'min_n_slines_in': 12, 'max_n_slines_out': 2, 'min_n_slines_out': 0}\n",
      "--  {'unique_colors': [0, 2], 'n_unique_colors': 2, 'n_unique_non_backg_colors': 1, 'grid_colors_perc': OrderedDict([(0, 0.9066666666666666), (2, 0.09333333333333334), (1, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0)]), 'max_color_perc': 0.9066666666666666, 'next_to_max_color_perc': 0.09333333333333334, 'most_common_color': 0, 'second_most_common_color': 2, 'least_common_color': 2, 'border_color': None, 'grid_shape': (15, 15), 'v_shape': 15, 'h_shape': 15, 'v_shape_half': None, 'h_shape_half': None, 'v_shape_third': None, 'h_shape_third': None, 'h_symm': False, 'v_symm': False, 'ld_symm': True, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': None, 'left_mid_point': None, 'lines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}, 'slines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}, 'plines': {'h_lines': [], 'v_lines': [], 'rd_lines': [{'ind': -14, 'color': 2, 'perc': 1.0}, {'ind': 8, 'color': 2, 'perc': 1.0}, {'ind': 14, 'color': 2, 'perc': 1.0}], 'ld_lines': [{'ind': 0, 'color': 2, 'perc': 1.0}]}, 'n_h_lines': 0, 'n_v_lines': 0, 'n_h_slines': 0, 'n_v_slines': 0, 'n_h_plines': 0, 'n_v_plines': 0, 'n_rd_plines': 3, 'n_ld_plines': 1, 'n_objects': 1, 'n_regions': 1, 'regions_max_color_perc_in': 0.9066666666666666, 'regions_max_next_to_max_color_perc_in': 0.09333333333333334}\n"
     ]
    }
   ],
   "source": [
    "task_n =  140\n",
    "train_data = build_trainlist(train_task_data[task_n])\n",
    "test_data = build_testlist(train_task_data[task_n])\n",
    "task_data = Task(train_data, test_data)\n",
    "task_data.compute_train_attributes()\n",
    "task_data.compute_test_attributes()\n",
    "task_data.compute_diff_attributes()\n",
    "task_data.find_common_diff()\n",
    "task_data.find_sequence()\n",
    "magic_numbers = get_magic_numbers(task_data)\n",
    "pred_functions = function_filter(task_data, DSL_fs_names) \n",
    "print(\"$$ \", magic_numbers)\n",
    "print(\"len(prepare_magic_arguments(special_1, magic_numbers)\",len(prepare_magic_arguments(special_1, magic_numbers)))\n",
    "#print(prepare_magic_arguments(special_1, magic_numbers))\n",
    "print(task_data.train_diff[0])\n",
    "#print(task_data.common_diff)\n",
    "print(\"** \", task_data.sequences)\n",
    "print(\"-- \", task_data.train_tensors[0][1].attributes)\n",
    "#print(task_data.test_tensors[0][1].attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Manual) ...\n",
      "--- 0.9623289108276367 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Manual) ...\")\n",
    "\n",
    "# fill row only if there is at least a colored pixel\n",
    "def verify_fill(l, color, backg_color, fill_override=None):\n",
    "\n",
    "    l = l.copy()\n",
    "    count_colors = sum([x != backg_color for x in l if x == color])\n",
    "    if count_colors >= 1: \n",
    "        fill_color = color\n",
    "        if fill_override != None:\n",
    "            fill_color = fill_override\n",
    "        l_start = 0\n",
    "        l_final = len(list(l))\n",
    "        if l_start != l_final:\n",
    "            for i in range(l_start, l_final):\n",
    "                if l[i] == backg_color:\n",
    "                    l[i] = fill_color\n",
    "                    \n",
    "    return l\n",
    "\n",
    "# Replace ALL Points != backround color in Row with Row/Fill Color\n",
    "def fill_points(l, colors, fill_override=None):\n",
    "    for color in colors[\"filling_colors\"]:\n",
    "        l = verify_fill(l, color, colors[\"background_color\"], fill_override)    \n",
    "    return l\n",
    "\n",
    "# Fill Lines By Type Passed as Parameter\n",
    "def fill_lines(a, a_t, task_data,*args, ctype=\"rows\", filling_colors = \"ALL\", fill_override=None):\n",
    "    \n",
    "    colors = {}       \n",
    "    colors[\"background_color\"] = [a_t.attributes[\"most_common_color\"]]\n",
    "    if filling_colors == \"ALL\":\n",
    "        filling_colors = [c for c in a_t.attributes[\"unique_colors\"] if c!= a_t.attributes[\"most_common_color\"]] # exclude the background\n",
    "    colors[\"filling_colors\"] = filling_colors \n",
    "    \n",
    "    if ctype == \"rows\":\n",
    "        for i, row in enumerate(a):\n",
    "            col = fill_points(a[i, :], colors, fill_override)\n",
    "            for idx, point in enumerate(col):\n",
    "                if a[i][idx] == colors[\"background_color\"]:\n",
    "                    a[i][idx] = point\n",
    "        return a\n",
    "    \n",
    "    elif ctype == \"columns\":\n",
    "        for i, row in enumerate(a.T):\n",
    "            col = fill_points(a[:, i], colors, fill_override)\n",
    "            for idx, point in enumerate(col):\n",
    "                if a[idx][i] == colors[\"background_color\"]:\n",
    "                    a[idx][i] = point\n",
    "        return a\n",
    "    \n",
    "    elif ctype == \"ldiagonals\":\n",
    "        for offset in range(-(a.shape[0] - 1), (a.shape[0])):\n",
    "            col = fill_points(np.diagonal(a, offset=offset), colors, fill_override)\n",
    "            if offset < 0:\n",
    "                for idx, point in enumerate(col):\n",
    "                    if a[np.abs(offset):, :][idx][idx] == colors[\"background_color\"]:\n",
    "                        a[np.abs(offset):, :][idx][idx] = point\n",
    "            else:\n",
    "                for idx, point in enumerate(col):\n",
    "                    if a[:, np.abs(offset):][idx][idx] == colors[\"background_color\"]:\n",
    "                        a[:, np.abs(offset):][idx][idx] = point\n",
    "        return a\n",
    "    \n",
    "    elif ctype == \"rdiagonals\":\n",
    "        b = np.flip(a, axis=1)\n",
    "        for offset in range(-(a.shape[1] - 1), (a.shape[1])):\n",
    "            col = fill_points(np.diagonal(b, offset=offset), colors, fill_override)\n",
    "            if offset < 0:\n",
    "                for idx, point in enumerate(col):\n",
    "                    if b[np.abs(offset):, :][idx][idx] == colors[\"background_color\"]:\n",
    "                        b[np.abs(offset):, :][idx][idx] = point\n",
    "            else:\n",
    "                for idx, point in enumerate(col):\n",
    "                    if b[:, np.abs(offset):][idx][idx] == colors[\"background_color\"]:\n",
    "                        b[:, np.abs(offset):][idx][idx] = point\n",
    "        return np.flip(b, axis=1)\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "# fill simple lines with a new_color. Solves 302. Only h and v for now.\n",
    "def lines_1(a, a_t, task_data,*args):\n",
    "    lines = a_t.attributes[\"slines\"]\n",
    "    new_color = args[0]\n",
    "    for row_index in lines[\"h_lines\"]:\n",
    "        a[row_index,:] = new_color\n",
    "    for col_index in lines[\"v_lines\"]:\n",
    "        a[:,col_index] = new_color\n",
    "    return a\n",
    "# Fill ALL Rows in grid for colors different from background\n",
    "def lines_2(a, a_t, task_data,*args):\n",
    "    return fill_lines(a, a_t, task_data,*args, ctype=\"rows\")\n",
    "# Fill ALL Columns in grid for colors different from background\n",
    "def lines_3(a, a_t, task_data,*args):\n",
    "    return fill_lines(a, a_t, task_data,*args, ctype=\"columns\")\n",
    "# Fill ALL Left Diagonals in grid for colors different from background\n",
    "def lines_4(a, a_t, task_data,*args):\n",
    "    return fill_lines(a, a_t, task_data,*args,  ctype=\"ldiagonals\")\n",
    "# Fill ALL Right Diagonals in grid for colors different from background\n",
    "def lines_5(a, a_t, task_data,*args):\n",
    "    return fill_lines(a, a_t, task_data,*args,  ctype=\"rdiagonals\")\n",
    "# Fill lines, according to the pseudolines found in output, with a given order\n",
    "def lines_6(a, a_t, task_data,*args):\n",
    "    fill_order = task_data.sequences[\"plines_order\"] # Ex: [(2,\"v\"),(3,\"h\"),(1,\"h\")]\n",
    "    for color,orient in fill_order:\n",
    "        coords = zip(*np.where(a == color))\n",
    "        for point in coords:\n",
    "            if orient == \"h\":\n",
    "                a[point[0],:] = color\n",
    "            if orient == \"v\":\n",
    "                a[:,point[1]] = color\n",
    "    return a\n",
    "# Draw lines h and v for every colored point\n",
    "def lines_7(a, a_t, task_data,*args):\n",
    "    override_color = DUMMY_COLOR\n",
    "    background_colors = a_t.attributes[\"most_common_color\"]\n",
    "    filling_color = args[0]\n",
    "    b = a.copy()\n",
    "    a_rows = fill_lines(a, a_t, task_data,*args, ctype=\"rows\", fill_override=override_color)\n",
    "    c = a.copy()\n",
    "    a_columns = fill_lines(a, a_t, task_data,*args, ctype=\"columns\", fill_override=override_color)\n",
    "    a = a_rows + a_columns\n",
    "    a[a > 9] = filling_color\n",
    "    return a\n",
    "\n",
    "# Draw lines ld and rd for every colored point\n",
    "def lines_8(a, a_t, task_data,*args):\n",
    "    override_color = DUMMY_COLOR\n",
    "    background_colors = a_t.attributes[\"most_common_color\"]\n",
    "    filling_color = args[0]\n",
    "    b = a.copy()\n",
    "    a_ldiagonal = fill_lines(b, a_t, task_data,*args, ctype=\"ldiagonals\", fill_override=override_color)\n",
    "    c = a.copy()\n",
    "    a_rdiagonal = fill_lines(c, a_t, task_data,*args, ctype=\"rdiagonals\", fill_override=override_color)\n",
    "    a = a_ldiagonal + a_rdiagonal \n",
    "    a[a > 9] = filling_color\n",
    "    return a\n",
    "\n",
    "# fill columns (top-->down) with the first not-brackground color encountered. Solves 321.\n",
    "def fill_columns(a, b, feat, colors):\n",
    "    background_color = get_background_color(b)\n",
    "    filled_cols = []\n",
    "    for x in range(0,b.shape[0]):\n",
    "        for y in range(0,b.shape[1]):\n",
    "            if (b[x,y]!=background_color) and (y not in filled_cols):\n",
    "                fill_color = b[x,y]\n",
    "                for xxx in range(x,b.shape[0]):\n",
    "                    b[xxx,y] = fill_color\n",
    "                filled_cols.append(y)\n",
    "    return b\n",
    "\n",
    "def combine_tasks(a):\n",
    "    b = a.copy()\n",
    "    t_in = task_data.train_tensors[0][0]\n",
    "    #try:\n",
    "        #t_in = task_data.test_tensors[0][0]\n",
    "        #b = repeat_2(b,t_in, task_data)\n",
    "        #b = superp_2(b,t_in, task_data,*[0,1,2])\n",
    "        #b = superp_ob(b,t_in, task_data,*[0,1])\n",
    "        #b = superp_reg_2(b,t_in, task_data,*[0,8])\n",
    "        #b = color_reg_4(b,t_in, task_data,*[0])\n",
    "        #b = draw_reg_1(b,t_in, task_data,*[0])\n",
    "        #b = color_ob_1(b,t_in, task_data,*[3])\n",
    "        #b = crop_1(b,t_in, task_data,*[2])\n",
    "        #b = crop_3(b,t_in, task_data,*[1])\n",
    "        #b = lines_3(b,t_in, task_data,*[0])\n",
    "        #b = lines_2(b,t_in, task_data,*[0])\n",
    "    b = lines_7(b,t_in, task_data,*[2])\n",
    "        #b = lines_6(b,t_in, task_data,*[0])\n",
    "    #except Exception as e:\n",
    "    #    print(\"Error:\", e)\n",
    "    \n",
    "    return b\n",
    "\n",
    "tasks_indices = [task_n]\n",
    "for task in tasks_indices:\n",
    "    check_p(train_task_data[task], combine_tasks)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  # 140, 165, 302, 304, 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'h_lines': [{'ind': 4, 'color': 1, 'perc': 1.0}, {'ind': 6, 'color': 1, 'perc': 1.0}], 'v_lines': [{'ind': 2, 'color': 2, 'perc': 0.7777777777777778}], 'rd_lines': [], 'ld_lines': []}, {'h_lines': [{'ind': 1, 'color': 3, 'perc': 1.0}, {'ind': 4, 'color': 3, 'perc': 1.0}, {'ind': 6, 'color': 1, 'perc': 1.0}], 'v_lines': [{'ind': 5, 'color': 2, 'perc': 0.7}], 'rd_lines': [], 'ld_lines': []}, {'h_lines': [{'ind': 1, 'color': 1, 'perc': 1.0}, {'ind': 3, 'color': 3, 'perc': 1.0}, {'ind': 6, 'color': 3, 'perc': 1.0}], 'v_lines': [{'ind': 3, 'color': 2, 'perc': 0.7}, {'ind': 9, 'color': 2, 'perc': 0.7}], 'rd_lines': [], 'ld_lines': []}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_plines = [{'h_lines': [{'ind': 4, 'color': 1, 'perc': 1.0}, {'ind': 6, 'color': 1, 'perc': 1.0}], 'v_lines': [{'ind': 2, 'color': 2, 'perc': 0.7777777777777778}], 'rd_lines': [], 'ld_lines': []}, {'h_lines': [{'ind': 1, 'color': 3, 'perc': 1.0}, {'ind': 4, 'color': 3, 'perc': 1.0}, {'ind': 6, 'color': 1, 'perc': 1.0}], 'v_lines': [{'ind': 5, 'color': 2, 'perc': 0.7}], 'rd_lines': [], 'ld_lines': []}, {'h_lines': [{'ind': 1, 'color': 1, 'perc': 1.0}, {'ind': 3, 'color': 3, 'perc': 1.0}, {'ind': 6, 'color': 3, 'perc': 1.0}], 'v_lines': [{'ind': 3, 'color': 2, 'perc': 0.7}, {'ind': 9, 'color': 2, 'perc': 0.7}], 'rd_lines': [], 'ld_lines': []}]\n",
    "print(all_plines)\n",
    "\n",
    "len(all_plines[0][\"h_lines\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 'v'], [3, 'h'], [1, 'h']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_fill_order(all_plines):\n",
    "    \n",
    "    # select the task with more plines\n",
    "    c_i = []\n",
    "    for i, g in enumerate(all_plines):\n",
    "        colors = set()\n",
    "        for key,l in g.items():\n",
    "            for val in l:\n",
    "                colors.add(val[\"color\"])\n",
    "        c_i.append([i,colors])      \n",
    "    c_i.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    p_lines = all_plines[c_i[0][0]]   \n",
    "    \n",
    "    # sort them by percentage. The smaller percentages first, since it means that the line is partially covered by other lines.\n",
    "    ll = []\n",
    "    for k,v in p_lines.items():\n",
    "        for val in v:\n",
    "            ll.append([k,val[\"color\"],val[\"perc\"]])\n",
    "    ll.sort(key=lambda x: x[2], reverse=False)\n",
    "    fill_order = []\n",
    "    for l in ll:\n",
    "        if l[0] == \"h_lines\":\n",
    "            fill_order.append([l[1],\"h\"]) # [color,orientation]\n",
    "        if l[0] == \"v_lines\":\n",
    "            fill_order.append([l[1],\"v\"])\n",
    "    \n",
    "    # eliminate duplicates\n",
    "    unique_order = []\n",
    "    for o in fill_order:\n",
    "        if o not in unique_order:\n",
    "            unique_order.append(o)\n",
    "    return unique_order\n",
    "\n",
    "compute_fill_order(all_plines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeit flip_2(tt,task_data.train_tensors[0][0], task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_colors': [0, 1], 'n_unique_colors': 2, 'n_unique_non_backg_colors': 1, 'grid_colors_perc': OrderedDict([(0, 0.5), (1, 0.5), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0)]), 'max_color_perc': 0.5, 'most_common_color': 0, 'second_most_common_color': 1, 'least_common_color': 1, 'border_color': None, 'grid_shape': (2, 2), 'v_shape': 2, 'h_shape': 2, 'v_shape_half': 1, 'h_shape_half': 1, 'v_shape_third': 0, 'h_shape_third': 0, 'h_symm': False, 'v_symm': False, 'ld_symm': True, 'rd_symm': True, 'top_left_corner': (0, 0), 'top_mid_point': (0, 1), 'left_mid_point': (1, 0), 'lines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}, 'has_hole': False, 'holes_coords_obj': None, 'holes_coords_parent': None}\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "[[1 0 0 1 0]\n",
      " [0 1 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 1 0]\n",
      " [1 1 0 0 1]]\n",
      "[[0 3]\n",
      " [1 4]]\n"
     ]
    }
   ],
   "source": [
    "dd = task_data.train_tensors[1][0].objects[1]\n",
    "print(dd.attributes)\n",
    "print(dd.grid)\n",
    "print(dd.parent_grid)\n",
    "print(dd.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_colors': [0, 2], 'n_unique_colors': 2, 'n_unique_non_backg_colors': 1, 'grid_colors_perc': OrderedDict([(0, 0.52), (2, 0.48), (1, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0)]), 'max_color_perc': 0.52, 'most_common_color': 0, 'second_most_common_color': 2, 'least_common_color': 2, 'border_color': None, 'grid_shape': (5, 5), 'v_shape': 5, 'h_shape': 5, 'v_shape_half': None, 'h_shape_half': None, 'v_shape_third': None, 'h_shape_third': None, 'h_symm': False, 'v_symm': False, 'ld_symm': True, 'rd_symm': False, 'top_left_corner': (0, 0), 'top_mid_point': None, 'left_mid_point': None, 'lines': {'h_lines': [], 'v_lines': [], 'rd_lines': [], 'ld_lines': []}}\n",
      "[[0 2 0 0 2]\n",
      " [2 2 0 2 2]\n",
      " [0 0 0 0 0]\n",
      " [0 2 0 2 2]\n",
      " [2 2 0 2 0]]\n",
      "[[0 2 0 0 2]\n",
      " [2 2 0 2 2]\n",
      " [0 0 0 0 0]\n",
      " [0 2 0 2 2]\n",
      " [2 2 0 2 0]]\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [2, 0], [2, 1], [2, 2], [2, 3], [2, 4], [3, 0], [3, 1], [3, 2], [3, 3], [3, 4], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4]]\n"
     ]
    }
   ],
   "source": [
    "#rr = Region(task_data.train_tensors[0][0].grid,regions[0])\n",
    "#rr.compute_attributes()\n",
    "rr = task_data.train_tensors[0][0].regions[0]\n",
    "print(rr.attributes)\n",
    "print(rr.grid)\n",
    "print(rr.parent_grid)\n",
    "print(rr.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newly solved tasks:  [0, 58, 371]\n",
      "old broken tasks:  [48, 258]\n"
     ]
    }
   ],
   "source": [
    "score_old =  [1, 2, 5, 13, 25, 30, 35, 38, 47, 48, 55, 56, 71, 82, 86, 99, 102, 112, 115, 128, 134, 139, 141, 143, 145, 149, 151, 152, 154, 163, 171, 176, 178, 186, 187, 195, 206, 209, 210, 222, 226, 230, 235, 240, 243, 248, 250, 258, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 317, 318, 325, 337, 346, 379, 383, 384, 385, 388, 394]\n",
    "score_new = [0, 1, 2, 5, 13, 25, 30, 35, 38, 47, 55, 56, 58, 71, 82, 86, 99, 102, 112, 115, 128, 134, 139, 141, 143, 145, 149, 151, 152, 154, 163, 171, 176, 178, 186, 187, 195, 206, 209, 210, 222, 226, 230, 235, 240, 243, 248, 250, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 317, 318, 325, 337, 346, 371, 379, 383, 384, 385, 388, 394]\n",
    "\n",
    "#score_new = [1, 2, 5, 13, 25, 30, 35, 38, 47, 48, 55, 56, 71, 82, 86, 99, 102, 112, 115, 128, 134, 139, 141, 143, 145, 149, 151, 152, 154, 163, 171, 176, 178, 186, 187, 195, 206, 209, 210, 222, 226, 230, 235, 240, 243, 248, 250, 258, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 317, 318, 325, 337, 346, 379, 383, 384, 385, 388, 394]\n",
    "\n",
    "\n",
    "print(\"newly solved tasks: \", [item for item in score_new if item not in score_old]) #[1, 48, 186, 250, 337]\n",
    "print(\"old broken tasks: \", [item for item in score_old if item not in score_new])\n",
    "# TODO tasks solved with filter_programs: 66,..\n",
    "# TODO tasks solved at some point: 48, 52, 128, 258, 345, 371...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGoCAYAAAC9shqwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcFElEQVR4nO3df4xlZ3kf8OcprGphKDa1F2oX1o5AJksoUs0VlVprtylquq5jFAmIiJKULVsrY9dVRaxEakC7JgQiFPmPIjBy3RTiRAohEsoPLVWUpnZStU6GoERFK9w6wvyMZxdo+DHE1lK//WPG8vTVzL1zzj3nzLlnPh8JMd457/ue9945937vPee8T5ZSAgCA5/yNg94BAICxEZAAACoCEgBARUACAKgISAAAFQEJAKByaANSZn4kM9/dsu2nMvNfdL1PABxO3pPGJ1dxHaTMfCIizpRSfv+g96VPmXkuIl5ZSvnxg94X2E1mfiQivlJK+fkWbT8VEb9eSvlY93sGw/GeNE3PP+gd6ENmPr+U8r2D3g8Ysy5e1EspP7VE21Nt2zZx2F7UGR/vSatp5U6xZeZDEfGKiPidzPxOZv5MZt6QmSUz35GZX4yIP9je9hOZ+WRmfjMz/zAzX7Ojn49m5nu3fz6ZmV/OzJ/OzIuZ+ZeZeXrOPjycmWe2f357Zv63zPylzPw/mfn5zDxVbfv+zPyTzPxWZv5WZr5k57hV309k5hsz859FxL+LiB/dnuefd/Ygwj5k5iQ/QEGXvCdN18oFpFLKT0TEFyPih0spLyylfGDHr09ExPdHxA9t//enIuJVEXE0Ij4TEb82p+uXRcSLI+L6iHhHRHwoM6/e5269ISIei4hrIuIDEfEfMzN3/P4nI+JfRsTfiYjvRcS/X9RhKeU/R8T7IuLj2/N83T73BRbyog7d8J40XSsXkBY4V0rZLKX8dUREKeWXSynfLqU8HRHnIuJ1mfniPdpejoj3lFIul1LOR8R3IuKmfY77hVLKfyil/N+I+Fhs/dG9dMfvHyqlfLaUshkR746It2bm85pPD7rhRR0G4T1phU0tIH3p2R8y83mZ+YuZ+ReZ+a2IeGL7V9fs0fbr1Tni70bEC/c57pPP/lBK+e72jzvbfmnHz1+IiCNz9gMOmhd16Ib3pBW2qgFpr1vvdv77j0XEmyLijbH1ifaG7X/PGN7Ld/z8ith6E/laRGxGxAue/cX2i/21O7ZdvVsMmQIv6tCM96QJWtWAtBER37dgmxdFxNMR8fXYesLf1/dOzfHjmXk8M18QEe+JiN/c/pT8vyLiisz855l5JCLeFRF/c0e7jYi4ITNX9Xli3LyoQze8J03Qqk7y/RHxrsz8q8y8Z49tfiW2PmV+JSIuRMSjQ+3cLh6KiI/G1ifkKyLi30RElFK+GRF3RsSDsbWfmxGx82LTT2z//9cz8zND7SyHhhd16Ib3pAlayYUiV0lmPhwRv1pKefCg9wV2ysw3RcQHI+JvRcR7I+I3I+LzEXHk2dNkmfnC2Loo+wcj4huxde3PxyLiVaWUxzPzoxHx5VLKuzLzZGz9rf/dHWM8EXustbTz2MjMt29v9492/L7sGOfhiPgfEfFPIuLVEfFIRJwupXxte9u3x9ab1PNi6wLvf/3suJn5tyPityLiNRHx+VLK31/ukYPV5T1p/wSknvljhOU5jqAbjqX985UzAEDFSrk9K6WcPOh9AIAI70lNOMUGAFBZ+A1SZt4REXdERBw5cuTmq666qtEAV1xxRTz11FO9ba/NcG0uXboUpZSDuL0bmJBl31fmafNaqL/D29+897VG3yAdPXq0XLp0qdHga2trcf/99/e2vTbDtlmFgNTni+9uuj5gD3KcKc1lqHGmNJeD+BDU5n1lnjava/o7vP1F7P2+5hokJqeU8kBEPBDR/Yvvbvo4YA9qnCnNZahxpjQX4DnuYgMAqAhIAAAVAQkAoCIgAQBUBCQAgIqABABQEZAAACoCEgBARUACAKgISAAAlUbFaq+++upYW1trNMBsNut1e22Ga6PMAQCHxcKAVNe1avMm2bTNEGNo074NAEydU2wAABUBCQCgIiABAFQEJACAioAEAFBZeBcbAHRp2eVj5nnLXffEybvPdtbftc9s6m/J/rrUZkmbeebdyS0gATCoLpaP2cvJu8/GhSMv7ay/45c39Ldkf10vJzPU8jROsQEAVAQkAICKgAQAUBGQAAAqvRerbXpHQZsr6Nu2aWqsRWSHaqNu297O/u/S+xjHL2/E0Xd+eOXHmNo4Q83l4n139j4G8Jzei9U2vaOgzRX0bduMuSDsmNuMXZ+3EO9mNpvFlZc3eh0jYivUH+95nCHGmNo4Q83lWMe3N+9miq8H0Jbb/JmcPm8h3svRW073PkbXt98e1BhTG2eouVxcXxdgYECuQQIAqAhIAAAVAQkAoCIgAQBUBCQAgIqABABQEZAAACoCEgBARUACAKgISAAAld6L1TatU3TtM5uNizIem83i4vp64zZN5zLWIrJDtVHmAIDDYpTFasdcqFUbgOX0WVB689HzjT8wz9PmA/g8J+66p9Pixn3M9/g/uLWz/q59ZrPT57fNlwHzzHsPVKwWgEH1XVB6zP01/dJgkT6KGHdZfLvtlx7zDPXB3jVIAAAVAQkAoCIgAQBUBCQAgIqABABQEZAAACoCEgBARUACAKgISAAAFStpw4p4+IP39r6C7NraWhx954d7HWNIHjOgrVEWq/34hScbj3Hy7rO9t9l89Hyj7SPGW3i2TZtVqdvWZ52n3cxms7iyw9pKeznWcQ2i3Qw1l6avC21N6TEbYi6rcozDEEZZrLZpnZqh2rSteTO1NmPXd52n3XRZu2gvfdRc2s0Qc2lz/LUxpcdsqLkAW1yDBABQEZAAACoCEgBARUACAKgISAAAFQEJAKBioUgA2MPJu892uxBox2tmdb1/xy9vxIXOelttAhIAg+pzMdc2i+bO0/WipoexvzE/v/PWFhOQABhU34u5dtlf08WOF+l6kdRV6G/Mz+88rkECAKgISAAAlVEWq216/vPaZzbj4n13NmpzbDaLi+vrjdqMtYjsUG3UgQLgsJhMsdoxF3edWhsAmDqn2AAAKgISAEBFQAIAqAhIAAAVAQkAoCIgAQBUBCQAgIqABABQEZAAACoCEgBAZWGpEYCuPfzBewcpc9O0diTAsyZTrPbjF55s3KapsRaRHarNqtRtW/ZvtqnZbBZXNvybbeNYi+e4qSnNJaLdcdFmjKk8ZqtyjMMQJlOsVoFbxWqftezfbBtHbznd+xgX19cHeb6mNJeIYf7Gp/aYAU6xAcCeuj4d3PRsBwdHQAJgUH2eBu/6tGrX/bW5jGTV+xvz8zsv/ApIAAyq79PgY+6v6WUni7S5xGTo/sb8fMzjNn8AgIqABABQEZAAACoCEgBARUACAKgISAAAFQEJAKAyynWQ7n1VNtp+bW2t8boIilgCAHsZZbHapmOMtbjr1NqoAwXAYTHKYrVjLtSqDQBMn2uQAAAqAhIAQEVAAgCoCEgAABUBCQCgIiABAFQEJACAioAEAFAZZakRAKZr2QoN87SpKjBkf5uPno+L6+ud9XfirnsaVatYpGn1i/30N+bnd95iyQISAINatkLDIoepv6bVKhY5fnmj8/7G/PjNM8pabB+/8GTjMU7efbZxm6bGWiNtqDarUpakz0+nu5nNZrF+3529jvHsOEOMcWWHnx73cmyAuUREvOWuexq/NjR17TObcWkij9mqHOMwhFHWYmuaXtu2GXO9szG3Gbu+P53uZqjHcYhxjt5yuvcxLq6vDzKXrj9d76brT9x7GeoxA7a4SBsAoCIgAQBUBCQAgIqABABQEZAAACoCEgBARUACAKgISAAAFQEJAKAiIAEAVAQkAIDKKIvVNtl+mTZN5zLWIrJDtVEHCoDDQrHahrQBgOlzig0AoCIgAQBUBCQAgMrCa5AAoEvL3vwzT5sbVobs7y133RMn7z7bWX9tblIaur8xP7/zrsMVkAAY1LI3/ywy5v6a3ri0SJublIbub8zPxzxOsQEAVAQkAICKgAQAUBGQAAAqAhIAQEVAAgCoTKZY7cX77mzU5thspljtRIvV9rnGym66XpfjIMeZzWax3vBYajvOEDYfPR8X19d7HePYbNb7GBHDPGarcozDECZTrHbMxV2n1mbs+l5jZTdDPY7mMs5xpjQXYItTbAAAFQEJAKAiIAEAVAQkAICKgAQAUBGQAAAqAhIAQEVAAgCoCEgAABUBCQCgsrDUCAB0qc96iV3XrOu6v67rA3ZdC7CP/sb8/M4r39N7sdqmfwxtnhyFZxWrBVZH3/US9ae/LvRerDai+WTGXKhVGwCYPtcgAQBUBCQAgIqABABQEZAAACoCEgBARUACAKgISAAAFQEJAKAiIAEAVAQkAICKYrVMTp+FMHfTdfHEgxxnSnMZapwpzUXpIXhO78Vqmx7UYy3Uqs3qvHj2XQhzN0M9NuYyznGmNBdgi2K12jRuAwBT5xokAICKgAQAUBGQAAAqAhIAQMVt/gAMqs+lOLpeDkF/0+5v3o1KAhIAg+p7KQ796a8LTrEBAFQEJACAioAEAFARkAAAKgISAEBFsVpt9k3dNgAOC8VqtWncBgCmzik2AICKgAQAUBGQAAAqAhIAQEVAAgCoCEgAABUBCQCgIiABAFQEJACAioAEAFBZWGoEVs3O+oER8XREfLbP8e6///5rIuJrfY4x1DhTmstQ40xpLhFxU8/9w8rIUsr8Df7/N5sfiOZvNk0P6jYvAtoM0+amUsqLGo5xoDLz06WU16/6GEONM6W5DDWOubQaZ9n3lXm6DpL6m3Z/e76vNSpW2+bgadpmiDG0adcmMz/dpH+A3Sz7vjKP/vTXtL+9fucaJACAioDE1D0wkTGGGmdKcxlqHHOBCWoakNocPE3bDDGGNu3arNyL5/ZX+Ss/xlDjTGkuQ41jLkvrekz96a+T/hZepA0AcNg4xQYAUBGQAAAqAhIAQEVAAgCoCEgAABUBCQCgIiABAFQEJACAioAEAFA5FAEpMz+Sme8+6P2AVedYgm44lsZv9AEpM5/IzDcu00cp5adKKT/f1T7tVxf73md/HC6Opf7643BxLPXX35iMPiAtkpnPP+h9gClwLEE3HEvTMOqAlJkPRcQrIuJ3MvM7mfkzmXlDZpbMfEdmfjEi/mB7209k5pOZ+c3M/MPMfM2Ofj6ame/d/vlkZn45M386My9m5l9m5uk5+3BdZv52Zn4jMx/PzH+1W787+97Hvt+RmV/dHvuetv0t+fByiDiWHEt0w7F0eI6lUQekUspPRMQXI+KHSykvLKV8YMevT0TE90fED23/96ci4lURcTQiPhMRvzan65dFxIsj4vqIeEdEfCgzr95j21+PiC9HxHUR8eaIeF9m/uCS+/6Pt/f1n0bEz+Y+vp5c0B/M5Vjad38wl2Np3/2tvFEHpAXOlVI2Syl/HRFRSvnlUsq3SylPR8S5iHhdZr54j7aXI+I9pZTLpZTzEfGdiLip3igzXx4R/zAifraU8lQp5c8i4sGI+Mkl9/3e7X3/nxHxnyLibUv2B8twLEE3HEsTssoB6UvP/pCZz8vMX8zMv8jMb0XEE9u/umaPtl8vpXxvx39/NyJeuMt210XEN0op397xb1+IrYS/jC/t+PkL2+PAQXEsQTccSxOyCgGp7OPffywi3hQRb4ytryhv2P73XHLsr0bESzLzRTv+7RUR8ZXtnzcj4gU7fveyOfu408ur/r66ZH+wH46lxf3BfjiWFve38lYhIG1ExPct2OZFEfF0RHw9tp7I93UxcCnlSxHx3yPi/Zl5RWb+vdg6N/yr25v8WUTcmpkvycyXRcS/3ee+vzszX7B9wd7piPj4kv3BfjiWFvcH++FYWtzfyluFgPT+iHhXZv7VzivrK78SW18JfiUiLkTEox2O/7bYSv5fjYhPRsTZUsrvb//uoYj489j66vT34rk/qEX7/khEPB4R/yUifqmU8ntL9gf74Vha3B/sh2NpcX8rL0uZ7Ldjo5OZN0TE5yPiSHWuGWjAsQTdcCztbRW+QQIAGJSABABQcYoNAKDiGyQAgMrCgnqZeUdE3BERceTIkZuvuuqqRgNcccUV8dRTT/W2vTbDtbl06VKUUpZdwwM45JZ9X5mnzWuh/g5vf/Pe1xqdYjt69Gi5dOlSo8HX1tbi/vvv7217bYZtswoBqc8X3910fcAe5DhTmstQ40xpLgfxIajN+8o8bV7X9Hd4+4vY+31t4TdIsGpKKQ9ExAMR3b/47qaPA/agxpnSXIYaZ0pzAZ7jGiQAgIqABABQEZAAACoCEgBARUACAKgISAAAFQEJAKAiIAEAVAQkAICKgAQAUGlUrPbqq6+OtbW1RgPMZrNet9dmuDbKHABwWCwMSHVdqzZvkk3bDDGGNu3bAMDUOcUGAFARkAAAKgISAEBFQAIAqCy8SBsAVsXJu8/G0Xd+uLP+jl/e0N+S/a3qzUACEgCDWnb5mHmufWYzjl/e0N+I+uvy+W2zpM0888KbgATAoLpYPmYvJ+8+GxeOvLSz/o5f3tDfkv11/Q3SUN9IuQYJAKAiIAEAVAQkAIBK79cgNb2joM0V9G3bfPhzf9qozZ2NtgYAVlXvxWqbXhHf5gr6tm02Tt3eqM3smusabR8x3sKzbdqsyq2afd4hs5vZbBYn7z7b6xgRW3+zfY8zxBhTG2eouWw+er73MVblGIch9F6stukdBW2uoG/b5qWf+u1GbdZfffOoi8gqVrulzztk9nL0ltO9j9H13SUHNcbUxhlqLhfX1yd5vMJYuQYJAKAiIAEAVAQkAICKgAQAUBGQAAAqAhIAQEVAAgCoCEgAABUBCQCgIiABAFR6L1bbxrk73tBo+41Tt8dbG5YNaVqHDQA4PEZZrLZpeNl85U2DtFGsVh0oYNxO/O6DjT8wz9PmA/g8v/Gh7vqK6Ge+F37k5zrrb5WNslht0yKyG6duH6SNYrUAy1v2g/c8bT78Dtlf0y8NFuljvl3u37XPbHb6/Lb5MmCeee+BozzFBsB0LfvBe56zN17f+MPvPG0+TM/zyG1nGn1psMiJxx/rfL4XXvvmzvo7fnmj8w/iQ32wd5E2AEBFQAIAqAhIAAAVAQkAoCIgAQBUBCQAgIqABABQEZAAACoCEgBAZZQraZ974I8bbX/88kbj2jFt2sR9dzbbHjrUdc2l3UytDpPHDGhrlMVqm9aBGarNsZEWkR2qzarUbeuzztNuZrNZXNlh7aK9dF1zaa8xuqzDtJeu61HtZUqPWZvXn6ZW5RiHIYyyWG3TOjVDtbm4vj7qIrKK1W7ps87TXo7ecrr3MbquubSbrusw7aXN8dfGlB6ztq8/QDuuQQIAqAhIAAAVAQkAoCIgAQBUBCQAgMoo10ECgDF45LYzna5z1fWSEGPfv1UmIAEwqD7XKut67auu1+w6jP11+fy2WfNvnnlLZwhIAAyqz7XKzt54fadrXz1y25lO1+zqeg2wVeiv6/W7hloPzDVIAAAVAQkAoDKZWmxrn/yFRm02X3lTnHj8sUZtzo+0RtpQbZQ5AOCwmEwttqbnnDdO3d64zfqrbx51jTS12ACgG06xAQBUBCQAgIqABABQEZAAACoCEgBARUACAKgISAAAFQEJAKAiIAEAVAQkAICKgAQAUJlMsdrf+FCzumrXPrPZaPuIiNk11zVvM9LCs23arErdtmX/ZpuazWZxZcO/2TY2X3lTbJy6vfcxmh5/bbz+c3/UuFh0G1N6zI61OMabWpVjHIYwmWK1QxS4Vax2NSz7N9vG0VtO9z7Giccfa/w329TGqdvjwmvf3OsYEcPMJaJdUeo2YwzxmF1cX5/k8QpjtTAgAcBhdeJ3H4y3dhiym57t4OAISAAMqs/T4F2fVu26vzaXkax6f10+v20uJ5ln3reyAhIAg+rzNPjZG6/v9LRq16dpH7ntTONLQuZpc4nJ0P11fWp4qFPN7mIDAKgISAAAFQEJAKAiIAEAVAQkAICKgAQAUBGQAAAqo1wH6dwdb2i0/cap2xuvdNp3fSYAYHWNslht0/DSZqXTNm0Uq1UHCoDDYZTFapuuWtpmpdM2bRSrBYDDwTVIAAAVAQkAoCIgAQBUBCQAgIqABABQEZAAACoCEgBARUACAKiMstQIANO1bIWGedpUSRiyv9d/7o/ixOOPddbfhVvf1qhaxSJNq1/sp78un982VSPmmbdYsoAEwKCWrdAwz9kbr29cJWGeNlUXhuzvkdvONKpWscjxyxud99d1xYahKkCMMiCde+CPG21//PJGXPiRn2vcpmmBWwDgcBhlsdqmX++1baNY7TSL1fb59f1uZrNZ3PrJX+h1jIjuv+rfa4wuv16fN07fc4nYOv3wyG1neh2j61MSeznW8amF3azKMQ5DGGWx2qZf77Vto1jtNF8Q+/z6fi+nP/envY/R9Vfze41x4bVv7nWMiIgTjz/W+1wiuj/9sJuuT0ns5eL6+iSPVxgrd7EBAFQEJACAioAEAFARkAAAKgISAEBFQAIAqAhIAAAVAQkAoCIgAQBUBCQAgIqABABQUay2AcVq1YEC4HBQrLYBxWoB4HBwig0AoCIgAQBUFp5iA4AuLXtt6zybr7yp8fWlQ/Z34da3xSO3nemsvzbX4A7dX5fPb5vrbeeZd5mJgATAoJa9tnWeszde3/j60nk2Tt3eaX+P3Ham8TWz87S5Bnfo/rq+1nWoa2edYgMAqAhIAAAVAQkAoCIgAQBUBCQAgIqABABQmcxt/ufueEOj7btc1wIAmJbJFKttGnjaLP6lWO1q1G3rcxG63cxms7iz1xG2x7nmulh/9c29j3Hxvv5nc342630uERGzR8/HxfX1Xsc4Npv1PkZE9wvk7WZVjnEYwmSK1TZdyKvN4l+K1a6GPheh28tQj6O5jHOcKc0F2OIaJACAioAEAFARkAAAKgISAEBFQAIAqAhIAAAVAQkAoCIgAQBUBCQAgMpkarEBsBr6LAd0vuOSPF2X+Om6/E3XpW766K/L57frkjvzVqfvPSA9/MF7Gy2Pv7a21ng5/bW1tfjR//onzdq8+ua4v0UbAJbTdzkg/emvC70Xq22a9sZaqFUbdaAAODx6L1Yb0fyNdcyFWrUBgOlzkTYAQEVAAgCoCEgAABUBCQCgIiABAFQEJACAioAEAFARkAAAKgISAEBFQAIAqPRerBaG1mel8N10XV36IMeZ0lyGGmdKc1F6CJ6jWK02+7YqL559VwrfzVCPjbmMc5wpzQXYolitNo3bAMDUuQYJAKAiIAEAVAQkAICKu9gAGFSfd5p2fbef/qbd37zrcAUkAAbV952m+tNfF5xiAwCoCEgAABUBCQCgIiABAFQEJACAilps2uybsiQAHBZqsWnTuA0ATJ1TbAAAFQEJAKAiIAEAVAQkAICKgAQAUBGQAAAqAhIAQEVAAgCoCEgAABUBCQCgIiABAFSylDJ/gx3FaiPiByLisw3HuCYivtbj9toM1+amUsqLGo4xuA7+Zptq89iPdZwpzWWocaY0l0GO8Z6P0a4fJ/1Nu7+9/+ZLKfv+X0R8usn2bdoMMYY2wz03B/2/IfZ5qMfFXMY5jrmMa0z96a+r/pxiAwCoCEgAAJWmAemBFmM0bTPEGNq0a9NmjIM2xD4P9biYyzjHMZdxjak//XXS38KLtAEADhun2AAAKgISAEBFQAIAqAhIAAAVAQkAoPL/AB0YSEYwSuLsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x432 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_task(train_task_data[165]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superpose all the objects with an operation given by op\n",
    "def superp_ob(a, a_t, task_data,*args, key=None, op=\"AND\"):\n",
    "    \n",
    "    b = black_square\n",
    "    background_color = args[0]\n",
    "    new_color = args[1]\n",
    "    for previous, current in zip(a_t.objects, a_t.objects[1:]):\n",
    "        if not (key is None):\n",
    "            pass\n",
    "        else:\n",
    "            if op==\"AND\":\n",
    "                b = np.where((previous.grid !=background_color) & (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"OR\":\n",
    "                b = np.where((previous.grid !=background_color) | (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"XOR\":\n",
    "                b = np.where((previous.grid !=background_color) ^ (current.grid !=background_color), new_color, background_color)\n",
    "            if op==\"ADD\":\n",
    "                b =  np.where((previous.grid + current.grid) < 10, previous.grid + current.grid, background_color)\n",
    "    return b\n",
    "\n",
    "\n",
    "def superp_ob_1(a, a_t, task_data,*args):\n",
    "    return superp_reg(a, a_t, task_data,*args, key=None, op=\"ADD\")\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "# need to detect fixed objects amomng all frames\n",
    "\n",
    "def detect_objs_movements(objects):\n",
    "    \n",
    "    ob_mvs = {}\n",
    "    #for ob in objects:\n",
    "    pass\n",
    "        \n",
    "def move_ob(a, a_t, task_data,*args):\n",
    "    \n",
    "    #a_t.objects\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
