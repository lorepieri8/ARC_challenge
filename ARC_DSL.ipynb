{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import scipy\n",
    "import gc\n",
    "import cv2\n",
    "import requests\n",
    "import collections\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as colors_mat\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from itertools import product\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.signal import convolve2d\n",
    "from collections import Counter\n",
    "from cv2 import matchTemplate as cv2m\n",
    "\n",
    "DEBUG = True # Active logging, printing, etc. False when committing to the LB. \n",
    "url_slack = \"https://hooks.slack.com/services/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\"  # This is secret, do not share.\n",
    "headers = {'Content-type': 'application/json'}\n",
    "MAX_DIM_MATRIX = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Initial Data ...\n",
      "--- 0.049981117248535156 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Initial Data ...\")\n",
    "\n",
    "if os.path.isdir(\"/kaggle/input/abstraction-and-reasoning-challenge/\"):\n",
    "    data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "else:\n",
    "    data_path = Path('')\n",
    "training_path = data_path / 'training'\n",
    "training_path = data_path / 'training'\n",
    "evaluation_path = data_path / 'evaluation'\n",
    "testing_path = data_path / 'test'\n",
    "\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "evaluation_tasks = sorted(os.listdir(evaluation_path))\n",
    "testing_tasks = sorted(os.listdir(testing_path))\n",
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Functions ...\n",
      "--- 0.0019071102142333984 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Functions ...\")\n",
    "\n",
    "def flattener(pred):\n",
    "    \n",
    "    str_pred = str([row for row in pred.tolist()])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    \n",
    "    return str_pred\n",
    "\n",
    "def build_trainlist(task):\n",
    "    \n",
    "    task_data = []\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "        list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "    \n",
    "    return task_data\n",
    "\n",
    "def build_testlist(task, LB_submission=False):\n",
    "    \n",
    "    task_data = []\n",
    "    \n",
    "    if LB_submission:\n",
    "        for i, t in enumerate(task[\"test\"]):\n",
    "            t_in = np.array(t[\"input\"]).astype('uint8')       \n",
    "            list.append(task_data, (t_in.copy()))\n",
    "    else:\n",
    "        for i, t in enumerate(task[\"test\"]):\n",
    "            t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')        \n",
    "            list.append(task_data, (t_in.copy(), t_out.copy()))\n",
    "          \n",
    "    return task_data\n",
    "\n",
    "def load_data(p, phase=None):\n",
    "    \n",
    "    if phase in {'training', 'test', 'evaluation'}:\n",
    "        p = data_path / phase / p\n",
    "    \n",
    "    task = json.loads(Path(p).read_text())\n",
    "    dict_vals_to_np = lambda x: { k : np.array(v) for k, v in x.items() }\n",
    "    assert set(task) == {'test', 'train'}\n",
    "    res = dict(test=[], train=[])\n",
    "    \n",
    "    for t in task['train']:\n",
    "        assert set(t) == {'input', 'output'}\n",
    "        res['train'].append(dict_vals_to_np(t))\n",
    "    for t in task['test']:\n",
    "        res['test'].append(dict_vals_to_np(t))\n",
    "        \n",
    "    return res\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Files ...\n",
      "--- 0.8427340984344482 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Data Files ...\")\n",
    "\n",
    "train_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(training_tasks[i], phase='training')\n",
    "    list.append(train_task_data, task)\n",
    "\n",
    "eval_task_data = []\n",
    "for i in range(0, 400):\n",
    "    task = load_data(evaluation_tasks[i], phase='evaluation')\n",
    "    list.append(eval_task_data, task)\n",
    "\n",
    "test_task_data = []\n",
    "for i in range(0, 100):\n",
    "    task = load_data(testing_tasks[i], phase='test')\n",
    "    list.append(test_task_data, task)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checking Functions\n",
      "--- 0.0030508041381835938 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Checking Functions\")\n",
    "\n",
    "cmap = colors_mat.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors_mat.Normalize(vmin=0, vmax=9)\n",
    "num2color = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\n",
    "color2num = {c: n for n, c in enumerate(num2color)}\n",
    "\n",
    "def plot_one(task, ax, i,train_or_test,input_or_output):\n",
    "    \n",
    "    input_matrix = task[train_or_test][i][input_or_output]\n",
    "    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
    "    ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
    "    ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(train_or_test + ' '+ input_or_output)\n",
    "    \n",
    "def plot_task(task):\n",
    "\n",
    "    num_train = len(task['train'])\n",
    "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
    "    for i in range(num_train):     \n",
    "        plot_one(task, axs[0,i],i,'train','input')\n",
    "        plot_one(task, axs[1,i],i,'train','output')        \n",
    "    plt.tight_layout()\n",
    "    plt.show()        \n",
    "        \n",
    "    num_test = len(task['test'])\n",
    "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
    "    if num_test==1: \n",
    "        plot_one(task, axs[0],0,'test','input')\n",
    "        plot_one(task, axs[1],0,'test','output')     \n",
    "    else:\n",
    "        for i in range(num_test):      \n",
    "            plot_one(task, axs[0,i],i,'test','input')\n",
    "            plot_one(task, axs[1,i],i,'test','output')  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def check_p(task, pred_func):\n",
    "    \n",
    "    fig_num = 0\n",
    "    n = len(task[\"train\"]) + len(task[\"test\"])\n",
    "    fig, axs = plt.subplots(3, n, figsize=(4*n,12), dpi=50)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # All Data for Task\n",
    "    train_data = build_trainlist(task)\n",
    "    test_data = build_testlist(task)\n",
    "    task_data = Task(train_data, test_data)\n",
    "    \n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')   \n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Train-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Train-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Train-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "        \n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]).astype('uint8'), np.array(t[\"output\"]).astype('uint8')\n",
    "        t_pred = pred_func(t_in)\n",
    "        \n",
    "        axs[0][fig_num].imshow(t_in, cmap=cmap, norm=norm)\n",
    "        axs[0][fig_num].set_title(f'Test-{i} in')\n",
    "        axs[0][fig_num].set_yticks(list(range(t_in.shape[0])))\n",
    "        axs[0][fig_num].set_xticks(list(range(t_in.shape[1])))\n",
    "        axs[1][fig_num].imshow(t_out, cmap=cmap, norm=norm)\n",
    "        axs[1][fig_num].set_title(f'Test-{i} out')\n",
    "        axs[1][fig_num].set_yticks(list(range(t_out.shape[0])))\n",
    "        axs[1][fig_num].set_xticks(list(range(t_out.shape[1])))\n",
    "        axs[2][fig_num].imshow(t_pred, cmap=cmap, norm=norm)\n",
    "        axs[2][fig_num].set_title(f'Test-{i} pred')\n",
    "        axs[2][fig_num].set_yticks(list(range(t_pred.shape[0])))\n",
    "        axs[2][fig_num].set_xticks(list(range(t_pred.shape[1])))\n",
    "        fig_num += 1\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Main)\n",
      "--- 0.0016331672668457031 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Main)\")\n",
    "\n",
    "#https://stackoverflow.com/questions/32531377/how-can-i-check-if-one-two-dimensional-numpy-array-contains-a-specific-pattern-o\n",
    "# return the coords of all the instances of template in grid (upper left corner)\n",
    "def match_template(grid, template):\n",
    "    \n",
    "    # check that the shapes are consinstent\n",
    "    if grid.shape == (1,):\n",
    "        return []\n",
    "    if template.shape == (1,):\n",
    "        pass \n",
    "    else:\n",
    "        if (grid.shape[0] < template.shape[0]) or (grid.shape[1] < template.shape[1]):\n",
    "            return []\n",
    "        \n",
    "    M = cv2m(grid.astype('uint8'),template.astype('uint8'),cv2.TM_SQDIFF)\n",
    "    x,y = np.where(M==0)\n",
    "    coords = list(zip(x, y))\n",
    "    return coords\n",
    "\n",
    "# https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical\n",
    "def checkEqual1(iterator):\n",
    "    iterator = iter(iterator)\n",
    "    try:\n",
    "        first = next(iterator)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "    return all(first == rest for rest in iterator)\n",
    "\n",
    "def send_slack_report(message):\n",
    "    data = {'auth_token': 'auth1', 'widget': 'id1', 'text': message}\n",
    "    r = requests.post(url_slack, data=json.dumps(data), headers=headers)\n",
    "\n",
    "def get_neighbors(grid, i, j):\n",
    "    \n",
    "    nbh = lambda x, i, j: { \n",
    "        (ip, jp) : x[i+ip, j+jp] \n",
    "            for ip, jp in product([1, -1, 0], repeat=2) \n",
    "                if 0 <= i+ip < x.shape[0] and 0 <= j+jp < x.shape[1]\n",
    "    }\n",
    "        \n",
    "    nbh_data = nbh(grid, i, j)\n",
    "    nbh_values = [(1, 1), (1, -1), (1, 0), (-1, 1), (-1, -1), \n",
    "                  (-1, 0), (0, 1), (0, -1), (0, 0)]\n",
    "\n",
    "    for val in nbh_values:\n",
    "        if val not in nbh_data:\n",
    "            nbh_data[val] = 0\n",
    "    \n",
    "    return nbh_data\n",
    "\n",
    "def get_background_color(grid):\n",
    "    \n",
    "    try:    \n",
    "        background_color = 0\n",
    "        cnt = np.bincount(grid.flatten())[1:]\n",
    "        bg_color = [i + 1 for i, x in enumerate(cnt) if x == max(cnt)][0]\n",
    "        if np.nonzero(cnt)[0].shape[0] >= 2:\n",
    "            if max(cnt) >= (grid.shape[0] * grid.shape[1] * 0.25):\n",
    "                background_color = bg_color\n",
    "        return background_color    \n",
    "    \n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "# return a list with all the colors available in grid\n",
    "def get_unique_colors(grid):\n",
    "        return np.unique(grid).tolist()\n",
    "    \n",
    "# Return a dictionary color:percentage, for instance: {0: 0.666,1: 0.333, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}\n",
    "def color_percentage(grid, sorted_dict=True):\n",
    "    \n",
    "    n_elements = grid.shape[0] * grid.shape[1]\n",
    "    if ( n_elements <= 0):\n",
    "        raise ValueError(\"n_elements <= 0\")\n",
    "    unique, counts = np.unique(grid, return_counts=True)\n",
    "    if not (all(j < 10 for j in unique)):\n",
    "        raise ValueError(\"Uknown color! \", j)\n",
    "        \n",
    "    percentages =  dict(zip(unique, counts))\n",
    "    for color in range(0,10):\n",
    "        if color not in percentages.keys():\n",
    "            percentages[color] = 0.0\n",
    "    percentages.update((x, y*1.0/n_elements) for x, y in percentages.items())\n",
    "    \n",
    "    if sorted_dict:\n",
    "        #percentages = collections.OrderedDict(percentages)\n",
    "        percentages = collections.OrderedDict(sorted(percentages.items(), key=lambda item: item[1], reverse=True))\n",
    "        \n",
    "\n",
    "    return percentages\n",
    "\n",
    "# Return True if symmetric\n",
    "def horizontal_symmetric(grid):\n",
    "    return np.array_equal(grid, np.flipud(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def vertical_symmetric(grid):\n",
    "    return np.array_equal(grid, np.fliplr(grid))\n",
    "\n",
    "# Return True if symmetric\n",
    "def left_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid.T)\n",
    "\n",
    "# Return True if symmetric\n",
    "def right_diagonal_symmetric(grid):\n",
    "    return np.array_equal(grid, grid[::-1,::-1].T) # or np.rot90(grid,2).T\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Detection)\n",
      "--- 0.001940011978149414 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Detection)\")\n",
    "       \n",
    "# Ensure No Duplicate Objects\n",
    "def search_array(arr, arr_data):\n",
    "    return next((True for elem in arr_data if np.array_equal(elem, arr)), False)\n",
    "\n",
    "# Separate Objects by Distance\n",
    "def object_detection_1(grid):\n",
    "    \n",
    "    # List of Objects\n",
    "    object_list = []\n",
    "    grid_copy = grid.copy()\n",
    "    struct = generate_binary_structure(2, 2)\n",
    "    labels, num_labels = label((grid_copy != 0), structure=struct)\n",
    "\n",
    "    # Find Objects\n",
    "    for i in range(0, num_labels):\n",
    "        idx = np.column_stack(np.where(labels == i + 1))\n",
    "        x_min = min([point[0] for point in idx])\n",
    "        y_min = min([point[1] for point in idx])\n",
    "        x_max = max([point[0] for point in idx])\n",
    "        y_max = max([point[1] for point in idx])\n",
    "\n",
    "        object_data = {}\n",
    "        object_data['coords'] = idx\n",
    "        object_data['obj'] = grid_copy[x_min: x_max + 1, y_min: y_max + 1]\n",
    "        list.append(object_list, object_data)\n",
    "\n",
    "    return object_list\n",
    "        \n",
    "# Separate Objects by Color/Distance\n",
    "def object_detection_2(grid):\n",
    "    \n",
    "    # List of Objects\n",
    "    object_list = []\n",
    "    grid_copy = grid.copy()\n",
    "    struct = generate_binary_structure(2, 2)\n",
    "    \n",
    "    # Ensure Colors != Background\n",
    "    grid_colors = np.unique(grid_copy)\n",
    "    bg_color = get_background_color(grid_copy)\n",
    "    grid_colors = [col for col in grid_colors if col not in [0, bg_color]]\n",
    "\n",
    "    # Find Objects\n",
    "    for color in grid_colors:\n",
    "        labels, num_labels = label((grid_copy == color), structure=struct)\n",
    "        for i in range(0, num_labels):\n",
    "            idx = np.column_stack(np.where(labels == i + 1))\n",
    "            x_min = min([point[0] for point in idx])\n",
    "            y_min = min([point[1] for point in idx])\n",
    "            x_max = max([point[0] for point in idx])\n",
    "            y_max = max([point[1] for point in idx])\n",
    "\n",
    "            object_data = {}\n",
    "            object_data['coords'] = idx\n",
    "            object_data['obj'] = grid_copy[x_min: x_max + 1, y_min: y_max + 1]\n",
    "            list.append(object_list, object_data)\n",
    "        \n",
    "    return object_list\n",
    "\n",
    "# Separate Layers in grid\n",
    "def layer_detection(grid):\n",
    "    \n",
    "    # List of Layers\n",
    "    layer_list = []\n",
    "    grid_copy = grid.copy()\n",
    "    grid_colors = np.unique(grid_copy)\n",
    "\n",
    "    # Find Layers by Color\n",
    "    for color in grid_colors:\n",
    "        layer_copy = grid_copy.copy()\n",
    "        layer_copy[layer_copy != color] = 0\n",
    "        \n",
    "        idx = []\n",
    "        for i in range(0, grid_copy.shape[0]):\n",
    "            for j in range(0, grid_copy.shape[1]):\n",
    "                list.append(idx, [i, j])\n",
    "\n",
    "        layer_data = {}\n",
    "        layer_data['coords'] = np.array(idx)\n",
    "        layer_data['obj'] = layer_copy\n",
    "        list.append(layer_list, layer_data)\n",
    "        \n",
    "    return layer_list\n",
    "      \n",
    "# Separate Regions in grid\n",
    "def region_detection(grid):\n",
    "    \n",
    "    # List of Regions\n",
    "    region_list = []\n",
    "    grid_copy = grid.copy()\n",
    "\n",
    "    # Ensure Colors != Background\n",
    "    grid_colors = np.unique(grid_copy)\n",
    "    bg_color = get_background_color(grid_copy)\n",
    "    grid_colors = [col for col in grid_colors if col not in [0, bg_color]]\n",
    "    \n",
    "    # Find Regions by Looking for Horizontal/Vertical Lines\n",
    "    # Typically, there won't be any overlap between region lines/object colors\n",
    "    for color in grid_colors:\n",
    "        \n",
    "        # Declare Splits\n",
    "        vertical_splits = None\n",
    "        horizontal_splits = None\n",
    "\n",
    "        # Vertical Regions\n",
    "        vertical_partition = np.zeros((grid_copy.shape[0], 1))       \n",
    "        vertical_partition[:, 0] = color\n",
    "        vertical_result = cv2.matchTemplate(\n",
    "            grid_copy.astype(np.uint8), vertical_partition.astype(np.uint8), cv2.TM_SQDIFF)\n",
    "        vertical_positions = np.argwhere(vertical_result < 0.001)\n",
    "\n",
    "        # Horizontal Regions\n",
    "        horizontal_partition = np.zeros((1, grid_copy.shape[1]))       \n",
    "        horizontal_partition[0, :] = color\n",
    "        horizontal_result = cv2.matchTemplate(\n",
    "            grid_copy.astype(np.uint8), horizontal_partition.astype(np.uint8), cv2.TM_SQDIFF)\n",
    "        horizontal_positions = np.argwhere(horizontal_result < 0.001)\n",
    "                \n",
    "        # Check if Horizontal/Vertical Partitions Exist\n",
    "        if (len(vertical_positions) >= 1) or (len(horizontal_positions) >= 1):\n",
    "            \n",
    "            # Combine Vertical/Horizontal Regions\n",
    "            vertical_splits = [-1] + [x[1] for x in vertical_positions]\n",
    "            horizontal_splits = [-1] + [x[0] for x in horizontal_positions]\n",
    "            \n",
    "            # Get Vertical Split Ranges\n",
    "            for i, v_split in enumerate(vertical_splits):\n",
    "                end_split_i = None\n",
    "                start_split_i = vertical_splits[i]\n",
    "                if i + 1 == len(vertical_splits):\n",
    "                    end_split_i = grid_copy.shape[1]\n",
    "                else:\n",
    "                    end_split_i = vertical_splits[i + 1]\n",
    "\n",
    "                # Get Horizontal Split Ranges\n",
    "                for j, h_split in enumerate(horizontal_splits): \n",
    "                    end_split_j = None\n",
    "                    start_split_j = horizontal_splits[j]\n",
    "                                        \n",
    "                    if j + 1 == len(horizontal_splits):\n",
    "                        end_split_j = grid_copy.shape[0]\n",
    "                    else:\n",
    "                        end_split_j = horizontal_splits[j + 1]\n",
    "                    \n",
    "                    idx = []\n",
    "                    for i in range(start_split_i + 1, end_split_i):\n",
    "                        for j in range(start_split_j + 1, end_split_j):\n",
    "                            list.append(idx, [i, j])\n",
    "\n",
    "                    region_data = {}\n",
    "                    region_data['coords'] = np.array(idx)\n",
    "                    region_data['obj'] = grid_copy[start_split_j + 1: end_split_j, start_split_i + 1: end_split_i]\n",
    "                    list.append(region_list, region_data)\n",
    "\n",
    "    return region_list\n",
    "         \n",
    "# Separate Object in grid\n",
    "def object_detection(grid):\n",
    "    \n",
    "    # List of Objects\n",
    "    combined_objects = []\n",
    "    \n",
    "    # Run Object Detection (1)\n",
    "    obj1 = object_detection_1(grid)    \n",
    "    for object_ in obj1:\n",
    "        current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "        if not search_array(object_[\"obj\"], current_objects):\n",
    "            combined_objects.append(object_)\n",
    "\n",
    "    # Run Object Detection (2)\n",
    "    obj2 = object_detection_2(grid)\n",
    "    for object_ in obj2:\n",
    "        current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "        if not search_array(object_[\"obj\"], current_objects):\n",
    "            combined_objects.append(object_)\n",
    "\n",
    "    # Calculate Layers/Regions\n",
    "    layers = layer_detection(grid)\n",
    "    regions = region_detection(grid)\n",
    "\n",
    "    # Check Layers for Unique Objects\n",
    "    for layer in layers:\n",
    "        \n",
    "        # Run Object Detection (3)\n",
    "        obj1 = object_detection_1(layer[\"obj\"])\n",
    "        for object_ in obj1:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "        # Run Object Detection (4)\n",
    "        obj2 = object_detection_2(layer[\"obj\"])\n",
    "        for object_ in obj2:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "    # Check Regions for Unique Objects\n",
    "    for region in regions:\n",
    "        \n",
    "        # Run Object Detection (3)\n",
    "        obj1 = object_detection_1(region[\"obj\"])                \n",
    "        for object_ in obj1:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "        # Run Object Detection (4)\n",
    "        obj2 = object_detection_2(region[\"obj\"])\n",
    "        for object_ in obj2:\n",
    "            current_objects = [object_data[\"obj\"] for object_data in combined_objects]\n",
    "            if not search_array(object_[\"obj\"], current_objects):\n",
    "                combined_objects.append(object_)\n",
    "\n",
    "    return combined_objects\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Helper Functions (Entity)\n",
      "--- 0.004421234130859375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Helper Functions (Entity)\")\n",
    "\n",
    "# Fundamental Entity (Tensors, Objects, etc). \n",
    "# Contains all Basic Methods acting on Task Samples.\n",
    "class Entity():\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        self.grid = grid\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        self.attributes = {}\n",
    "        \n",
    "        # Color Related\n",
    "        self.attributes[\"unique_colors\"] = get_unique_colors(self.grid)\n",
    "        self.attributes[\"n_unique_colors\"] = len(self.attributes[\"unique_colors\"])\n",
    "        self.attributes[\"n_unique_non_backg_colors\"] = self.attributes[\"n_unique_colors\"] - 1\n",
    "        self.attributes[\"grid_colors_perc\"] = color_percentage(self.grid)\n",
    "    \n",
    "        existing_colors = {k: v for k, v in self.attributes[\"grid_colors_perc\"].items() if v > 0}\n",
    "        existing_colors = list(existing_colors.keys())\n",
    "\n",
    "        self.attributes[\"most_common_color\"] = existing_colors[0]\n",
    "        try:\n",
    "            self.attributes[\"second_most_common_color\"] = existing_colors[1]\n",
    "        except:\n",
    "            pass\n",
    "        self.attributes[\"least_common_color\"] = existing_colors[-1]\n",
    "        \n",
    "        # Shape Related\n",
    "        self.attributes[\"grid_shape\"] = self.grid.shape\n",
    "        \n",
    "        # Symmetry Related\n",
    "        self.attributes[\"h_symm\"] = horizontal_symmetric(self.grid)\n",
    "        self.attributes[\"v_symm\"] = vertical_symmetric(self.grid)\n",
    "        self.attributes[\"ld_symm\"] = left_diagonal_symmetric(self.grid)\n",
    "        self.attributes[\"rd_symm\"] = right_diagonal_symmetric(self.grid)\n",
    "        \n",
    "        \n",
    "# Extends Entity Class\n",
    "# Contains Data for Sections of grid\n",
    "class Section(Entity):\n",
    "    \n",
    "    def __init__(self, section_data):\n",
    "        super().__init__(section_data[\"obj\"])\n",
    "        self.coords = section_data[\"coords\"]\n",
    "            \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()\n",
    "\n",
    "# Extends Entity Class\n",
    "# Contains Entire Data for Input/Output\n",
    "class Tensor(Entity):\n",
    "    \n",
    "    def __init__(self, grid):\n",
    "        super().__init__(grid)\n",
    "        self.objects = []\n",
    "        self.layers = []\n",
    "        self.regions = []\n",
    "        \n",
    "    def compute_features(self):\n",
    "        object_data = object_detection(self.grid)\n",
    "        layer_data = layer_detection(self.grid)\n",
    "        region_data = region_detection(self.grid)\n",
    "    \n",
    "        for object_ in object_data:\n",
    "            section = Section(object_)\n",
    "            section.compute_attributes()\n",
    "            list.append(self.objects, section)\n",
    "        for layer_ in layer_data:\n",
    "            section = Section(layer_)\n",
    "            section.compute_attributes()\n",
    "            list.append(self.layers, section)\n",
    "        for region_ in region_data:\n",
    "            section = Section(region_)\n",
    "            section.compute_attributes()\n",
    "            list.append(self.regions, section)\n",
    "                \n",
    "    def compute_attributes(self):\n",
    "        super().compute_attributes()           \n",
    "\n",
    "# Fundamental Class for ALL Tasks\n",
    "# Contains all Basic Methods acting on Tasks.\n",
    "class Task():\n",
    "    \n",
    "    def __init__(self, train_data, test_data, LB_submission=False):\n",
    "        \n",
    "        # Lists of Train/Test Tensors\n",
    "        self.train_tensors = [] # Explicitly:  [[t_in_1,t_out_1],[t_in_2,t_out_2],...\n",
    "        self.train_diff = []  # For every in-out pair, difference between in and out attributes\n",
    "        self.common_diff = {} # For all the in-out pairs, common differences (Example: All of the in-out pairs change color)\n",
    "        self.sequences = {} # Sequences or patterns among all the in-out pairs \n",
    "        self.test_tensors = []\n",
    "        self.LB_submission = LB_submission\n",
    "        \n",
    "        # Compute Train Tensors\n",
    "        for t_in, t_out in train_data:\n",
    "            tensor_in = Tensor(t_in)\n",
    "            tensor_out = Tensor(t_out)\n",
    "            list.append(self.train_tensors, [tensor_in, tensor_out])\n",
    "            \n",
    "        # Compute Test Tensors\n",
    "        if self.LB_submission:\n",
    "            for t_in in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                list.append(self.test_tensors, [tensor_in])\n",
    "        else:\n",
    "            for t_in, t_out in test_data:\n",
    "                tensor_in = Tensor(t_in)\n",
    "                tensor_out = Tensor(t_out)\n",
    "                list.append(self.test_tensors, [tensor_in, tensor_out])\n",
    "        \n",
    "           \n",
    "    # Compute Task Train Attributes \n",
    "    def compute_train_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            for t in in_out_pair:\n",
    "                t.compute_attributes()\n",
    "    \n",
    "    # Compute Task Test Attributes \n",
    "    def compute_test_attributes(self):\n",
    "        if self.LB_submission:\n",
    "            for t in self.test_tensors:\n",
    "                t[0].compute_attributes()\n",
    "        else:\n",
    "            for in_out_pair in self.test_tensors:\n",
    "                for t in in_out_pair:\n",
    "                    t.compute_attributes()\n",
    "    \n",
    "    # Compute Attribute Differences for every in-out pair\n",
    "    def compute_diff_attributes(self):\n",
    "        for in_out_pair in self.train_tensors:\n",
    "            diff = {}\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "            \n",
    "            # Color Related\n",
    "            diff[\"color_changed\"] = set(t_in.attributes[\"unique_colors\"]) != set(t_out.attributes[\"unique_colors\"])\n",
    "            diff[\"new_colors\"] = list(set(t_out.attributes[\"unique_colors\"]) - set(t_in.attributes[\"unique_colors\"]))\n",
    "            \n",
    "            keylist = t_in.attributes[\"grid_colors_perc\"].keys()\n",
    "            color_perc_in = np.array([t_in.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            color_perc_out = np.array([t_out.attributes[\"grid_colors_perc\"][key] for key in keylist])\n",
    "            diff[\"color_perc_changed\"] = not np.allclose(color_perc_in, color_perc_out)\n",
    "            \n",
    "            diff[\"most_common_color_changed\"] = t_in.attributes[\"most_common_color\"] != t_out.attributes[\"most_common_color\"]\n",
    "            try:\n",
    "                diff[\"second_most_common_color_changed\"] = t_in.attributes[\"second_most_common_color\"] != t_out.attributes[\"second_most_common_color\"]\n",
    "            except:\n",
    "                pass\n",
    "            diff[\"least_common_color_changed\"] = t_in.attributes[\"least_common_color\"] != t_out.attributes[\"least_common_color\"]\n",
    "            \n",
    "            # Shape Related\n",
    "            diff[\"shape_changed\"] = t_in.attributes[\"grid_shape\"] != t_out.attributes[\"grid_shape\"]\n",
    "            diff[\"h_shape_changed\"] = t_in.attributes[\"grid_shape\"][1] != t_out.attributes[\"grid_shape\"][1]\n",
    "            diff[\"v_shape_changed\"] = t_in.attributes[\"grid_shape\"][0] != t_out.attributes[\"grid_shape\"][0]\n",
    "           \n",
    "            \n",
    "            # Symmetry Related\n",
    "            diff[\"h_symm_changed\"] = t_in.attributes[\"h_symm\"] != t_out.attributes[\"h_symm\"]\n",
    "            diff[\"v_symm_changed\"] = t_in.attributes[\"v_symm\"] != t_out.attributes[\"v_symm\"]\n",
    "            diff[\"ld_symm_changed\"] = t_in.attributes[\"ld_symm\"] != t_out.attributes[\"ld_symm\"]\n",
    "            diff[\"rd_symm_changed\"] = t_in.attributes[\"rd_symm\"] != t_out.attributes[\"rd_symm\"]\n",
    "            \n",
    "            # Other\n",
    "            diff[\"is_in_in_out\"] = match_template(t_out.grid, t_in.grid)\n",
    "            diff[\"is_out_in_in\"] = match_template(t_in.grid, t_out.grid)\n",
    "            \n",
    "            \n",
    "            list.append(self.train_diff,diff)\n",
    "        \n",
    "    # Find Common Differences in Input/Output Pairs. Return a dict \"diff\":int, such as {'color_changed': -1, 'color_perc_changed': 1, 'shape_changed': 1}.\n",
    "    def find_common_diff(self):\n",
    "        \n",
    "        diffs = self.train_diff[0].keys()\n",
    "        \n",
    "        for k in diffs:\n",
    "            try:\n",
    "                truth_values = []\n",
    "                for i, diff in enumerate(self.train_diff): \n",
    "                    truth_values.append(diff[k])\n",
    "\n",
    "                if all(truth_values): \n",
    "                    self.common_diff[k] = 1 # this difference k is common in all the in-out pairs and it is True.\n",
    "                elif (not all(truth_values)) and (not any(truth_values)):\n",
    "                    self.common_diff[k] = -1 # this difference k is common in all the in-out pairs and it is False.\n",
    "                else:\n",
    "                    self.common_diff[k] = 0 # the difference is not common to all the in-out pairs.\n",
    "            except KeyError as error:\n",
    "                self.common_diff[k] = 0\n",
    "                \n",
    "        \n",
    "    # Find Sequences or patterns in Common Differences or in the outputs. \n",
    "    # For instance a color/shape common to all the outputs.\n",
    "    def find_sequence(self):\n",
    "        \n",
    "        # find which colors do not appear in train input, but appear in all the outputs\n",
    "        common_new_colors = [0,1,2,3,4,5,6,7,8,9]\n",
    "        for pair in task_data.train_diff:\n",
    "            common_new_colors = list(set(common_new_colors).intersection(pair[\"new_colors\"]))\n",
    "        self.sequences[\"common_new_colors\"] = common_new_colors\n",
    "        for i, cnc in enumerate(self.sequences[\"common_new_colors\"]):\n",
    "            self.sequences[\"common_new_colors\" + \"_\" + str(i)] = cnc\n",
    "                               \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Rotates) ...\n",
      "--- 0.0006458759307861328 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Rotates) ...\")\n",
    "\n",
    "# Rotate Image 90 Degrees\n",
    "def rotate_1(a, *args):\n",
    "    return np.rot90(a, 1, axes=(0,1))\n",
    "\n",
    "# Rotate Image 180 Degrees\n",
    "def rotate_2(a, *args):\n",
    "    return np.rot90(a, 2, axes=(0,1))\n",
    "\n",
    "# Rotate Image 270 Degrees\n",
    "def rotate_3(a, *args):\n",
    "    return np.rot90(a, 3, axes=(0,1))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Flips) ...\n",
      "--- 0.0005888938903808594 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Flips) ...\")\n",
    "\n",
    "# Flip Image Along X-Axis\n",
    "def flip_1(a, *args):\n",
    "    return np.flip(a, 0)\n",
    "\n",
    "# Flip Image Along Y-Axis\n",
    "def flip_2(a, *args):\n",
    "    return np.flip(a, 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Mirrors) ...\n",
      "--- 0.0009458065032958984 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Mirrors) ...\")\n",
    "\n",
    "# Mirror Image Along Top Side of Frame\n",
    "def mirror_1(a, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=0), a), axis=0)\n",
    "\n",
    "# Mirror Image Along Right Side of Frame\n",
    "def mirror_2(a, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=1)), axis=1)\n",
    "\n",
    "# Mirror Image Along Bottom Side of Frame\n",
    "def mirror_3(a, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((a, np.flip(a, axis=0)), axis=0)\n",
    "\n",
    "# Mirror Image Along Left Side of Frame\n",
    "def mirror_4(a, *args):\n",
    "    if ((a.shape[0] * 2) > MAX_DIM_MATRIX) or ((a.shape[1] * 2) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    return np.concatenate((np.flip(a, axis=1), a), axis=1)  \n",
    "\n",
    "# Get Transpose of Image\n",
    "def mirror_5(a, *args):\n",
    "    return a.T\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.0006098747253417969 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Duplicate Original grid args[0] times vertically and args[1] horizontally\n",
    "def repeat_1(a, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.tile(a,(args[0],args[1]))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Duplications) ...\n",
      "--- 0.0006730556488037109 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Duplications) ...\")\n",
    "\n",
    "# Elastically rescales up grid args[0] times vertically and args[1] horizontally\n",
    "def rescale_1(a, *args):\n",
    "    if ((a.shape[0] * args[0]) > MAX_DIM_MATRIX) or ((a.shape[1] * args[1]) > MAX_DIM_MATRIX):\n",
    "        raise ValueError(\"Matrix is too big\")\n",
    "    if (args[0] < 1) or (args[1] < 1):\n",
    "        raise ValueError(\"Number of repetitions must be at least 1 time\")\n",
    "    if (args[0] == 1) and (args[1] == 1):\n",
    "        raise ValueError(\"At least one number of repetitions must be greater than 1\")\n",
    "    return np.kron(a, np.ones((args[0],args[1]), dtype=np.uint8)) \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Crop) ...\n",
      "--- 0.000518798828125 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Crop) ...\")\n",
    "\n",
    "# Crop using the coordinates of a color as a reference.\n",
    "def crop_1(a, *args):\n",
    "    color = args[0]\n",
    "    coords = np.argwhere(a==color)\n",
    "    try:\n",
    "        x_min, y_min = coords.min(axis=0)\n",
    "        x_max, y_max = coords.max(axis=0)\n",
    "        return a[x_min:x_max+1, y_min:y_max+1]\n",
    "    except:\n",
    "        return a\n",
    "\n",
    "#def crop_n(a, *args):\n",
    "#    if (args[0] < 1) or (args[1] < 1) or (args[2] < 1) or (args[3] < 1):\n",
    "#        raise ValueError(\"Coordinates are less than 1\")\n",
    "#    x_min, y_min = args[0], args[1]\n",
    "#    x_max, y_max = args[2], args[3]\n",
    "#    return a[x_min-1:x_max-1, y_min-1:y_max-1]\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Symmetric) ...\n",
      "--- 0.0005509853363037109 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Symmetric) ...\")\n",
    "\n",
    "# Make Image Symmetric Along X-Axis\n",
    "def symmetric_1(a, *args):\n",
    "    b1 = flip_1(a, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "# Make Image Symmetric Along Y-Axis\n",
    "def symmetric_2(a, *args):\n",
    "    b1 = flip_2(a, *args)\n",
    "    return np.where(b1 == 0, a, b1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DSL Functions (Color) ...\n",
      "--- 0.0006709098815917969 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load DSL Functions (Color) ...\")\n",
    "\n",
    "# Substitute Color1 with Color2 (NOT viceversa) \n",
    "def color_1(a, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    a[b_first] = color2\n",
    "    return a\n",
    "\n",
    "# Swap Color1 with Color2 and Color2 with Color1\n",
    "def color_2(a, *args):\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a == color1\n",
    "    b_second = a == color2\n",
    "    a[b_first] = color2\n",
    "    a[b_second] = color1\n",
    "    return a\n",
    "\n",
    "# Substitute all colors different from Color1 with Color2 (NOT viceversa) \n",
    "def color_3(a, *args):\n",
    "    if (len(get_unique_colors(a)) < 3):\n",
    "        raise ValueError(\"Not enough colors in this grid\")\n",
    "    color1 = args[0]\n",
    "    color2 = args[1]\n",
    "    b_first = a != color1\n",
    "    a[b_first] = color2\n",
    "    return a\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine DSL Functions ...\n",
      "DSL_fs_names  ['rotate_1', 'rotate_2', 'rotate_3', 'flip_1', 'flip_2', 'mirror_1', 'mirror_2', 'mirror_3', 'mirror_4', 'mirror_5', 'repeat_1', 'rescale_1', 'crop_1', 'symmetric_1', 'symmetric_2', 'color_1', 'color_2', 'color_3']\n",
      "Total number of functions:  18\n",
      "--- 0.0014300346374511719 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Combine DSL Functions ...\")\n",
    "\n",
    "rotate = [rotate_1, rotate_2, rotate_3\n",
    "         ]\n",
    "flip = [flip_1, flip_2\n",
    "       ]\n",
    "mirror = [mirror_1,mirror_2,mirror_3,mirror_4,mirror_5]\n",
    "repeat = [repeat_1]\n",
    "rescale = [rescale_1]\n",
    "crop = [crop_1\n",
    "]\n",
    "symmetric = [symmetric_1, symmetric_2]\n",
    "color = [color_1, color_2, color_3\n",
    "        ]\n",
    "\n",
    "DSL_functions = rotate + flip + mirror + repeat + rescale + crop + symmetric + color\n",
    "DSL_fs_names = [f.__name__ for f in DSL_functions]\n",
    "print(\"DSL_fs_names \", DSL_fs_names)\n",
    "print(\"Total number of functions: \", len(DSL_functions))\n",
    "\n",
    "# Return True if the new_function should not compose with the current_functions\n",
    "def forbidden_composition(new_function, current_functions):\n",
    "    \n",
    "    f_names = [f.__name__ for f in current_functions]\n",
    "    new_f_names = [f.__name__ for f in new_function]\n",
    "    forbidden_combos = [\"crop\", \"rescale\", \"repeat\"]\n",
    "    \n",
    "    for keyword in forbidden_combos:\n",
    "        if (keyword in '\\t'.join(new_f_names)) and (keyword in '\\t'.join(f_names)):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Actions ...\n",
      "--- 0.001010894775390625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Actions ...\")\n",
    "\n",
    "# Return the action is defined by the dict above. Put \"UNDEF\" is the function may or may not change the attribute.\n",
    "# Notice that some \"UNDEF\" actions can actually be defined if we add more info.\n",
    "def get_functions_actions(entity):\n",
    "    \n",
    "    shape = entity.attributes[\"grid_shape\"]\n",
    "    is_a_square =  shape[0] == shape[1]\n",
    "    is_h_symm = entity.attributes[\"h_symm\"]\n",
    "    is_v_symm = entity.attributes[\"v_symm\"]\n",
    "    \n",
    "    go_from_h_symm_to_v_or_viceversa = ((is_h_symm) and (not is_v_symm)) or ((is_v_symm) and (not is_h_symm))\n",
    "    \n",
    "    functions_actions = {\n",
    "    \"rotate_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\": not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}, \n",
    "    \"rotate_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"rotate_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":not is_a_square,\"h_shape_changed\":not is_a_square,\"v_shape_changed\":not is_a_square,\"h_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"v_symm_changed\":go_from_h_symm_to_v_or_viceversa,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}, \n",
    "    \"flip_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"flip_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_2\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_3\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":False,\"v_shape_changed\":True,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_4\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":True,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"mirror_5\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"repeat_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"rescale_1\":{\"color_changed\":False,\"color_perc_changed\":False,\"most_common_color_changed\":False,\"second_most_common_color_changed\":False,\"least_common_color_changed\":False,\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"crop_1\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":True,\"h_shape_changed\":\"UNDEF\",\"v_shape_changed\":\"UNDEF\",\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"symmetric_1\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":not is_h_symm,\"v_symm_changed\":False,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"symmetric_2\":{\"color_changed\":False,\"color_perc_changed\":\"UNDEF\",\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":not is_v_symm,\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_1\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"},\n",
    "    \"color_2\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":False,\"v_symm_changed\":False,\"ld_symm_changed\":False,\"rd_symm_changed\":False},\n",
    "    \"color_3\":{\"color_changed\":True,\"color_perc_changed\":True,\"most_common_color_changed\":\"UNDEF\",\"second_most_common_color_changed\":\"UNDEF\",\"least_common_color_changed\":\"UNDEF\",\"shape_changed\":False,\"h_shape_changed\":False,\"v_shape_changed\":False,\"h_symm_changed\":\"UNDEF\",\"v_symm_changed\":\"UNDEF\",\"ld_symm_changed\":\"UNDEF\",\"rd_symm_changed\":\"UNDEF\"}\n",
    "                    }\n",
    "    return functions_actions\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Filtering ...\n",
      "--- 0.0007758140563964844 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Function Filtering ...\")\n",
    "\n",
    "# Filter the functions which will enter the generate loops. Run over all the test_in and take only the functions that are compatible with all the test_in.\n",
    "def function_filter(task, fs_names):\n",
    "\n",
    "    test_t_ins = task.test_tensors\n",
    "    functions_to_select = fs_names\n",
    "    functions_removed = []\n",
    "    \n",
    "    for t_in in test_t_ins:\n",
    "        \n",
    "        functions_actions = get_functions_actions(t_in[0])\n",
    "        diff = task.common_diff\n",
    "        \n",
    "        d1 = [\"color_changed\",\"color_perc_changed\",\"most_common_color_changed\",\"second_most_common_color_changed\",\"least_common_color_changed\",\"shape_changed\",\"h_shape_changed\",\"v_shape_changed\"]\n",
    "        d2 = [\"new_colors\", \"h_symm_changed\",\"v_symm_changed\",\"ld_symm_changed\",\"rd_symm_changed\",\"is_in_in_out\", \"is_in_in_out\"] \n",
    "        print(\"diff\",diff)\n",
    "        d_final =  [x for x in list(diff.keys()) if x not in d2]\n",
    "\n",
    "        # remove the functions (from the list of all function) which make undesired changes. \n",
    "        for f,v in functions_actions.items():\n",
    "            \n",
    "            for diff_name in d_final:\n",
    "                if diff[diff_name]==-1: # Example: if the task is preserving the color. \n",
    "                    if v[diff_name]==True: # Example: check if the function modifies colors. Explicit ==True check is important here.\n",
    "                        if f in functions_to_select: \n",
    "                            functions_removed.append(f) # Example: If so, remove function which modify colors.\n",
    "           \n",
    "\n",
    "                            \n",
    "               \n",
    "    print(\"functions removed\", set(functions_removed))\n",
    "    functions_to_select = [item for item in fs_names if item not in functions_removed]\n",
    "    functions_to_select = [func for func in DSL_functions if func.__name__ in functions_to_select] # convert from string to function\n",
    "    return functions_to_select\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic Numbers ...\n",
      "--- 0.0017430782318115234 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Magic Numbers ...\")\n",
    "\n",
    "# How many additional arguments every functions is taking, for each kind of argument. The order is important here.\n",
    "fs_argument_structure = {\n",
    "\"rotate_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0}, \n",
    "    \"rotate_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"rotate_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0}, \n",
    "    \"flip_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"flip_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"mirror_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"mirror_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"mirror_3\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"mirror_4\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"mirror_5\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"repeat_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"rescale_1\":{\"color_related\":0, \"shape_related\":2,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"crop_1\":{\"color_related\":1, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"symmetric_1\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"symmetric_2\":{\"color_related\":0, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"color_1\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"color_2\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0},\n",
    "    \"color_3\":{\"color_related\":2, \"shape_related\":0,\"regions_related\":0,\"object_related\":0,\"layer_related\":0}\n",
    "                    }\n",
    "\n",
    "\n",
    "# helper to get_magic_numbers from a single tensor. Only color related magic numbers.\n",
    "def get_magic_numbers_color_single(t, magic_numbers_colors):\n",
    "    #colors_perc = t.attributes[\"grid_colors_perc\"] \n",
    "    magic_numbers_colors.append(t.attributes[\"most_common_color\"])\n",
    "    try:\n",
    "        magic_numbers_colors.append(t.attributes[\"second_most_common_color\"])\n",
    "    except:\n",
    "        pass\n",
    "    magic_numbers_colors.append(t.attributes[\"least_common_color\"])\n",
    "    \n",
    "    return magic_numbers_colors \n",
    "\n",
    "# helper\n",
    "def compute_shape_variations(diff,direction, magic_numbers_shape, t_out_shape, t_in_shape): \n",
    "    # append ratios and differences. This is useful for functions like repeat, crop and resize.\n",
    "    if diff:\n",
    "        ratio_1 = t_out_shape[direction]//t_in_shape[direction]\n",
    "        ratio_2 = t_in_shape[direction]//t_out_shape[direction]\n",
    "        diff_1 = t_out_shape[direction]-t_in_shape[direction]\n",
    "        diff_2 = t_in_shape[direction]-t_out_shape[direction]\n",
    "        \n",
    "        if (ratio_1 > 1) and ((t_out_shape[direction]%t_in_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_1)\n",
    "        if (ratio_2 > 1) and ((t_in_shape[direction]%t_out_shape[direction])==0):\n",
    "            magic_numbers_shape.append(ratio_2)\n",
    "        if diff_1 > 0:\n",
    "            magic_numbers_shape.append(diff_1)\n",
    "        if diff_2 > 0:\n",
    "            magic_numbers_shape.append(diff_2)\n",
    "\n",
    "# helper to get_magic_numbers from a pair of tensors. Only shape related magic numbers.\n",
    "def get_magic_numbers_shape_pair(in_out_pair, magic_numbers_shape,task_data,pair_n):\n",
    "    \n",
    "    t_in = in_out_pair[0]\n",
    "    t_out = in_out_pair[1]\n",
    "    \n",
    "    t_in_shape = t_in.attributes[\"grid_shape\"] \n",
    "    t_out_shape = t_out.attributes[\"grid_shape\"] \n",
    "    \n",
    "    # do not append t_in shapes, as they should not be predictive\n",
    "    magic_numbers_shape.extend([1,2,3,4]) # these are pretty basic shape numbers always worth trying \n",
    "    magic_numbers_shape.append(t_out_shape[0])\n",
    "    magic_numbers_shape.append(t_out_shape[1])\n",
    "    \n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"h_shape_changed\"],0, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    compute_shape_variations(task_data.train_diff[pair_n][\"v_shape_changed\"],1, magic_numbers_shape, t_out_shape, t_in_shape)\n",
    "    \n",
    "    return magic_numbers_shape \n",
    "\n",
    "# prepare the magic numbers for all the categories. Example: {'color_related': [0, 2, 3, 4, 6, 8], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "def get_magic_numbers(task_data):\n",
    "    \n",
    "    magic_numbers = {\"color_related\":[], \"shape_related\":[],\"regions_related\":[],\"object_related\":[],\"layer_related\":[]}\n",
    "    \n",
    "    # get magic numbers from train in-out pairs\n",
    "    for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "        magic_numbers[\"shape_related\"] = get_magic_numbers_shape_pair(in_out_pair, magic_numbers[\"shape_related\"],task_data,pair_n)\n",
    "        \n",
    "        for color_n, new_color in enumerate(task_data.sequences[\"common_new_colors\"]): \n",
    "            magic_numbers[\"color_related\"].append(new_color)\n",
    "        for t in in_out_pair:         \n",
    "            magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t, magic_numbers[\"color_related\"])\n",
    "       \n",
    "    # get magic numbers from test in samples\n",
    "    for t in task_data.test_tensors:       \n",
    "        magic_numbers[\"color_related\"] = get_magic_numbers_color_single(t[0], magic_numbers[\"color_related\"])    \n",
    "    \n",
    "    \n",
    "    magic_numbers[\"color_related\"] = list(set(magic_numbers[\"color_related\"]))\n",
    "    magic_numbers[\"shape_related\"] = list(set(magic_numbers[\"shape_related\"]))\n",
    "    return magic_numbers\n",
    "\n",
    "\n",
    "# return all the possible combinations of lists of arguments. For instance, if the function take 2 color_related arguments\n",
    "# and 1 shape_related argument, the function will return a list like: [ [1,2,3], [1,2,4], ... ] with [c1,c2,s1] as ordering.\n",
    "def prepare_magic_arguments(func, magic_numbers):\n",
    "    \n",
    "    func_argument_structure = fs_argument_structure[func.__name__]\n",
    "    magic_args = {'color_related': [], 'shape_related': [], 'regions_related': [], 'object_related': [], 'layer_related': []}\n",
    "    \n",
    "    for x_related,numbers in magic_numbers.items():\n",
    "        if func_argument_structure[x_related] > 0:\n",
    "            # compute all the possible combinations of arguments of the same kind\n",
    "            magic_args[x_related] = list(itertools.product(numbers, repeat=func_argument_structure[x_related]))\n",
    "    \n",
    "    # assemble the arguments of different categories together\n",
    "    magic_args_lists = []\n",
    "    for k,v in magic_args.items():\n",
    "        if len(v) > 0:\n",
    "            magic_args_lists.append(v)\n",
    "    magic_args_mixed = list(itertools.product(*magic_args_lists))\n",
    "    for i in range(len(magic_args_mixed)):\n",
    "        magic_args_mixed[i] = [y for x in magic_args_mixed[i] for y in (x if isinstance(x, tuple) else (x,))]\n",
    "    return magic_args_mixed \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program():\n",
    "    \n",
    "    def __init__(self, functions=[], sim_score=0, acting_on=\"Tensor\", mn=[]):\n",
    "        self.functions = functions # list of functions. The program is the composition of those.\n",
    "        self.sim_score = sim_score # How well the program scores on the expected output.\n",
    "        self.acting_on = acting_on # Is this acting on a Tensor, an Object, a Layer?\n",
    "        self.task_accuracy = 0  # +1 for every time program maps t_in in t_out\n",
    "        self.magic_numbers = mn # list of lists of magic numbers. Every sublist is associated to a function.\n",
    "        self.magic_logic_understood = False\n",
    "        self.logic_num = [] # array which contain strings explaining the logic of the magic numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how much the predicted_out coming from entity_in is in line with the expected \n",
    "# attribute differences of the train in-out pairs in task_data.\n",
    "def attributes_similarity(task_data,entity_in,predicted_out_grid, verbose=False):\n",
    "    \n",
    "    sim_score = 0 # sim_score = 1 if the grids are equal\n",
    "    t_in_grid = entity_in.grid\n",
    "    \n",
    "    # slight misuse of the Task object. I'm using it to easily compute \"common_diff\" and \"sequence\" for [entity_in,predicted_out]\n",
    "    train_data = build_trainlist({\"train\":[{\"input\":t_in_grid,\"output\":predicted_out_grid},],})\n",
    "    t = Task(train_data, train_data)\n",
    "    t.compute_train_attributes()\n",
    "    t.compute_diff_attributes()\n",
    "    t.find_common_diff()\n",
    "    t.find_sequence()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n task_data.common_diff\", task_data.common_diff)\n",
    "        print(\"\\n t.common_diff\", t.common_diff)\n",
    "    \n",
    "    keys_to_exclude = ['color_perc_changed', 'most_common_color_changed', 'second_most_common_color_changed', \n",
    "                       'least_common_color_changed','h_symm_changed', 'v_symm_changed', 'ld_symm_changed',\n",
    "                       'rd_symm_changed',\n",
    "                       #'color_changed',\n",
    "                       #'new_colors',\n",
    "                       #'shape_changed',\n",
    "                       #\"h_shape_changed\", \"v_shape_changed\"\n",
    "                      ] \n",
    "    \n",
    "    normalisation = 0 # normalise to 1\n",
    "    \n",
    "    for key_diff, value in task_data.common_diff.items():\n",
    "        if key_diff not in keys_to_exclude:\n",
    "            normalisation += 1\n",
    "            if task_data.common_diff[key_diff] == t.common_diff[key_diff]: \n",
    "                sim_score += 1\n",
    "    \n",
    "    return sim_score/normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the programs which do not predict the expected attributes when acting on the test t_in\n",
    "def filter_programs(programs, task_data):\n",
    "    \n",
    "\n",
    "    filtered_trained_similarities = []\n",
    "    # Iterate Through Test Tasks\n",
    "    for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "        t_in = in_out_pair[0]\n",
    "\n",
    "        for prog_ram in programs:\n",
    "            \n",
    "            #print(\"prog_ram\",[(x.functions,x.magic_numbers, x.magic_logic_understood) for x in [prog_ram]]) \n",
    "            # make the prediction\n",
    "            pred_generate = t_in.grid\n",
    "            get_magic_numbers_from_logic(prog_ram, t_in, task_data) \n",
    "            for num, func in enumerate(prog_ram.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), func, *prog_ram.magic_numbers[num])\n",
    "                \n",
    "            at_s = attributes_similarity(task_data,t_in,pred_generate)#, verbose=True)\n",
    "            #print(\"at_s\", at_s)\n",
    "            if np.isclose(at_s, 1.0):   # the program satisfies all the expected attributes     \n",
    "                filtered_trained_similarities.append(prog_ram)\n",
    "                \n",
    "    return filtered_trained_similarities \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Programs...\n",
      "--- 0.0036468505859375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Generate Programs...\")\n",
    "        \n",
    "def pred_wrapper(grid, func, *magic_args):\n",
    "    grid_copy = grid.copy()\n",
    "    if DEBUG:\n",
    "        try:\n",
    "            return func(grid_copy, *magic_args)\n",
    "        except Exception as error:\n",
    "            #print(\"ERROR in \", func, error)\n",
    "            return grid\n",
    "    else:\n",
    "        try:\n",
    "            return func(grid_copy, *magic_args)\n",
    "        except:\n",
    "            return grid\n",
    "        \n",
    "def get_sim_score(pred, reference):\n",
    "    if np.array_equal(pred, reference):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5\n",
    "\n",
    "# generate a candidate program\n",
    "def generate_programs(task_data):\n",
    "    \n",
    "    n_train_pairs = len(task_data.train_tensors)\n",
    "    max_solution_length = 2\n",
    "    \n",
    "    # compute attributes\n",
    "    task_data.compute_train_attributes()\n",
    "    task_data.compute_test_attributes()\n",
    "    task_data.compute_diff_attributes()\n",
    "    task_data.find_common_diff()\n",
    "    task_data.find_sequence()\n",
    "    \n",
    "    magic_numbers = get_magic_numbers(task_data)\n",
    "    \n",
    "    # candidate functions which when combined could deliver the correct solution program.\n",
    "    pred_functions = function_filter(task_data, DSL_fs_names)  \n",
    "    \n",
    "    for in_out_pair in task_data.train_tensors:\n",
    "        t_in = in_out_pair[0]\n",
    "        t_out = in_out_pair[1]\n",
    "        \n",
    "        pred_similarities = []\n",
    "        for pred_func in pred_functions:\n",
    "            # run over all magic arguments\n",
    "            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "            for mn in magic_args:\n",
    "                # evaluate all the pred_functions on the t_in Tensor and keep track of their score\n",
    "                pred_generate = pred_wrapper(t_in.grid, pred_func, *mn)\n",
    "                sim_score = get_sim_score(pred_generate, t_out.grid)\n",
    "                list.append(pred_similarities,Program([pred_func],sim_score,\"Tensor\",[mn]))\n",
    "            \n",
    "            # TODO, do the same on Sections\n",
    "        \n",
    "        # keep the first n best scoring programs \n",
    "        n = len(pred_similarities)  \n",
    "        pred_similarities = sorted(pred_similarities, key=lambda x: x.sim_score, reverse=True)[:n]\n",
    "        trained_similarities = []\n",
    "        \n",
    "        \n",
    "        prediction_flags = [True] * len(pred_similarities) # flag if keep searching to update the function. \n",
    "        \n",
    "        # print(\"Seek Better Solution...\")\n",
    "        for j, program in enumerate(pred_similarities):\n",
    "            \n",
    "            current_prog = [program]\n",
    "            # If False, No Better program, store the program as it is now.\n",
    "            while prediction_flags[j] == True:\n",
    "                        \n",
    "                current_pred_func = None\n",
    "                current_pred_magic_numbers = None\n",
    "                new_current_prog = []\n",
    "                updated_flag = [False] * len(current_prog) # flag if the functions are being updated\n",
    "                \n",
    "                for k, prog in enumerate(current_prog):\n",
    "                    \n",
    "                                           \n",
    "                    # if the chains of functions is longer than allowed, add it to the functions to select\n",
    "                    if (len(prog.functions) >= max_solution_length):\n",
    "                        list.append(trained_similarities, prog)\n",
    "                        continue \n",
    "                        \n",
    "                    # compose the program\n",
    "                    pred_generate = t_in.grid \n",
    "                    for num, pred_func in enumerate(prog.functions):\n",
    "                        pred_generate = pred_wrapper(pred_generate.copy(), pred_func, *prog.magic_numbers[num]) # function composition\n",
    "                    task_sim_score = get_sim_score(pred_generate.copy(), t_out.grid)\n",
    "                    current_pred_func = prog.functions\n",
    "                    current_pred_magic_numbers = prog.magic_numbers\n",
    "                    \n",
    "                                    \n",
    "                    look_for_updates = True  # Just put False if debugging\n",
    "                    if look_for_updates:\n",
    "                        updated_similarities = []\n",
    "\n",
    "                        # Iterate over all the functions to generate a new composite function\n",
    "                        for pred_func in pred_functions:\n",
    "                            magic_args = prepare_magic_arguments(pred_func, magic_numbers)\n",
    "                            for mn in magic_args:\n",
    "                                pred_func_generate = pred_wrapper(pred_generate.copy(), pred_func, *mn)\n",
    "                                task_sim_score = get_sim_score(pred_func_generate, t_out.grid)\n",
    "                                list.append(updated_similarities,Program([pred_func],task_sim_score,\"Tensor\",[mn]))\n",
    "\n",
    "                        \n",
    "                        # check if the new composite function scores better than the current_pred_func\n",
    "                        for p in updated_similarities:\n",
    "                            if forbidden_composition(p.functions, current_pred_func): # skip this function, if composition is forbidden\n",
    "                                continue\n",
    "                            if prog.sim_score == 1:\n",
    "                                improvement_threshold = 0 # DEBUG Normally this should be positive! \n",
    "                            else:\n",
    "                                improvement_threshold = -0.1 # DEBUG Normally this should be positive! (assuming max(score)= 1)\n",
    "                            if (p.sim_score > prog.sim_score + improvement_threshold): \n",
    "                                # the function have been improved! Now it will over the whole process again, to see if it can be improved further.\n",
    "                                \n",
    "                                new_current_prog.append(Program(current_pred_func + p.functions ,p.sim_score,\"Tensor\",current_pred_magic_numbers +p.magic_numbers)) \n",
    "                                if not updated_flag[k]:\n",
    "                                    updated_flag[k] = True     # at least one new function has been generated\n",
    "                            else:\n",
    "                                pass\n",
    "                  \n",
    "                    # the functions cannot be improved further (at least not with 1 step), add it to the functions to select\n",
    "                    if not updated_flag[k]: # no updates\n",
    "                        list.append(trained_similarities, prog)\n",
    "                \n",
    "                \n",
    "                #print(\"current_prog loop end\")\n",
    "                #print(\"...\")\n",
    "                current_prog = new_current_prog\n",
    "                \n",
    "                if len(current_prog)==0:\n",
    "                    prediction_flags[j] = False \n",
    "            #print(\"End prediction_flags[j] == True while loop\")\n",
    "            #print(\"-----------\")\n",
    "          \n",
    "        #print(\"End pred_similarities for loop\")\n",
    "        #print(\"-----------\")       \n",
    "        #print(\"trained_similarities\",[(x.functions,x.magic_numbers) for x in trained_similarities])\n",
    "        \n",
    "        return trained_similarities\n",
    "\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Program ...\n",
      "--- 0.0017039775848388672 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Select Program ...\")\n",
    "\n",
    "def select_programs(task_data, generated_programs):\n",
    "    \n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(generated_programs):\n",
    "        program.task_accuracy = 0\n",
    "        logic_understood = []  # list of bools\n",
    "        logic_nums = [] # list of list of strings, containing the logic associated to the respective magic numbers\n",
    "    \n",
    "        # Iterate Through Train Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.train_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "        \n",
    "            pred_generate = t_in.grid\n",
    "            # predict\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), pred_func, *program.magic_numbers[num])\n",
    "            \n",
    "                   \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid):\n",
    "                program.task_accuracy += 1\n",
    "                \n",
    "                # check if the magic numbers follow a logic\n",
    "                program.logic_num = [-1] * len(program.functions) # -1 is a flag for bad outcome\n",
    "                for num, pred_func in enumerate(program.functions):\n",
    "                    program.logic_num[num] = [-1] * len(program.magic_numbers[num])\n",
    "                    for j, n in enumerate(program.magic_numbers[num]):\n",
    "                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"color_related\"] > 0:\n",
    "                            # logic coming from a single grid\n",
    "                            if t_in.attributes[\"most_common_color\"] == n:\n",
    "                                program.logic_num[num][j] = \"most_common_color\"\n",
    "                            elif (\"second_most_common_color\" in t_in.attributes) and (t_in.attributes[\"second_most_common_color\"] == n):\n",
    "                                program.logic_num[num][j] = \"second_most_common_color\"\n",
    "                            elif t_in.attributes[\"least_common_color\"] == n:\n",
    "                                program.logic_num[num][j] = \"least_common_color\"\n",
    "                            else:\n",
    "                                # logic coming from all the in-out train pairs\n",
    "                                for i, cnc in enumerate(task_data.sequences[\"common_new_colors\"]):\n",
    "                                    if cnc == n:\n",
    "                                        program.logic_num[num][j] = \"common_new_colors\" + \"_\" + str(i)\n",
    "                                        \n",
    "                        if fs_argument_structure[pred_func.__name__][\"shape_related\"] > 0:\n",
    "                            if t_in.attributes[\"n_unique_colors\"] == n:\n",
    "                                program.logic_num[num][j] = \"n_unique_colors\"\n",
    "                            elif t_in.attributes[\"n_unique_non_backg_colors\"] == n:\n",
    "                                program.logic_num[num][j] = \"n_unique_non_backg_colors\"\n",
    "\n",
    "                        \n",
    "                # if all the numbers are recognized in some attribute, then we undestood the logic of the task (at least regarding magic numbers)\n",
    "                log_und = True\n",
    "                for k in program.logic_num:\n",
    "                    if -1 in k:\n",
    "                        log_und = False\n",
    "                logic_understood.append(log_und)\n",
    "                logic_nums.append(program.logic_num)\n",
    "                \n",
    "        program.magic_logic_understood = checkEqual1(logic_nums) and all(logic_understood) and (len(logic_understood) > 0)  # True if the program has understood the logic on all the in-out pairs and all the logics are the same      \n",
    "        \n",
    "    # filter by requiring the prediction to have the expected attributes\n",
    "    # generated_programs = filter_programs(generated_programs, task_data)\n",
    "    \n",
    "    # Select Best 3 Solutions\n",
    "    best_programs = sorted(generated_programs, key=lambda x: x.magic_logic_understood, reverse=True) # give priority to programs which understood the logic\n",
    "    best_programs = sorted(best_programs, key=lambda x: x.task_accuracy, reverse=True)\n",
    "    #print(\"best_programs sorted\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs]) \n",
    "    best_programs = best_programs[:3]\n",
    "    print(\"best_programs filtered\", [(x.functions,x.magic_numbers,x.task_accuracy,x.magic_logic_understood, x.logic_num) for x in best_programs]) \n",
    "    return best_programs\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the logic has been understood from the in-out pairs, use this logic to generate the magic numbers\n",
    "# which will solve the test prediction\n",
    "def get_magic_numbers_from_logic(program, t_in, task_data):\n",
    "    \n",
    "    if program.magic_logic_understood:\n",
    "        for num, logic_n in enumerate(program.logic_num):\n",
    "            for l,logic in enumerate(logic_n):\n",
    "                if logic in t_in.attributes: # logic coming from a single grid\n",
    "                    program.magic_numbers[num][l] = t_in.attributes[logic]\n",
    "                if logic in task_data.sequences: # logic coming from all the in-out train pairs\n",
    "                    program.magic_numbers[num][l] = task_data.sequences[logic] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Program Application Framework ...\n",
      "--- 0.0010290145874023438 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Load Program Application Framework ...\")\n",
    "\n",
    "# apply on the test tasks\n",
    "def compute_test_accuracy(task_n, task_data, best_programs):\n",
    "\n",
    "    # Initialize Local Variables\n",
    "    output_test = 0\n",
    "    good_programs = []\n",
    "    good_logics = []\n",
    "    num_test = len(task_data.test_tensors)\n",
    "\n",
    "    # Iterate Through Generated Programs\n",
    "    for i, program in enumerate(best_programs):\n",
    "        program.task_accuracy = 0\n",
    "\n",
    "        # Iterate Through Test Tasks\n",
    "        for pair_n, in_out_pair in enumerate(task_data.test_tensors):\n",
    "            t_in = in_out_pair[0]\n",
    "            t_out = in_out_pair[1]\n",
    "\n",
    "            pred_generate = t_in.grid\n",
    "            \n",
    "            # build magic numbers from the logic\n",
    "            get_magic_numbers_from_logic(program, t_in, task_data)                       \n",
    "            \n",
    "            # make the prediction\n",
    "            for num, pred_func in enumerate(program.functions):\n",
    "                pred_generate = pred_wrapper(pred_generate.copy(), pred_func, *program.magic_numbers[num])\n",
    "                           \n",
    "        \n",
    "            # If Prediction is Accurate, Increment Accuracy\n",
    "            if np.array_equal(pred_generate, t_out.grid):\n",
    "                program.task_accuracy += 1\n",
    "\n",
    "        if program.task_accuracy >= 1:\n",
    "            good_programs.append(program.functions)\n",
    "            good_logics.append(program.logic_num)\n",
    "            output_test += 1\n",
    "            \n",
    "        # Print Log of Task, Program, Accuracy, Percentage Accurate\n",
    "        percent_accuracy = np.round((program.task_accuracy / num_test * 100), 2)\n",
    "        print(\"(Test:{}.{:02d})-(Program:{}, MNs:{}, logic:{})- Acc:{}/{}\".format(\n",
    "            task_n, i, [f.__name__ for f in program.functions], [mn for mn in program.magic_numbers], program.logic_num, program.task_accuracy, num_test))\n",
    "\n",
    "    # Return Accuracy\n",
    "    output_test = int(output_test >= 1)\n",
    "    return {\"accuracy\":output_test,\"good_programs\":[[f.__name__ for f in fs] for fs in good_programs],\"logic\":good_logics}\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Manual) ...\n",
      "--- 0.5737462043762207 seconds ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Manual) ...\")\n",
    "\n",
    "def combine_tasks(a):\n",
    "    b = a.copy()\n",
    "    #print(b)\n",
    "    #b = mirror_4(b)\n",
    "    #b = rotate_1(b)\n",
    "    b = crop_1(b,*[6])\n",
    "    #b = repeat_1(b,*[1,2])\n",
    "    \n",
    "    return b\n",
    "\n",
    "tasks_indices = [338]\n",
    "for task in tasks_indices:\n",
    "    check_p(train_task_data[task], combine_tasks)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DSL Coverage (Training Set) ...\n",
      "Generating Program for Task 13\n",
      "diff {'color_changed': 1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': 1, 'second_most_common_color_changed': 1, 'least_common_color_changed': 1, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': -1, 'is_out_in_in': 0}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'is_in_in_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-cb1f99caf42a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_testlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_task_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_programs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mbest_programs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_programs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_test_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_programs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-350-338aa84674fb>\u001b[0m in \u001b[0;36mgenerate_programs\u001b[0;34m(task_data)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# candidate functions which when combined could deliver the correct solution program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mpred_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDSL_fs_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0min_out_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-345-3bfbcf07a61e>\u001b[0m in \u001b[0;36mfunction_filter\u001b[0;34m(task, fs_names)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdiff_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md_final\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiff_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Example: if the task is preserving the color.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiff_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Example: check if the function modifies colors. Explicit ==True check is important here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions_to_select\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                             \u001b[0mfunctions_removed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Example: If so, remove function which modify colors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_in_in_out'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Testing DSL Coverage (Training Set) ...\")\n",
    "\n",
    "accuracy_full = 0\n",
    "accuracy_tasks = []\n",
    "detailted_accuracy_tasks = []\n",
    "training_flag = True\n",
    "start=13\n",
    "finish=14\n",
    "if training_flag == True:\n",
    "    for task_n in range(start,finish):\n",
    "        task_time = time.time()\n",
    "        print(\"Generating Program for Task {}\".format(task_n))\n",
    "        accuracy = []\n",
    "        \n",
    "        train_data = build_trainlist(train_task_data[task_n])\n",
    "        test_data = build_testlist(train_task_data[task_n])\n",
    "        task_data = Task(train_data, test_data)\n",
    "        gen = generate_programs(task_data)\n",
    "        best_programs = select_programs(task_data, gen)\n",
    "        res = compute_test_accuracy(task_n, task_data, best_programs)\n",
    "        \n",
    "        print(\"Generation Took %s Seconds\" % (time.time() - task_time))\n",
    "        accuracy_full += res[\"accuracy\"]\n",
    "\n",
    "        if res[\"accuracy\"] >= 1:\n",
    "            list.append(accuracy_tasks, task_n)\n",
    "            list.append(detailted_accuracy_tasks, [task_n,res[\"good_programs\"],res[\"logic\"]])\n",
    "            \n",
    "        report_0 = \"Training Set - Final Accuracy: {} / {}\".format(accuracy_full, finish-start)\n",
    "        report_1 = \"Training Set - Accurate Tasks: {}\".format(accuracy_tasks)\n",
    "        report_2 = \"Training Set - Detailed Accurate Tasks: {}\".format(detailted_accuracy_tasks)\n",
    "        print(report_0, \"\\n\", report_1, \"\\n\", \"--------------------\" )\n",
    "        final_report = report_0 + \" \\n \" + report_1 + \" \\n \" + report_2 + \" \\n \" + str(time.time() - start_time) + \" seconds\"\n",
    "        if (((task_n%50==0) or (task_n==finish-start-1)) and (task_n!=0)) and DEBUG:\n",
    "            #send_slack_report(final_report)\n",
    "            pass\n",
    "            \n",
    "if DEBUG:\n",
    "    #send_slack_report(final_report)\n",
    "    pass\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work Area. Feel free to clean if it gets too messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color_changed': True, 'new_colors': [], 'color_perc_changed': True, 'most_common_color_changed': True, 'least_common_color_changed': False, 'shape_changed': True, 'h_shape_changed': True, 'v_shape_changed': True, 'h_symm_changed': True, 'v_symm_changed': True, 'ld_symm_changed': False, 'rd_symm_changed': True, 'is_in_in_out': [], 'is_out_in_in': []}\n",
      "{'color_changed': 1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': 1, 'least_common_color_changed': -1, 'shape_changed': 1, 'h_shape_changed': 0, 'v_shape_changed': 1, 'h_symm_changed': 0, 'v_symm_changed': 0, 'ld_symm_changed': 0, 'rd_symm_changed': 0, 'is_in_in_out': -1, 'is_out_in_in': 0}\n",
      "{'common_new_colors': []}\n"
     ]
    }
   ],
   "source": [
    "task_n = 338#134\n",
    "train_data = build_trainlist(train_task_data[task_n])\n",
    "test_data = build_testlist(train_task_data[task_n])\n",
    "task_data = Task(train_data, test_data)\n",
    "task_data.compute_train_attributes()\n",
    "task_data.compute_test_attributes()\n",
    "task_data.compute_diff_attributes()\n",
    "task_data.find_common_diff()\n",
    "task_data.find_sequence()\n",
    "magic_numbers = get_magic_numbers(task_data)\n",
    "#print(magic_numbers)\n",
    "#print(prepare_magic_arguments(color_1, magic_numbers))\n",
    "print(task_data.train_diff[0])\n",
    "print(task_data.common_diff)\n",
    "print(task_data.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unique_colors': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " 'n_unique_colors': 10,\n",
       " 'n_unique_non_backg_colors': 9,\n",
       " 'grid_colors_perc': OrderedDict([(0, 0.5679012345679012),\n",
       "              (7, 0.09876543209876543),\n",
       "              (1, 0.07407407407407407),\n",
       "              (4, 0.07407407407407407),\n",
       "              (8, 0.06172839506172839),\n",
       "              (9, 0.04938271604938271),\n",
       "              (2, 0.024691358024691357),\n",
       "              (6, 0.024691358024691357),\n",
       "              (3, 0.012345679012345678),\n",
       "              (5, 0.012345679012345678)]),\n",
       " 'most_common_color': 0,\n",
       " 'second_most_common_color': 7,\n",
       " 'least_common_color': 5,\n",
       " 'grid_shape': (9, 9),\n",
       " 'h_symm': False,\n",
       " 'v_symm': False,\n",
       " 'ld_symm': False,\n",
       " 'rd_symm': False}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_data.train_tensors[0][0].attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 0, 0, 0, 0, 8, 8, 8, 8, 0, 8, 8],\n",
       "       [8, 0, 0, 8, 0, 8, 0, 8, 8, 8, 0, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8],\n",
       "       [8, 8, 8, 0, 0, 0, 8, 8, 8, 8, 0, 0, 0, 0, 8, 8, 0, 8, 8, 8, 8],\n",
       "       [8, 8, 0, 8, 8, 8, 8, 0, 8, 8, 0, 0, 0, 0, 8, 8, 0, 0, 0, 8, 8],\n",
       "       [8, 8, 8, 8, 0, 8, 8, 0, 8, 8, 0, 0, 0, 0, 8, 8, 8, 0, 8, 8, 8],\n",
       "       [0, 0, 0, 8, 8, 0, 8, 0, 0, 8, 0, 0, 0, 0, 8, 0, 0, 0, 8, 0, 0],\n",
       "       [8, 8, 8, 8, 0, 0, 8, 0, 8, 0, 0, 0, 0, 0, 8, 8, 8, 0, 8, 8, 8],\n",
       "       [8, 0, 0, 8, 0, 0, 8, 8, 0, 8, 0, 0, 0, 0, 8, 0, 8, 8, 8, 8, 8],\n",
       "       [8, 8, 8, 8, 8, 8, 0, 8, 0, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 8],\n",
       "       [2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 8, 8, 8, 8, 0, 8, 0],\n",
       "       [0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8],\n",
       "       [2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 8, 8, 0, 8, 8, 8, 0],\n",
       "       [2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 0, 0],\n",
       "       [2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 8, 0, 8, 0, 8, 8, 8],\n",
       "       [2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 8, 0, 0, 8],\n",
       "       [0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 8, 0, 0, 0, 8, 8, 0],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 8, 8, 0, 0, 8, 8],\n",
       "       [2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 8, 8, 8, 0, 8, 8, 8]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_data.train_tensors[0][0].grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[2, 2, 0,0],\n",
    "       [0, 2, 2,0],\n",
    "       [0, 0, 0,0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " task_data.common_diff {'color_changed': 1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': -1, 'second_most_common_color_changed': 0, 'least_common_color_changed': 1, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': -1, 'is_out_in_in': 1}\n",
      "\n",
      " t.common_diff {'color_changed': -1, 'new_colors': -1, 'color_perc_changed': 1, 'most_common_color_changed': -1, 'second_most_common_color_changed': -1, 'least_common_color_changed': 1, 'shape_changed': 1, 'h_shape_changed': 1, 'v_shape_changed': 1, 'h_symm_changed': -1, 'v_symm_changed': -1, 'ld_symm_changed': -1, 'rd_symm_changed': -1, 'is_in_in_out': -1, 'is_out_in_in': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_similarity(task_data,task_data.test_tensors[0][0],crop_1(task_data.test_tensors[0][0].grid,*[1]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newly solved tasks:  [56, 268, 288]\n",
      "old broken tasks:  [145]\n"
     ]
    }
   ],
   "source": [
    "score_old =  [13, 30, 35, 48, 82, 86, 112, 115, 128, 139, 141, 145, 149, 151, 152, 154, 163, 171, 176, 178, 209, 210, 222, 228, 230, 240, 248, 258, 262, 266, 275, 289, 299, 306, 308, 309, 310, 379, 383, 384]\n",
    "score_new = [13, 30, 35, 48, 56, 82, 86, 112, 115, 128, 139, 141, 149, 151, 152, 154, 163, 171, 176, 178, 209, 210, 222, 228, 230, 240, 248, 258, 262, 266, 268, 275, 288, 289, 299, 306, 308, 309, 310, 379, 383, 384] \n",
    "print(\"newly solved tasks: \", [item for item in score_new if item not in score_old])\n",
    "print(\"old broken tasks: \", [item for item in score_old if item not in score_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = np.array([[2, 2, 0,0],\n",
    "       [0, 2, 2,0],\n",
    "       [0, 0, 0,0]])\n",
    "ff2 = np.array([2])\n",
    "\n",
    "    \n",
    "match_template(ff2, ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([2]).shape == (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
